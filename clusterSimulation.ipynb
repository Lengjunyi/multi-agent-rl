{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b3149e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e081ed88",
   "metadata": {},
   "source": [
    "This part is reproduction of a previous work of past year student, Timothy Yeo\n",
    "\n",
    "With 2 Data Center, each with 5 machines and 6 queue length.\n",
    "total feature nubmer is 2 * (5 * 2+6 * 3+2) = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c3978a",
   "metadata": {},
   "source": [
    "## Single-Agent Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ebc93cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a NN network with following architecture\n",
    "# Input Layer (60 features)\n",
    "# Leaky ReLU activation\n",
    "# Hidden Layer 1 (512 features)\n",
    "# Leaky ReLU activation\n",
    "# Hidden Layer 2 (256 features)\n",
    "# Leaky ReLU activation\n",
    "# Hidden Layer 3 (256 features)\n",
    "# Leaky ReLU activation\n",
    "# Hidden Layer 3 (256 features)\n",
    "# Leaky ReLU activation\n",
    "# Output Layer (4 actions)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SingleAgentNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SingleAgentNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(60, 512)\n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.layer3 = nn.Linear(256, 256)\n",
    "        self.layer4 = nn.Linear(256, 256)\n",
    "        self.layer5 = nn.Linear(256, 4)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Neural Network with input layer {self.input_layer}, hidden layer 1 {self.hidden_layer_1}, hidden layer 2 {self.hidden_layer_2}, hidden layer 3 {self.hidden_layer_3}, hidden layer 4 {self.hidden_layer_4}, and output layer {self.output_layer}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "    def forward_pass(self, input_data):\n",
    "        x = self.layer1(input_data)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer4(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c195d7e",
   "metadata": {},
   "source": [
    "Above are implementation of a previous student's work.\n",
    "Following will be the work by myself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f513300e",
   "metadata": {},
   "source": [
    "# Data Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e82ac8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_SIZE = 28\n",
    "QUERY_SIZE = 1\n",
    "VALUE_SIZE = 4\n",
    "# second config: no information is passed\n",
    "VALUE_SIZE = 1\n",
    "\n",
    "\n",
    "JOB_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46ea3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ae44bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each data center holds two NN, one for state compression (Attention-model) and another for action selection (DQN), the following class represents the Attention model\n",
    "\n",
    "# It has access to the full state of the data center and state representation of neighboring data centers\n",
    "\n",
    "# State Compression Using Attention Model\n",
    "class StateCompressor(nn.Module):\n",
    "    def __init__(self, state_size, query_size, value_size, device=\"cpu\"):\n",
    "        super(StateCompressor, self).__init__()\n",
    "        # might replace into a more appropriate encoder\n",
    "        self.W_v_local = nn.Linear(state_size, value_size).to(device)\n",
    "        # attention qkv\n",
    "        self.W_q = nn.Linear(value_size, query_size).to(device)\n",
    "        # value size add 1 to include extra encoding for the local state distingushment\n",
    "        self.W_k = nn.Linear(value_size+1, query_size).to(device)\n",
    "        self.W_v = nn.Linear(value_size+1, value_size).to(device)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "    def forward_pass(self, local_state, remote_info):\n",
    "        local_info = self.W_v_local(local_state.detach())\n",
    "        full_info = torch.cat((local_info.detach().unsqueeze(0), remote_info.detach()), 0)\n",
    "        full_info_with_encoding = torch.cat((full_info, torch.zeros(full_info.size(0), 1).to(self.device)), 1)\n",
    "        full_info_with_encoding[0, -1] = 1\n",
    "\n",
    "\n",
    "        # print(\"full_info\", full_info.size())\n",
    "        q = self.W_q(local_info)\n",
    "        k = self.W_k(full_info_with_encoding)\n",
    "        v = self.W_v(full_info_with_encoding)\n",
    "        # print(q.size(), k.size(), v.size())\n",
    "        x = torch.matmul(q, k.T)\n",
    "        # print(x.size())\n",
    "        x = torch.nn.functional.softmax(x)\n",
    "        x = torch.matmul(x, v)\n",
    "\n",
    "        return local_info + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bffe161c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3812], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\l\\AppData\\Local\\Temp\\ipykernel_20796\\2790792578.py:39: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = torch.nn.functional.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "# brief test\n",
    "state_compressor = StateCompressor(STATE_SIZE, QUERY_SIZE, VALUE_SIZE)\n",
    "print(state_compressor.forward_pass(torch.zeros(STATE_SIZE), torch.zeros((2,VALUE_SIZE))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "866d9aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# action selection using DQN\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, rep_size, device=\"cpu\"):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(state_size+rep_size+JOB_SIZE+1, 512).to(device)\n",
    "        self.layer2 = nn.Linear(512, 256).to(device)\n",
    "        self.layer3 = nn.Linear(256, 256).to(device)\n",
    "        self.layer4 = nn.Linear(256, 256).to(device)\n",
    "        self.layer5 = nn.Linear(256, 1).to(device)\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer4(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "087de7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0462], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# brief test\n",
    "dqn = DQN(STATE_SIZE, VALUE_SIZE)\n",
    "print(dqn.forward_pass(torch.zeros(STATE_SIZE + VALUE_SIZE + 2 + 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8ad5c3",
   "metadata": {},
   "source": [
    "With 2 Data Center, each with 5 machines and 6 queue length.\n",
    "total feature nubmer is 2 * (5 * 2+6 * 3+2) = 60\n",
    "\n",
    "which means that per machine, we have 5*2+6*3 = 28 state size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a38d9a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCenter():\n",
    "    def __init__(self, device):\n",
    "        # self.data_center_id = data_center_id\n",
    "        # self.machine_num = machine_num\n",
    "        # self.queue_num = queue_num\n",
    "        self.state = torch.zeros(STATE_SIZE).to(device)\n",
    "        self.compressor = StateCompressor(STATE_SIZE, QUERY_SIZE, VALUE_SIZE, device=device)\n",
    "        self.dqn = DQN(STATE_SIZE, VALUE_SIZE)\n",
    "        self.representations = torch.zeros(VALUE_SIZE).to(device)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.dqn_optimizer = torch.optim.Adam(self.dqn.parameters(), lr=0.001)\n",
    "        self.compressor_optimizer = torch.optim.Adam(self.compressor.parameters(), lr=0.001)\n",
    "    \n",
    "    def update(self, delta):\n",
    "        with torch.no_grad():\n",
    "            # reward = gains from successful job allocation - losses from queueing delay\n",
    "            reward = torch.tensor(0.0).to(self.device)\n",
    "            # Separate machine states and queue states\n",
    "            machines = self.state[:10].view(5, 2).clone()\n",
    "            queues = self.state[10:].view(6, 3).clone()\n",
    "\n",
    "            # Update machine states\n",
    "            machines[:, 1] = torch.maximum(torch.zeros_like(machines[:, 1]), machines[:, 1] - delta)\n",
    "            machines[machines[:, 1] == 0, 0] = 0\n",
    "\n",
    "            # Find available machines and assign jobs from the queue\n",
    "            for i in range(queues.size(0)):\n",
    "                if queues[i, 0] > 0:\n",
    "                    # Find first available machine\n",
    "                    available_machine_index = torch.nonzero(machines[:, 0] == 0, as_tuple=False)\n",
    "                    if available_machine_index.size(0) > 0:\n",
    "                        first_available = available_machine_index[0].item()\n",
    "                        machines[first_available, 0] = 1\n",
    "                        machines[first_available, 1] = queues[i, 1]\n",
    "                        reward += queues[i, 2]\n",
    "                        queues[i, :] = 0\n",
    "                else:\n",
    "                    break\n",
    "            # move remaining jobs to the front\n",
    "            queues = torch.cat((queues[queues[:, 0] > 0], queues[queues[:, 0] == 0]), 0)\n",
    "            \n",
    "\n",
    "            \n",
    "            # queues[:, 2] = torch.maximum(torch.zeros_like(queues[:, 2]), queues[:, 2] - 0.1)\n",
    "            queues[:, 2] *= 0.9\n",
    "\n",
    "            # Merge the updated machine and queue states back into self.state\n",
    "            self.state = torch.cat((machines.view(-1), queues.view(-1)))\n",
    "\n",
    "            return reward\n",
    "    \n",
    "    def update_rep(self, remote_info):\n",
    "        new_reps = self.compressor.forward_pass(self.state, remote_info)\n",
    "        # print(new_reps.size(), self.representations.size())\n",
    "        assert new_reps.size() == self.representations.size()\n",
    "        self.representations = new_reps\n",
    "    \n",
    "    def get_q_values(self, reps, job):\n",
    "        batch_input = torch.zeros((2, STATE_SIZE + VALUE_SIZE + JOB_SIZE + 1))\n",
    "        batch_input[0] = torch.cat((self.state, self.representations, job, torch.ones(1).to(self.device)), 0)\n",
    "        for i in range(reps.size(0)):\n",
    "            batch_input[i+1] = torch.cat((self.state, reps[i], job, torch.zeros(1).to(self.device)), 0)\n",
    "            # expand the concat into several instructions\n",
    "        \n",
    "        # batch_input[0, :STATE_SIZE] = self.state\n",
    "        # # batch_input[0, STATE_SIZE:STATE_SIZE+VALUE_SIZE] = self.representations\n",
    "        # batch_input[0, STATE_SIZE+VALUE_SIZE:STATE_SIZE+VALUE_SIZE+JOB_SIZE] = job\n",
    "\n",
    "        batch_input.to(self.device)\n",
    "        q_values = self.dqn.forward_pass(batch_input)\n",
    "        return q_values\n",
    "\n",
    "    # add job to the queue of the data center\n",
    "    def add_job(self, job):\n",
    "        reward = 0\n",
    "        state = self.state.clone()\n",
    "        for i in range(6):\n",
    "            if state[10+i*3] == 0:\n",
    "                state[10+i*3] = 1\n",
    "                state[10+i*3+1] = job[0]\n",
    "                state[10+i*3+2] = job[1]\n",
    "                break\n",
    "        else:\n",
    "            reward -= 0.2\n",
    "        self.state = state\n",
    "        return reward\n",
    "\n",
    "\n",
    "    \n",
    "    # how to do this?\n",
    "    def backprop(self):\n",
    "        self.dqn_optimizer.step()\n",
    "        self.compressor_optimizer.step()\n",
    "\n",
    "        self.dqn_optimizer.zero_grad()\n",
    "        self.compressor_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03427382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 3.9000, 1.0000, 0.9000, 1.0000, 5.0000, 1.0000, 4.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0')\n",
      "tensor([-0.1790], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\l\\AppData\\Local\\Temp\\ipykernel_20796\\2790792578.py:39: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = torch.nn.functional.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dc = DataCenter(device)\n",
    "dc.state[0] = 1\n",
    "dc.state[1] = 4\n",
    "dc.state[2] = 1\n",
    "dc.state[3] = 1\n",
    "dc.state[10] = 1\n",
    "dc.state[11] = 5\n",
    "dc.state[12] = 12\n",
    "dc.state[13] = 1\n",
    "dc.state[14] = 4\n",
    "dc.state[15] = 1\n",
    "\n",
    "dc.update(0.1)\n",
    "print(dc.state)\n",
    "\n",
    "remote_info = torch.zeros((2, VALUE_SIZE)).to(device)\n",
    "dc.update_rep(remote_info)\n",
    "print(dc.representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27f27bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobGenerator():\n",
    "    def __init__(self, data_center_num) -> None:\n",
    "        self.underlying_state = torch.randint(0, 2, (data_center_num,))\n",
    "        self.data_center_num = data_center_num\n",
    "\n",
    "    def generate_job(self):\n",
    "        jobs = []\n",
    "        for i in range(self.data_center_num):\n",
    "            if torch.rand(1).item() < 0.02:\n",
    "                self.underlying_state[i] = 1 - i\n",
    "                \n",
    "            seed = torch.rand(1).item()\n",
    "            if self.underlying_state[i] == 1:\n",
    "                # choose high workload\n",
    "                if seed < 0.4:\n",
    "                    jobs.append((10, 1.0))\n",
    "                elif seed < 0.7:\n",
    "                    jobs.append((6, 0.6))\n",
    "                else:\n",
    "                    jobs.append((4, 0.4))\n",
    "            else:\n",
    "                # choose low workload\n",
    "                if seed < 0.3:\n",
    "                    jobs.append((4, 0.4))\n",
    "                elif seed < 0.7:\n",
    "                    jobs.append((3, 0.3))\n",
    "                else:\n",
    "                    jobs.append((2, 0.2))\n",
    "        return [torch.tensor(j) for j in jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feb31ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([2.0000, 0.2000]), tensor([3.0000, 0.3000])]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "job_generator = JobGenerator(2)\n",
    "print(job_generator.generate_job())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8fd074",
   "metadata": {},
   "source": [
    "# Validity check\n",
    "\n",
    "To investigate that there is no trivial solution for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "572f98fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-113.00000000000107\n",
      "tensor(740.3980)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "total_reward = 0\n",
    "total_neg_reward = 0\n",
    "\n",
    "dataCenter = DataCenter(device)\n",
    "jobGenerator = JobGenerator(1)\n",
    "for i in range(2000):\n",
    "    job = jobGenerator.generate_job()[0]\n",
    "    reward = dataCenter.add_job(job)\n",
    "    total_neg_reward += reward\n",
    "    reward += dataCenter.update(1)\n",
    "    total_reward += reward\n",
    "\n",
    "print(total_neg_reward)\n",
    "\n",
    "dataCenter = DataCenter(device)\n",
    "jobGenerator = JobGenerator(1)\n",
    "for i in range(2000):\n",
    "    job = jobGenerator.generate_job()[0]\n",
    "    reward = dataCenter.add_job(job)\n",
    "    reward += dataCenter.update(1)\n",
    "    total_reward += reward\n",
    "\n",
    "print(total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c310f4",
   "metadata": {},
   "source": [
    "# Utility Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "bc23fcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(q_values, epsilon):\n",
    "    action = None\n",
    "    if torch.rand(1).item() < epsilon:\n",
    "        action = torch.randint(0, q_values.size(0), (1, ))\n",
    "    else:\n",
    "        action = torch.argmax(q_values)\n",
    "    q_value = q_values[action]\n",
    "    return action, q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "348ef84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, state, rep, job, action, reward, next_state, next_rep, next_job):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, rep, job, action, reward, next_state, next_rep, next_job)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # zip into torch tensors\n",
    "        # return zip(*random.sample(self.buffer, batch_size))\n",
    "        batch = random.sample(self.buffer, min(batch_size, len(self.buffer)))\n",
    "        state, rep, job, action, reward, next_state, next_rep, next_job = zip(*batch)\n",
    "        return torch.stack(list(state)), torch.stack(list(rep)), torch.stack(list(job)), torch.stack(list(action)), torch.stack(list(reward)), torch.stack(list(next_state)), torch.stack(list(next_rep)), torch.stack(list(next_job))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d23f4731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1.],\n",
      "        [0.]]), tensor([[1., 1.],\n",
      "        [0., 0.]]), tensor([[0.],\n",
      "        [0.]]), tensor([[0.],\n",
      "        [0.]]), tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1.],\n",
      "        [0.]]), tensor([[1., 1.],\n",
      "        [0., 0.]]))\n"
     ]
    }
   ],
   "source": [
    "# sample test\n",
    "\n",
    "replay_buffer = ReplayBuffer(100)\n",
    "replay_buffer.push(torch.zeros(STATE_SIZE), torch.zeros(VALUE_SIZE), torch.zeros(JOB_SIZE), torch.zeros(1), torch.zeros(1), torch.zeros(STATE_SIZE), torch.zeros(VALUE_SIZE), torch.zeros(JOB_SIZE))\n",
    "replay_buffer.push(torch.ones(STATE_SIZE), torch.ones(VALUE_SIZE), torch.ones(JOB_SIZE), torch.zeros(1), torch.zeros(1), torch.ones(STATE_SIZE), torch.ones(VALUE_SIZE), torch.ones(JOB_SIZE))\n",
    "\n",
    "print(replay_buffer.sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aa5222",
   "metadata": {},
   "source": [
    "# Main Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "68daa6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98fdd64",
   "metadata": {},
   "source": [
    "## Pure DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "7052beb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "model initialized randomly\n",
      "we got  tensor(1326.1486, device='cuda:0') total reward  and actions tensor([2056., 1944.]) 190.0\n",
      "tensor(1326.1486, device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 3.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000,\n",
      "        5.0000, 1.0000, 3.0000, 0.1944, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000,  1.0000,  1.0000,  4.0000,  1.0000,  4.0000,\n",
      "         1.0000, 10.0000,  1.0000,  3.0000,  0.1771,  1.0000,  3.0000,  0.1968,\n",
      "         1.0000, 10.0000,  0.5832,  1.0000,  4.0000,  0.2880,  1.0000,  3.0000,\n",
      "         0.2700,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([2]) tensor(0.5249, device='cuda:0') tensor([10.5733,  9.9677, 10.5469, 10.4242], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1256.8341, device='cuda:0') total reward  and actions tensor([2018., 1982.]) 180.5\n",
      "tensor(1256.8341, device='cuda:0') tensor([1., 4., 1., 4., 1., 4., 0., 0., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  6.0000,  1.0000,  3.0000,  1.0000,  2.0000,  1.0000,  2.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.4252,  1.0000,  2.0000,  0.1063,\n",
      "         1.0000, 10.0000,  0.5249,  1.0000, 10.0000,  0.6480,  1.0000,  4.0000,\n",
      "         0.2880,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([3]) tensor(0.1837, device='cuda:0') tensor([9.6917, 8.9663, 9.9481, 9.8248], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1375.5861, device='cuda:0') total reward  and actions tensor([2040., 1960.]) 171.47499999999997\n",
      "tensor(1375.5861, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  3.0000,  1.0000,  1.0000,  1.0000,  4.0000,\n",
      "         1.0000,  1.0000,  1.0000,  4.0000,  0.2100,  1.0000,  3.0000,  0.1750,\n",
      "         1.0000, 10.0000,  0.8100,  1.0000, 10.0000,  0.9000,  1.0000,  4.0000,\n",
      "         0.2880,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.,  2.,  1.,  4.,  1.,  4.,  1., 10.,  1.,  3.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([0]) tensor(1.5838, device='cuda:0') tensor([9.2582, 9.1815, 8.8879, 9.2853], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1397.4841, device='cuda:0') total reward  and actions tensor([2112., 1888.]) 162.90124999999998\n",
      "tensor(1397.4841, device='cuda:0') tensor([ 1.0000,  7.0000,  1.0000,  6.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "         1.0000,  2.0000,  1.0000,  6.0000,  0.3189,  1.0000, 10.0000,  0.5905,\n",
      "         1.0000,  4.0000,  0.2916,  1.0000, 10.0000,  0.8100,  1.0000,  4.0000,\n",
      "         0.2592,  1.0000,  2.0000,  0.1440], device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 2.0000, 1.0000, 3.0000, 1.0000, 4.0000, 1.0000,\n",
      "        5.0000, 1.0000, 2.0000, 0.1458, 1.0000, 4.0000, 0.2880, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([3]) tensor(0.2916, device='cuda:0') tensor([7.5044, 7.5550, 7.4380, 7.5319], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1380.8079, device='cuda:0') total reward  and actions tensor([2109., 1891.]) 154.75618749999998\n",
      "tensor(1380.8079, device='cuda:0') tensor([1., 2., 1., 3., 1., 1., 1., 3., 1., 7., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  6.0000,  1.0000,  8.0000,  1.0000,  5.0000,  1.0000,  1.0000,\n",
      "         1.0000,  3.0000,  1.0000, 10.0000,  0.7200,  1.0000,  4.0000,  0.3600,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([2]) tensor(0., device='cuda:0') tensor([9.0973, 8.8621, 9.0732, 9.0269], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1386.7561, device='cuda:0') total reward  and actions tensor([2119., 1881.]) 147.01837812499997\n",
      "tensor(1386.7561, device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 4.0000, 1.0000, 8.0000, 1.0000,\n",
      "        3.0000, 1.0000, 4.0000, 0.2100, 1.0000, 6.0000, 0.4374, 1.0000, 3.0000,\n",
      "        0.1750, 1.0000, 4.0000, 0.3240, 1.0000, 2.0000, 0.1296, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1., 5., 1., 7., 1., 4., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([2]) tensor(0.5200, device='cuda:0') tensor([8.2352, 8.4533, 8.1097, 8.3095], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1432.9930, device='cuda:0') total reward  and actions tensor([2145., 1855.]) 139.66745921874994\n",
      "tensor(1432.9930, device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  3.0000,  1.0000,  6.0000,  1.0000,  3.0000,\n",
      "         1.0000,  1.0000,  1.0000,  4.0000,  0.2592,  1.0000, 10.0000,  0.9000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 1.0000, 1.0000, 6.0000, 1.0000, 8.0000, 1.0000,\n",
      "        9.0000, 1.0000, 4.0000, 0.2333, 1.0000, 2.0000, 0.1458, 1.0000, 3.0000,\n",
      "        0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1]) tensor(0.3499, device='cuda:0') tensor([7.8370, 7.8367, 7.8698, 7.8657], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1432.6597, device='cuda:0') total reward  and actions tensor([2197., 1803.]) 132.68408625781245\n",
      "tensor(1432.6597, device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 5.0000, 1.0000, 4.0000, 1.0000, 4.0000, 1.0000,\n",
      "        3.0000, 1.0000, 2.0000, 0.1296, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  5.0000,  1.0000,  3.0000,  1.0000, 10.0000,\n",
      "         1.0000,  3.0000,  1.0000,  4.0000,  0.3600,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([0]) tensor(1.1110, device='cuda:0') tensor([8.6097, 8.4838, 8.5807, 8.4329], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1438.1858, device='cuda:0') total reward  and actions tensor([2204., 1796.]) 126.04988194492182\n",
      "tensor(1438.1858, device='cuda:0') tensor([1., 2., 1., 3., 1., 3., 1., 8., 1., 6., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 3.0000, 1.0000, 5.0000, 1.0000, 4.0000, 1.0000,\n",
      "        5.0000, 1.0000, 6.0000, 0.2834, 1.0000, 2.0000, 0.1181, 1.0000, 4.0000,\n",
      "        0.2592, 1.0000, 3.0000, 0.2430, 1.0000, 2.0000, 0.1800, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([0]) tensor(0.7296, device='cuda:0') tensor([7.8961, 7.8378, 7.7617, 7.7795], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1477.4122, device='cuda:0') total reward  and actions tensor([2212., 1788.]) 119.74738784767571\n",
      "tensor(1477.4122, device='cuda:0') tensor([ 1.0000, 10.0000,  1.0000,  2.0000,  1.0000,  1.0000,  1.0000,  2.0000,\n",
      "         1.0000,  4.0000,  1.0000,  4.0000,  0.2624,  1.0000,  2.0000,  0.1050,\n",
      "         1.0000,  4.0000,  0.2916,  1.0000,  6.0000,  0.4860,  1.0000,  4.0000,\n",
      "         0.2880,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.,  1.,  1., 10.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor(1, device='cuda:0') tensor(1.4561, device='cuda:0') tensor([8.0628, 8.1091, 7.9306, 8.0696], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1468.1709, device='cuda:0') total reward  and actions tensor([2252., 1748.]) 113.76001845529191\n",
      "tensor(1468.1709, device='cuda:0') tensor([ 1.0000,  6.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  4.0000,\n",
      "         1.0000,  1.0000,  1.0000, 10.0000,  0.7290,  1.0000, 10.0000,  0.9000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 3.0000, 1.0000, 4.0000, 1.0000, 2.0000, 1.0000,\n",
      "        4.0000, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([3]) tensor(0.3600, device='cuda:0') tensor([8.9745, 8.9457, 8.9563, 8.9771], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1470.8442, device='cuda:0') total reward  and actions tensor([2307., 1693.]) 108.07201753252731\n",
      "tensor(1470.8442, device='cuda:0') tensor([ 1.0000,  9.0000,  1.0000,  2.0000,  1.0000,  2.0000,  1.0000,  3.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.9000,  1.0000,  4.0000,  0.2880,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.0000,  5.0000,  1.0000,  2.0000,  1.0000,  1.0000,  1.0000,  6.0000,\n",
      "         1.0000,  3.0000,  1.0000, 10.0000,  0.5249,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.3211, device='cuda:0') tensor([8.4474, 8.3994, 8.3929, 8.3995], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1433.7733, device='cuda:0') total reward  and actions tensor([2327., 1673.]) 102.66841665590094\n",
      "tensor(1433.7733, device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 3.0000, 1.0000, 9.0000, 1.0000, 3.0000, 1.0000,\n",
      "        3.0000, 1.0000, 3.0000, 0.1944, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  4.0000,\n",
      "         1.0000,  2.0000,  1.0000,  6.0000,  0.3888,  1.0000, 10.0000,  0.7200,\n",
      "         1.0000,  3.0000,  0.2700,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1]) tensor(0.1750, device='cuda:0') tensor([9.2367, 9.0750, 9.1055, 9.1529], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1481.9803, device='cuda:0') total reward  and actions tensor([2443., 1557.]) 97.53499582310589\n",
      "tensor(1481.9803, device='cuda:0') tensor([1., 4., 1., 8., 1., 3., 1., 1., 1., 5., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 1.0000, 1.0000, 8.0000, 1.0000, 2.0000, 1.0000,\n",
      "        2.0000, 1.0000, 4.0000, 0.2624, 1.0000, 2.0000, 0.1458, 1.0000, 2.0000,\n",
      "        0.1620, 1.0000, 4.0000, 0.2880, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1]) tensor(0.3600, device='cuda:0') tensor([8.3725, 8.3716, 8.4040, 8.3459], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1532.5675, device='cuda:0') total reward  and actions tensor([2412., 1588.]) 92.65824603195058\n",
      "tensor(1532.5675, device='cuda:0') tensor([1., 3., 1., 1., 1., 4., 1., 3., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 3.0000, 1.0000, 4.0000, 1.0000, 3.0000, 1.0000,\n",
      "        2.0000, 1.0000, 3.0000, 0.2187, 1.0000, 4.0000, 0.2880, 1.0000, 4.0000,\n",
      "        0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([2]) tensor(0., device='cuda:0') tensor([9.2675, 9.0463, 9.2642, 9.1618], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1518.7999, device='cuda:0') total reward  and actions tensor([2478., 1522.]) 88.02533373035305\n",
      "tensor(1518.7999, device='cuda:0') tensor([1., 9., 1., 1., 1., 1., 0., 0., 1., 7., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 8.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 6.0000, 1.0000,\n",
      "        4.0000, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([2]) tensor(0.4800, device='cuda:0') tensor([8.5761, 8.4634, 8.5903, 8.4373], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1516.4269, device='cuda:0') total reward  and actions tensor([2504., 1496.]) 83.6240670438354\n",
      "tensor(1516.4269, device='cuda:0') tensor([1., 6., 1., 2., 1., 4., 1., 3., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1., 6., 1., 3., 1., 1., 1., 1., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([0]) tensor(0.9200, device='cuda:0') tensor([8.9172, 8.8601, 8.7147, 8.8001], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1535.9220, device='cuda:0') total reward  and actions tensor([2511., 1489.]) 79.44286369164362\n",
      "tensor(1535.9220, device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 5.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000,\n",
      "        2.0000, 1.0000, 6.0000, 0.3543, 1.0000, 4.0000, 0.2624, 1.0000, 3.0000,\n",
      "        0.1575, 1.0000, 6.0000, 0.4374, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.,  5.,  1., 10.,  1.,  4.,  1.,  2.,  1.,  3.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([2]) tensor(1.1945, device='cuda:0') tensor([8.0443, 7.9988, 7.9396, 8.0169], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1498.6356, device='cuda:0') total reward  and actions tensor([2491., 1509.]) 75.47072050706143\n",
      "tensor(1498.6356, device='cuda:0') tensor([ 1.0000,  6.0000,  1.0000,  3.0000,  1.0000,  2.0000,  1.0000, 10.0000,\n",
      "         1.0000,  3.0000,  1.0000,  2.0000,  0.1440,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  4.0000,  1.0000,  5.0000,  1.0000,  2.0000,\n",
      "         1.0000,  2.0000,  1.0000,  4.0000,  0.2100,  1.0000,  3.0000,  0.1968,\n",
      "         1.0000, 10.0000,  0.6480,  1.0000,  2.0000,  0.1620,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([2]) tensor(1.6272, device='cuda:0') tensor([7.8842, 7.8595, 7.9458, 7.8084], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1534.3519, device='cuda:0') total reward  and actions tensor([2524., 1476.]) 71.69718448170835\n",
      "tensor(1534.3519, device='cuda:0') tensor([1., 3., 1., 8., 1., 6., 1., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  3.0000,  1.0000,  2.0000,  1.0000,  9.0000,\n",
      "         1.0000,  5.0000,  1.0000, 10.0000,  0.7200,  1.0000,  4.0000,  0.3600,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.8820, device='cuda:0') tensor([8.0441, 7.8326, 8.0426, 7.9076], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1536.4314, device='cuda:0') total reward  and actions tensor([2629., 1371.]) 68.11232525762293\n",
      "tensor(1536.4314, device='cuda:0') tensor([ 1.,  1.,  1.,  3.,  1., 10.,  1.,  4.,  1., 10.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 6.0000, 1.0000, 3.0000, 1.0000, 3.0000, 1.0000,\n",
      "        2.0000, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1]) tensor(2.4544, device='cuda:0') tensor([8.2246, 8.1638, 8.1962, 8.1732], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1551.4015, device='cuda:0') total reward  and actions tensor([2587., 1413.]) 64.70670899474177\n",
      "tensor(1551.4015, device='cuda:0') tensor([ 1.0000,  6.0000,  1.0000,  8.0000,  1.0000,  1.0000,  1.0000,  2.0000,\n",
      "         1.0000,  7.0000,  1.0000,  4.0000,  0.2916,  1.0000,  4.0000,  0.2333,\n",
      "         1.0000, 10.0000,  0.8100,  1.0000,  4.0000,  0.3600,  1.0000,  2.0000,\n",
      "         0.1440,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000,\n",
      "        4.0000, 1.0000, 2.0000, 0.1312, 1.0000, 3.0000, 0.2430, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1]) tensor(0.2333, device='cuda:0') tensor([8.0749, 8.1064, 7.9875, 8.0530], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1552.9318, device='cuda:0') total reward  and actions tensor([2651., 1349.]) 61.471373545004695\n",
      "tensor(1552.9318, device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000, 10.0000,  1.0000,  1.0000,  1.0000,  3.0000,\n",
      "         1.0000,  5.0000,  1.0000, 10.0000,  0.8100,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  2.0000,  1.0000,  2.0000,  1.0000, 10.0000,\n",
      "         1.0000,  2.0000,  1.0000,  2.0000,  0.1800,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([3]) tensor(1.6100, device='cuda:0') tensor([8.3871, 8.4057, 8.2606, 8.2831], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1540.8492, device='cuda:0') total reward  and actions tensor([2695., 1305.]) 58.39780486775445\n",
      "tensor(1540.8492, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000, 10.0000,  1.0000,  7.0000,  1.0000,  2.0000,\n",
      "         1.0000,  1.0000,  1.0000,  4.0000,  0.2333,  1.0000,  2.0000,  0.1440,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 6.0000, 1.0000, 3.0000, 1.0000, 3.0000, 1.0000,\n",
      "        4.0000, 1.0000, 3.0000, 0.2430, 1.0000, 6.0000, 0.4320, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1.2420, device='cuda:0') tensor([8.1640, 8.0196, 8.0984, 8.0890], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1548.3563, device='cuda:0') total reward  and actions tensor([2702., 1298.]) 55.47791462436673\n",
      "tensor(1548.3563, device='cuda:0') tensor([1.0000, 6.0000, 1.0000, 3.0000, 1.0000, 7.0000, 1.0000, 9.0000, 1.0000,\n",
      "        4.0000, 1.0000, 3.0000, 0.2160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 1.0000, 1.0000, 4.0000, 1.0000, 6.0000, 1.0000,\n",
      "        1.0000, 1.0000, 4.0000, 0.1890, 1.0000, 4.0000, 0.2624, 1.0000, 6.0000,\n",
      "        0.3499, 1.0000, 3.0000, 0.2187, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0.9956, device='cuda:0') tensor([7.2900, 7.3501, 7.2919, 7.2611], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1522.2291, device='cuda:0') total reward  and actions tensor([2625., 1375.]) 52.704018893148394\n",
      "tensor(1522.2291, device='cuda:0') tensor([1.0000, 7.0000, 1.0000, 5.0000, 1.0000, 4.0000, 1.0000, 6.0000, 1.0000,\n",
      "        5.0000, 1.0000, 6.0000, 0.5400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  2.0000,  1.0000,  6.0000,  1.0000,  2.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.6480,  1.0000,  4.0000,  0.3240,\n",
      "         1.0000,  2.0000,  0.1800,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0.1620, device='cuda:0') tensor([7.7580, 7.8012, 7.7388, 7.6967], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1528.9675, device='cuda:0') total reward  and actions tensor([2623., 1377.]) 50.068817948490974\n",
      "tensor(1528.9675, device='cuda:0') tensor([ 1.0000, 10.0000,  1.0000,  2.0000,  1.0000,  4.0000,  1.0000,  6.0000,\n",
      "         1.0000,  1.0000,  1.0000,  3.0000,  0.1417,  1.0000,  6.0000,  0.3937,\n",
      "         1.0000,  6.0000,  0.4374,  1.0000, 10.0000,  0.8100,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 4., 1., 4., 1., 3., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(1.7329, device='cuda:0') tensor([7.7909, 8.0697, 7.7636, 7.8436], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1590.7706, device='cuda:0') total reward  and actions tensor([2755., 1245.]) 47.56537705106642\n",
      "tensor(1590.7706, device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  4.0000,  1.0000,  2.0000,  1.0000,  4.0000,\n",
      "         1.0000,  9.0000,  1.0000, 10.0000,  0.9000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 4.0000, 0.2333, 1.0000, 3.0000, 0.2430, 1.0000, 4.0000,\n",
      "        0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.1458, device='cuda:0') tensor([9.1102, 9.0831, 9.0469, 9.0797], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1572.0939, device='cuda:0') total reward  and actions tensor([2722., 1278.]) 45.1871081985131\n",
      "tensor(1572.0939, device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 3.0000, 1.0000, 2.0000, 1.0000,\n",
      "        4.0000, 1.0000, 4.0000, 0.2916, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000,  5.0000,  1.0000,  2.0000,  1.0000,  2.0000,\n",
      "         1.0000,  1.0000,  1.0000, 10.0000,  0.5249,  1.0000,  3.0000,  0.2187,\n",
      "         1.0000, 10.0000,  0.6480,  1.0000,  3.0000,  0.2430,  1.0000,  3.0000,\n",
      "         0.2700,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0., device='cuda:0') tensor([8.2069, 8.1365, 8.1270, 8.1771], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1559.5598, device='cuda:0') total reward  and actions tensor([2711., 1289.]) 42.92775278858744\n",
      "tensor(1559.5598, device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 4.0000, 1.0000, 6.0000, 1.0000, 1.0000, 1.0000,\n",
      "        5.0000, 1.0000, 4.0000, 0.3240, 1.0000, 4.0000, 0.2592, 1.0000, 2.0000,\n",
      "        0.1440, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  5.0000,  1.0000,  7.0000,  1.0000,  4.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.5832,  1.0000,  4.0000,  0.2916,\n",
      "         1.0000,  4.0000,  0.2880,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1]) tensor(0.2624, device='cuda:0') tensor([7.3678, 7.4264, 7.3300, 7.3064], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1592.0984, device='cuda:0') total reward  and actions tensor([2786., 1214.]) 40.78136514915806\n",
      "tensor(1592.0984, device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 3.0000, 1.0000, 9.0000, 1.0000,\n",
      "        4.0000, 1.0000, 6.0000, 0.3937, 1.0000, 2.0000, 0.1166, 1.0000, 3.0000,\n",
      "        0.1944, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  4.0000,  1.0000,  2.0000,  1.0000,  1.0000,\n",
      "         1.0000,  6.0000,  1.0000, 10.0000,  0.6480,  1.0000,  6.0000,  0.4320,\n",
      "         1.0000,  3.0000,  0.2700,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0., device='cuda:0') tensor([8.0007, 7.9988, 7.9662, 7.9767], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1512.3051, device='cuda:0') total reward  and actions tensor([2667., 1333.]) 38.742296891700164\n",
      "tensor(1512.3051, device='cuda:0') tensor([1.0000, 9.0000, 1.0000, 6.0000, 1.0000, 6.0000, 1.0000, 2.0000, 1.0000,\n",
      "        9.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 2.0000, 1.0000, 7.0000, 1.0000, 3.0000, 1.0000,\n",
      "        3.0000, 1.0000, 2.0000, 0.1458, 1.0000, 3.0000, 0.2430, 1.0000, 2.0000,\n",
      "        0.1800, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.7171, device='cuda:0') tensor([7.5357, 7.5122, 7.4918, 7.4848], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1559.8578, device='cuda:0') total reward  and actions tensor([2768., 1232.]) 36.80518204711515\n",
      "tensor(1559.8578, device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000,  1.0000,  1.0000,  6.0000,  1.0000,  4.0000,\n",
      "         1.0000,  3.0000,  1.0000, 10.0000,  0.8100,  1.0000, 10.0000,  0.9000,\n",
      "         1.0000,  3.0000,  0.2160,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([0., 0., 1., 3., 1., 2., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0.2916, device='cuda:0') tensor([8.7802, 9.0034, 8.6350, 8.8593], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1603.7111, device='cuda:0') total reward  and actions tensor([2828., 1172.]) 34.964922944759394\n",
      "tensor(1603.7111, device='cuda:0') tensor([ 1.0000, 10.0000,  1.0000,  1.0000,  1.0000,  3.0000,  1.0000,  7.0000,\n",
      "         1.0000,  9.0000,  1.0000,  4.0000,  0.3600,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 5.0000, 1.0000, 2.0000, 1.0000, 3.0000, 1.0000,\n",
      "        6.0000, 1.0000, 6.0000, 0.3149, 1.0000, 2.0000, 0.1312, 1.0000, 4.0000,\n",
      "        0.2916, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1.0181, device='cuda:0') tensor([7.3758, 7.3556, 7.3109, 7.3072], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1612.0215, device='cuda:0') total reward  and actions tensor([2832., 1168.]) 33.21667679752143\n",
      "tensor(1612.0215, device='cuda:0') tensor([ 1.,  7.,  1.,  4.,  1.,  2.,  1., 10.,  1.,  5.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([1., 3., 1., 2., 1., 7., 1., 5., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1]) tensor(1.3000, device='cuda:0') tensor([8.3135, 8.1332, 8.0484, 8.1025], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1623.2853, device='cuda:0') total reward  and actions tensor([2863., 1137.]) 31.555842957645353\n",
      "tensor(1623.2853, device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  2.0000,  1.0000,  1.0000,  1.0000,  9.0000,\n",
      "         1.0000,  6.0000,  1.0000, 10.0000,  0.8100,  1.0000,  4.0000,  0.3600,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 8.0000, 1.0000, 5.0000, 1.0000, 1.0000, 1.0000, 4.0000, 1.0000,\n",
      "        1.0000, 1.0000, 3.0000, 0.2430, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.8100, device='cuda:0') tensor([8.2936, 8.2453, 8.2352, 8.2464], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1587.5670, device='cuda:0') total reward  and actions tensor([2854., 1146.]) 29.978050809763086\n",
      "tensor(1587.5670, device='cuda:0') tensor([1.0000, 6.0000, 1.0000, 1.0000, 1.0000, 5.0000, 1.0000, 3.0000, 1.0000,\n",
      "        2.0000, 1.0000, 4.0000, 0.3240, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  8.0000,  1.0000,  2.0000,  1.0000,  5.0000,  1.0000,  1.0000,\n",
      "         1.0000,  3.0000,  1.0000,  3.0000,  0.2187,  1.0000,  3.0000,  0.2430,\n",
      "         1.0000, 10.0000,  0.7200,  1.0000,  3.0000,  0.2700,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.2187, device='cuda:0') tensor([8.1971, 8.1223, 8.1078, 8.0875], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1598.7239, device='cuda:0') total reward  and actions tensor([2871., 1129.]) 28.47914826927493\n",
      "tensor(1598.7239, device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000,  3.0000,  1.0000, 10.0000,  1.0000,  1.0000,\n",
      "         1.0000,  3.0000,  1.0000,  4.0000,  0.3240,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  2.0000,  1.0000,  1.0000,  1.0000,  4.0000,\n",
      "         1.0000, 10.0000,  1.0000,  4.0000,  0.3600,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(2.2940, device='cuda:0') tensor([8.5510, 8.5223, 8.4160, 8.4943], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1592.0775, device='cuda:0') total reward  and actions tensor([2851., 1149.]) 27.05519085581118\n",
      "tensor(1592.0775, device='cuda:0') tensor([1.0000, 9.0000, 1.0000, 2.0000, 1.0000, 3.0000, 1.0000, 3.0000, 1.0000,\n",
      "        1.0000, 1.0000, 4.0000, 0.2592, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1., 1., 1., 3., 1., 1., 1., 3., 1., 5., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0.3000, device='cuda:0') tensor([8.8606, 8.8962, 8.7433, 8.7867], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1545.6720, device='cuda:0') total reward  and actions tensor([2801., 1199.]) 25.702431313020618\n",
      "tensor(1545.6720, device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 6.0000, 1.0000,\n",
      "        3.0000, 1.0000, 3.0000, 0.1575, 1.0000, 6.0000, 0.4860, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000,  3.0000,  1.0000,  2.0000,  1.0000,  6.0000,\n",
      "         1.0000,  5.0000,  1.0000,  3.0000,  0.2187,  1.0000,  3.0000,  0.2430,\n",
      "         1.0000, 10.0000,  0.7200,  1.0000,  2.0000,  0.1800,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.3937, device='cuda:0') tensor([8.5407, 8.4671, 8.4970, 8.3720], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1572.9291, device='cuda:0') total reward  and actions tensor([2828., 1172.]) 24.417309747369586\n",
      "tensor(1572.9291, device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  2.0000,  1.0000,  2.0000,  1.0000,  8.0000,\n",
      "         1.0000,  7.0000,  1.0000, 10.0000,  0.8100,  1.0000,  4.0000,  0.2880,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 5.0000, 1.0000, 5.0000, 1.0000, 3.0000, 1.0000, 4.0000, 1.0000,\n",
      "        1.0000, 1.0000, 6.0000, 0.4320, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(2, device='cuda:0') tensor(0.6030, device='cuda:0') tensor([7.7678, 7.7440, 7.7797, 7.6938], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1585.4297, device='cuda:0') total reward  and actions tensor([2921., 1079.]) 23.196444260001105\n",
      "tensor(1585.4297, device='cuda:0') tensor([1., 6., 1., 8., 1., 9., 1., 4., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1., 8., 1., 1., 1., 1., 1., 1., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0.7000, device='cuda:0') tensor([8.2004, 8.2915, 8.0094, 8.1838], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1619.5920, device='cuda:0') total reward  and actions tensor([2941., 1059.]) 22.03662204700105\n",
      "tensor(1619.5920, device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000,  1.0000,  1.0000,  7.0000,  1.0000,  7.0000,\n",
      "         1.0000,  2.0000,  1.0000,  4.0000,  0.1890,  1.0000,  4.0000,  0.2624,\n",
      "         1.0000,  4.0000,  0.2916,  1.0000,  3.0000,  0.1750,  1.0000, 10.0000,\n",
      "         0.8100,  1.0000,  4.0000,  0.3600], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 3.0000, 1.0000, 3.0000, 1.0000, 2.0000, 1.0000,\n",
      "        1.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0., device='cuda:0') tensor([8.1226, 8.0837, 8.0112, 8.0475], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1568.1863, device='cuda:0') total reward  and actions tensor([2903., 1097.]) 20.934790944650995\n",
      "tensor(1568.1863, device='cuda:0') tensor([ 1., 10.,  1.,  7.,  1.,  2.,  1.,  1.,  1.,  4.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  2.0000,  1.0000,  2.0000,\n",
      "         1.0000,  1.0000,  1.0000,  4.0000,  0.2333,  1.0000,  2.0000,  0.1458,\n",
      "         1.0000, 10.0000,  0.6480,  1.0000,  3.0000,  0.2430,  1.0000,  6.0000,\n",
      "         0.4320,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([2]) tensor(0.8935, device='cuda:0') tensor([8.6212, 8.6071, 8.6009, 8.5687], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1557.4462, device='cuda:0') total reward  and actions tensor([2831., 1169.]) 19.888051397418447\n",
      "tensor(1557.4462, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  2.0000,  1.0000,  2.0000,  1.0000,  4.0000,\n",
      "         1.0000,  7.0000,  1.0000, 10.0000,  0.4783,  1.0000,  3.0000,  0.1275,\n",
      "         1.0000,  4.0000,  0.2362,  1.0000,  4.0000,  0.1890,  1.0000,  6.0000,\n",
      "         0.4374,  1.0000,  3.0000,  0.1944], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 4.0000, 1.0000, 9.0000, 1.0000, 1.0000, 1.0000,\n",
      "        3.0000, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(2, device='cuda:0') tensor(0.3200, device='cuda:0') tensor([7.6964, 7.7170, 7.7550, 7.6247], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1571.6366, device='cuda:0') total reward  and actions tensor([2906., 1094.]) 18.893648827547523\n",
      "tensor(1571.6366, device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  1.0000,  1.0000,  3.0000,  1.0000,  4.0000,\n",
      "         1.0000,  6.0000,  1.0000, 10.0000,  0.9000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.0000, 10.0000,  1.0000,  7.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "         1.0000,  2.0000,  1.0000,  2.0000,  0.1620,  1.0000,  3.0000,  0.2700,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1.3005, device='cuda:0') tensor([8.5160, 8.5141, 8.4822, 8.4986], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1621.8026, device='cuda:0') total reward  and actions tensor([3008.,  992.]) 17.94896638617015\n",
      "tensor(1621.8026, device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  3.0000,  1.0000,  3.0000,  1.0000,  4.0000,\n",
      "         1.0000,  5.0000,  1.0000,  4.0000,  0.2126,  1.0000,  6.0000,  0.3543,\n",
      "         1.0000,  4.0000,  0.2100,  1.0000,  6.0000,  0.4374,  1.0000, 10.0000,\n",
      "         0.9000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 1., 1., 5., 1., 1., 1., 3., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(2, device='cuda:0') tensor(0.3000, device='cuda:0') tensor([7.8489, 7.8583, 7.8698, 7.8071], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1643.5234, device='cuda:0') total reward  and actions tensor([3059.,  941.]) 17.05151806686164\n",
      "tensor(1643.5234, device='cuda:0') tensor([ 1.0000,  8.0000,  1.0000,  2.0000,  1.0000,  5.0000,  1.0000,  6.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.7290,  1.0000,  6.0000,  0.4860,\n",
      "         1.0000,  6.0000,  0.5400,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 6.0000, 1.0000, 2.0000, 1.0000,\n",
      "        4.0000, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.8919, device='cuda:0') tensor([7.8371, 7.8288, 7.7652, 7.8117], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1606.2220, device='cuda:0') total reward  and actions tensor([2947., 1053.]) 16.198942163518556\n",
      "tensor(1606.2220, device='cuda:0') tensor([1.0000, 8.0000, 1.0000, 8.0000, 1.0000, 1.0000, 1.0000, 4.0000, 1.0000,\n",
      "        4.0000, 1.0000, 3.0000, 0.1944, 1.0000, 6.0000, 0.5400, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 3.0000, 1.0000, 4.0000, 1.0000, 4.0000, 1.0000,\n",
      "        1.0000, 1.0000, 6.0000, 0.3888, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(2, device='cuda:0') tensor(0.5832, device='cuda:0') tensor([8.0207, 8.0459, 8.0879, 7.9353], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1619.7941, device='cuda:0') total reward  and actions tensor([3036.,  964.]) 15.388995055342628\n",
      "tensor(1619.7941, device='cuda:0') tensor([ 1.0000,  5.0000,  1.0000,  5.0000,  1.0000,  2.0000,  1.0000,  8.0000,\n",
      "         1.0000,  8.0000,  1.0000, 10.0000,  0.9000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000,\n",
      "        7.0000, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([0]) tensor(0., device='cuda:0') tensor([8.2454, 8.2804, 8.1576, 8.2352], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1573.5178, device='cuda:0') total reward  and actions tensor([2983., 1017.]) 14.619545302575496\n",
      "tensor(1573.5178, device='cuda:0') tensor([1., 4., 1., 2., 1., 3., 1., 9., 1., 5., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 5.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000,\n",
      "        2.0000, 1.0000, 6.0000, 0.2834, 1.0000, 6.0000, 0.3149, 1.0000, 4.0000,\n",
      "        0.3240, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(2, device='cuda:0') tensor(0.4000, device='cuda:0') tensor([8.2515, 8.1520, 8.2528, 8.1831], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1612.1935, device='cuda:0') total reward  and actions tensor([2976., 1024.]) 13.888568037446719\n",
      "tensor(1612.1935, device='cuda:0') tensor([1., 2., 1., 1., 1., 9., 1., 6., 1., 9., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  5.0000,  1.0000, 10.0000,  1.0000,  3.0000,  1.0000,  6.0000,\n",
      "         1.0000,  3.0000,  1.0000,  2.0000,  0.1458,  1.0000,  2.0000,  0.1620,\n",
      "         1.0000,  2.0000,  0.1800,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1.1832, device='cuda:0') tensor([7.5014, 7.5058, 7.5058, 7.4655], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1642.1733, device='cuda:0') total reward  and actions tensor([3046.,  954.]) 13.19413963557438\n",
      "tensor(1642.1733, device='cuda:0') tensor([1., 1., 1., 2., 1., 9., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1., 1., 1., 4., 1., 2., 1., 1., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(1.1600, device='cuda:0') tensor([8.7222, 8.8334, 8.8135, 8.8132], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1646.0128, device='cuda:0') total reward  and actions tensor([3070.,  930.]) 12.53443265379566\n",
      "tensor(1646.0128, device='cuda:0') tensor([1., 1., 1., 8., 1., 4., 1., 8., 1., 8., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 4.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000,\n",
      "        3.0000, 1.0000, 2.0000, 0.1800, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.8680, device='cuda:0') tensor([8.4742, 8.4235, 8.3946, 8.4209], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1620.5829, device='cuda:0') total reward  and actions tensor([3031.,  969.]) 11.907711021105877\n",
      "tensor(1620.5829, device='cuda:0') tensor([1.0000, 6.0000, 1.0000, 5.0000, 1.0000, 1.0000, 1.0000, 8.0000, 1.0000,\n",
      "        8.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 4.0000, 1.0000, 2.0000, 1.0000, 2.0000, 1.0000,\n",
      "        7.0000, 1.0000, 2.0000, 0.1800, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0.3600, device='cuda:0') tensor([8.1560, 8.1616, 8.0653, 8.1192], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1657.6294, device='cuda:0') total reward  and actions tensor([3083.,  917.]) 11.312325470050583\n",
      "tensor(1657.6294, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  3.0000,  1.0000,  1.0000,  1.0000,  8.0000,\n",
      "         1.0000,  2.0000,  1.0000,  4.0000,  0.2362,  1.0000, 10.0000,  0.6561,\n",
      "         1.0000, 10.0000,  0.7290,  1.0000, 10.0000,  0.9000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000,\n",
      "        3.0000, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(3, device='cuda:0') tensor(0.5580, device='cuda:0') tensor([8.5233, 8.5237, 8.4791, 8.5476], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1597.1052, device='cuda:0') total reward  and actions tensor([3072.,  928.]) 10.746709196548053\n",
      "tensor(1597.1052, device='cuda:0') tensor([1.0000, 9.0000, 1.0000, 3.0000, 1.0000, 2.0000, 1.0000, 2.0000, 1.0000,\n",
      "        4.0000, 1.0000, 4.0000, 0.2916, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  2.0000,  1.0000,  1.0000,  1.0000,  2.0000,\n",
      "         1.0000,  5.0000,  1.0000, 10.0000,  0.7200,  1.0000,  2.0000,  0.1800,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.1800, device='cuda:0') tensor([8.8549, 8.7989, 8.8047, 8.8191], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1633.2394, device='cuda:0') total reward  and actions tensor([3055.,  945.]) 10.20937373672065\n",
      "tensor(1633.2394, device='cuda:0') tensor([ 1.,  1.,  1.,  8.,  1., 10.,  1.,  9.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([1., 3., 1., 5., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(1.3000, device='cuda:0') tensor([8.7085, 8.6213, 8.6290, 8.6073], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1613.1532, device='cuda:0') total reward  and actions tensor([3008.,  992.]) 9.698905049884617\n",
      "tensor(1613.1532, device='cuda:0') tensor([1., 9., 1., 2., 1., 2., 1., 6., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000,  5.0000,  1.0000, 10.0000,  1.0000,  3.0000,\n",
      "         1.0000,  2.0000,  1.0000,  4.0000,  0.2916,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1.4890, device='cuda:0') tensor([8.2665, 8.1815, 8.2280, 8.1661], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1634.4004, device='cuda:0') total reward  and actions tensor([3096.,  904.]) 9.213959797390386\n",
      "tensor(1634.4004, device='cuda:0') tensor([1.0000, 8.0000, 1.0000, 2.0000, 1.0000, 3.0000, 1.0000, 4.0000, 1.0000,\n",
      "        2.0000, 1.0000, 2.0000, 0.1296, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 9.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 8.0000, 1.0000,\n",
      "        1.0000, 1.0000, 4.0000, 0.2624, 1.0000, 3.0000, 0.2187, 1.0000, 6.0000,\n",
      "        0.4320, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.3600, device='cuda:0') tensor([7.9924, 7.9449, 7.9546, 7.9833], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1619.3728, device='cuda:0') total reward  and actions tensor([3092.,  908.]) 8.753261807520866\n",
      "tensor(1619.3728, device='cuda:0') tensor([ 1.,  4.,  1., 10.,  1.,  1.,  1.,  4.,  1.,  3.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 7.0000, 1.0000, 4.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 3.0000, 0.2430, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1.3000, device='cuda:0') tensor([8.9093, 8.8691, 8.8288, 8.8415], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1611.1381, device='cuda:0') total reward  and actions tensor([3038.,  962.]) 8.315598717144823\n",
      "tensor(1611.1381, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  2.0000,  1.0000, 10.0000,  1.0000,  5.0000,\n",
      "         1.0000,  3.0000,  1.0000,  6.0000,  0.3543,  1.0000,  4.0000,  0.1890,\n",
      "         1.0000,  6.0000,  0.5400,  1.0000,  4.0000,  0.2880,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 3.0000, 1.0000, 8.0000, 1.0000, 5.0000, 1.0000,\n",
      "        1.0000, 1.0000, 3.0000, 0.2430, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0.7322, device='cuda:0') tensor([7.5391, 7.5568, 7.5232, 7.5351], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1656.1970, device='cuda:0') total reward  and actions tensor([3188.,  812.]) 7.899818781287582\n",
      "tensor(1656.1970, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  7.0000,  1.0000,  3.0000,  1.0000,  8.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.7290,  1.0000, 10.0000,  0.8100,\n",
      "         1.0000,  6.0000,  0.5400,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 3., 1., 4., 1., 3., 1., 2., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0.6700, device='cuda:0') tensor([7.9146, 7.9726, 7.7953, 7.8256], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1649.6201, device='cuda:0') total reward  and actions tensor([3062.,  938.]) 7.504827842223202\n",
      "tensor(1649.6201, device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  2.0000,  1.0000,  7.0000,  1.0000,  1.0000,\n",
      "         1.0000,  2.0000,  1.0000,  4.0000,  0.2916,  1.0000, 10.0000,  0.9000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 3.0000, 1.0000, 9.0000, 1.0000, 1.0000, 1.0000,\n",
      "        3.0000, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0., device='cuda:0') tensor([8.5188, 8.4769, 8.4196, 8.4165], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1621.0714, device='cuda:0') total reward  and actions tensor([3007.,  993.]) 7.1295864501120425\n",
      "tensor(1621.0714, device='cuda:0') tensor([ 1.,  3.,  1.,  2.,  1.,  4.,  1., 10.,  1.,  2.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([1., 4., 1., 8., 1., 2., 1., 3., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(1.5200, device='cuda:0') tensor([8.6397, 8.5786, 8.5792, 8.5922], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1653.7812, device='cuda:0') total reward  and actions tensor([3066.,  934.]) 6.77310712760644\n",
      "tensor(1653.7812, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  3.0000,  1.0000,  1.0000,  1.0000,  2.0000,\n",
      "         1.0000,  1.0000,  1.0000,  4.0000,  0.2624,  1.0000, 10.0000,  0.7290,\n",
      "         1.0000,  6.0000,  0.5400,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 4.0000, 1.0000, 2.0000, 1.0000, 4.0000, 1.0000,\n",
      "        1.0000, 1.0000, 2.0000, 0.1620, 1.0000, 2.0000, 0.1800, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.5310, device='cuda:0') tensor([9.2175, 9.2012, 9.1982, 9.1383], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1622.8766, device='cuda:0') total reward  and actions tensor([2989., 1011.]) 6.434451771226117\n",
      "tensor(1622.8766, device='cuda:0') tensor([1., 1., 1., 7., 1., 3., 1., 9., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 4.0000, 1.0000,\n",
      "        5.0000, 1.0000, 4.0000, 0.3240, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.7807, device='cuda:0') tensor([8.6548, 8.4830, 8.6362, 8.5353], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1648.8929, device='cuda:0') total reward  and actions tensor([2983., 1017.]) 6.112729182664811\n",
      "tensor(1648.8929, device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 4.0000, 1.0000, 9.0000, 1.0000,\n",
      "        5.0000, 1.0000, 4.0000, 0.2126, 1.0000, 4.0000, 0.2362, 1.0000, 4.0000,\n",
      "        0.2624, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000, 10.0000,  1.0000,  2.0000,  1.0000,  2.0000,\n",
      "         1.0000,  9.0000,  1.0000,  3.0000,  0.2700,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1.0565, device='cuda:0') tensor([7.5680, 7.5857, 7.4656, 7.5132], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1615.8757, device='cuda:0') total reward  and actions tensor([2984., 1016.]) 5.807092723531571\n",
      "tensor(1615.8757, device='cuda:0') tensor([ 1.,  4.,  1.,  4.,  1.,  9.,  1.,  2.,  1., 10.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 6.0000, 1.0000, 2.0000, 1.0000, 3.0000, 1.0000,\n",
      "        2.0000, 1.0000, 6.0000, 0.3888, 1.0000, 3.0000, 0.2430, 1.0000, 2.0000,\n",
      "        0.1800, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1.6318, device='cuda:0') tensor([7.9682, 7.9882, 7.9474, 7.8964], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1620.7261, device='cuda:0') total reward  and actions tensor([2976., 1024.]) 5.516738087354992\n",
      "tensor(1620.7261, device='cuda:0') tensor([1., 2., 1., 3., 1., 3., 1., 4., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 6.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000,\n",
      "        1.0000, 1.0000, 6.0000, 0.4320, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.8520, device='cuda:0') tensor([9.3446, 9.3058, 9.2835, 9.3422], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1626.8281, device='cuda:0') total reward  and actions tensor([3025.,  975.]) 5.240901182987242\n",
      "tensor(1626.8281, device='cuda:0') tensor([ 1.,  3.,  1.,  5.,  1.,  9.,  1., 10.,  1.,  8.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 2.0000, 1.0000,\n",
      "        2.0000, 1.0000, 4.0000, 0.2624, 1.0000, 2.0000, 0.1458, 1.0000, 4.0000,\n",
      "        0.2592, 1.0000, 2.0000, 0.1620, 1.0000, 2.0000, 0.1800, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1.1312, device='cuda:0') tensor([7.6629, 7.6377, 7.6359, 7.6521], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1658.8784, device='cuda:0') total reward  and actions tensor([3112.,  888.]) 4.97885612383788\n",
      "tensor(1658.8784, device='cuda:0') tensor([ 1.,  7.,  1., 10.,  1.,  1.,  1.,  5.,  1.,  1.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  2.0000,  1.0000,  3.0000,  1.0000,  4.0000,\n",
      "         1.0000,  9.0000,  1.0000,  3.0000,  0.1968,  1.0000,  3.0000,  0.2187,\n",
      "         1.0000,  3.0000,  0.2430,  1.0000, 10.0000,  0.7200,  1.0000,  4.0000,\n",
      "         0.3600,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.9000, device='cuda:0') tensor([7.8392, 7.7668, 7.7707, 7.8113], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1645.5146, device='cuda:0') total reward  and actions tensor([3088.,  912.]) 4.729913317645986\n",
      "tensor(1645.5146, device='cuda:0') tensor([1., 4., 0., 0., 1., 5., 1., 7., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1., 1., 1., 1., 1., 3., 1., 2., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(0.7000, device='cuda:0') tensor([8.9250, 8.8959, 8.8659, 8.9245], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1637.0320, device='cuda:0') total reward  and actions tensor([2945., 1055.]) 4.493417651763686\n",
      "tensor(1637.0320, device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  3.0000,\n",
      "         1.0000,  1.0000,  1.0000, 10.0000,  0.7290,  1.0000,  4.0000,  0.3240,\n",
      "         1.0000, 10.0000,  0.9000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  2.0000,  1.0000,  3.0000,  1.0000,  4.0000,\n",
      "         1.0000, 10.0000,  1.0000,  4.0000,  0.2916,  1.0000,  3.0000,  0.2430,\n",
      "         1.0000,  3.0000,  0.2700,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.5832, device='cuda:0') tensor([8.3759, 8.3608, 8.2692, 8.3130], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1605.6232, device='cuda:0') total reward  and actions tensor([2941., 1059.]) 4.268746769175501\n",
      "tensor(1605.6232, device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 6.0000, 1.0000, 2.0000, 1.0000, 5.0000, 1.0000,\n",
      "        7.0000, 1.0000, 4.0000, 0.3240, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000, 10.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "         1.0000,  3.0000,  1.0000,  2.0000,  0.1800,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1.5560, device='cuda:0') tensor([8.6393, 8.6373, 8.5301, 8.6064], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1667.2167, device='cuda:0') total reward  and actions tensor([3037.,  963.]) 4.055309430716727\n",
      "tensor(1667.2167, device='cuda:0') tensor([ 1.0000,  5.0000,  1.0000,  2.0000,  1.0000,  1.0000,  1.0000,  6.0000,\n",
      "         1.0000,  4.0000,  1.0000, 10.0000,  0.7290,  1.0000,  4.0000,  0.3240,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "         1.0000,  3.0000,  1.0000, 10.0000,  0.7200,  1.0000,  3.0000,  0.2700,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0., device='cuda:0') tensor([8.8991, 8.9008, 8.7100, 8.7697], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1607.8784, device='cuda:0') total reward  and actions tensor([3032.,  968.]) 3.8525439591808897\n",
      "tensor(1607.8784, device='cuda:0') tensor([1., 3., 1., 5., 1., 2., 1., 2., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  2.0000,  1.0000,  2.0000,  1.0000,  1.0000,\n",
      "         1.0000,  1.0000,  1.0000, 10.0000,  0.7200,  1.0000,  3.0000,  0.2700,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0., device='cuda:0') tensor([9.5000, 9.4239, 9.4956, 9.4818], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1646.4738, device='cuda:0') total reward  and actions tensor([3075.,  925.]) 3.659916761221845\n",
      "tensor(1646.4738, device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 1.0000, 1.0000, 3.0000, 1.0000, 3.0000, 1.0000,\n",
      "        4.0000, 1.0000, 6.0000, 0.5400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 6.0000, 1.0000, 4.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000,\n",
      "        3.0000, 1.0000, 2.0000, 0.1800, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.6300, device='cuda:0') tensor([9.0295, 8.9500, 8.9665, 8.9715], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1617.8169, device='cuda:0') total reward  and actions tensor([3019.,  981.]) 3.4769209231607525\n",
      "tensor(1617.8169, device='cuda:0') tensor([ 1., 10.,  1.,  9.,  1.,  4.,  1.,  9.,  1.,  1.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  3.0000,  1.0000, 10.0000,  1.0000,  2.0000,\n",
      "         1.0000,  2.0000,  1.0000,  4.0000,  0.2916,  1.0000,  3.0000,  0.2430,\n",
      "         1.0000,  4.0000,  0.3600,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1.6480, device='cuda:0') tensor([7.7734, 7.7727, 7.7656, 7.7094], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1653.5687, device='cuda:0') total reward  and actions tensor([3115.,  885.]) 3.3030748770027154\n",
      "tensor(1653.5687, device='cuda:0') tensor([1., 6., 1., 3., 0., 0., 1., 3., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1., 6., 1., 2., 1., 3., 1., 1., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(0.8000, device='cuda:0') tensor([9.1011, 9.0469, 9.0881, 9.0324], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1624.4502, device='cuda:0') total reward  and actions tensor([3162.,  838.]) 3.137921133152579\n",
      "tensor(1624.4502, device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 7.0000, 1.0000, 4.0000, 1.0000,\n",
      "        5.0000, 1.0000, 4.0000, 0.2916, 1.0000, 3.0000, 0.2160, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000,\n",
      "        1.0000, 1.0000, 6.0000, 0.3888, 1.0000, 2.0000, 0.1620, 1.0000, 4.0000,\n",
      "        0.2880, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0., device='cuda:0') tensor([8.7104, 8.6862, 8.6580, 8.6899], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1631.7181, device='cuda:0') total reward  and actions tensor([3068.,  932.]) 2.9810250764949497\n",
      "tensor(1631.7181, device='cuda:0') tensor([1., 8., 1., 7., 1., 1., 1., 4., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.,  2.,  1.,  2.,  1., 10.,  1.,  3.,  1.,  4.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor(0, device='cuda:0') tensor(1.5600, device='cuda:0') tensor([8.5614, 8.4250, 8.4469, 8.4451], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1676.8611, device='cuda:0') total reward  and actions tensor([3085.,  915.]) 2.8319738226702023\n",
      "tensor(1676.8611, device='cuda:0') tensor([1., 2., 1., 5., 1., 9., 1., 4., 1., 7., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1., 3., 1., 1., 1., 2., 1., 1., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0.8000, device='cuda:0') tensor([8.7776, 8.8151, 8.6282, 8.7095], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1669.1268, device='cuda:0') total reward  and actions tensor([3155.,  845.]) 2.690375131536692\n",
      "tensor(1669.1268, device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  1.0000,  1.0000,  4.0000,  1.0000,  1.0000,\n",
      "         1.0000,  1.0000,  1.0000, 10.0000,  0.8100,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 1.0000, 1.0000, 6.0000, 1.0000, 3.0000, 1.0000,\n",
      "        1.0000, 1.0000, 2.0000, 0.1800, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.4800, device='cuda:0') tensor([9.4753, 9.3871, 9.4030, 9.3568], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1605.8878, device='cuda:0') total reward  and actions tensor([3225.,  775.]) 2.5558563749598573\n",
      "tensor(1605.8878, device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 9.0000, 1.0000, 6.0000, 1.0000, 5.0000, 1.0000,\n",
      "        9.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 6.0000, 1.0000, 3.0000, 1.0000, 2.0000, 1.0000, 2.0000, 1.0000,\n",
      "        1.0000, 1.0000, 2.0000, 0.1800, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1.1880, device='cuda:0') tensor([7.8298, 7.8546, 7.7443, 7.7518], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1636.6703, device='cuda:0') total reward  and actions tensor([3225.,  775.]) 2.4280635562118644\n",
      "tensor(1636.6703, device='cuda:0') tensor([ 1.0000,  5.0000,  1.0000,  1.0000,  1.0000,  2.0000,  1.0000,  3.0000,\n",
      "         1.0000,  9.0000,  1.0000, 10.0000,  0.9000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000, 10.0000,  1.0000,  5.0000,  1.0000,  1.0000,\n",
      "         1.0000,  1.0000,  1.0000,  3.0000,  0.1968,  1.0000,  4.0000,  0.2916,\n",
      "         1.0000,  6.0000,  0.3888,  1.0000,  4.0000,  0.3600,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.5832, device='cuda:0') tensor([7.8093, 7.7845, 7.7463, 7.7635], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1649.3864, device='cuda:0') total reward  and actions tensor([3208.,  792.]) 2.306660378401271\n",
      "tensor(1649.3864, device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 3.0000, 1.0000, 1.0000, 1.0000, 6.0000, 1.0000,\n",
      "        3.0000, 1.0000, 6.0000, 0.4374, 1.0000, 4.0000, 0.2333, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000, 10.0000,  1.0000,  4.0000,  1.0000,  5.0000,\n",
      "         1.0000,  3.0000,  1.0000,  4.0000,  0.2880,  1.0000,  3.0000,  0.2700,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(2, device='cuda:0') tensor(1.0800, device='cuda:0') tensor([7.9081, 7.9114, 7.9123, 7.8937], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1619.0745, device='cuda:0') total reward  and actions tensor([3128.,  872.]) 2.1913273594812077\n",
      "tensor(1619.0745, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  3.0000,  1.0000,  4.0000,  1.0000, 10.0000,\n",
      "         1.0000,  1.0000,  1.0000,  6.0000,  0.5400,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 9.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 7.0000, 1.0000,\n",
      "        3.0000, 1.0000, 2.0000, 0.1181, 1.0000, 3.0000, 0.2187, 1.0000, 2.0000,\n",
      "        0.1620, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.9000, device='cuda:0') tensor([7.9895, 7.8454, 7.9158, 7.8773], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1632.1221, device='cuda:0') total reward  and actions tensor([3227.,  773.]) 2.081760991507147\n",
      "tensor(1632.1221, device='cuda:0') tensor([1., 4., 1., 5., 1., 1., 1., 6., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1., 5., 1., 1., 1., 4., 0., 0., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0.6400, device='cuda:0') tensor([8.9695, 8.9717, 8.8983, 8.9646], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1678.8361, device='cuda:0') total reward  and actions tensor([3259.,  741.]) 1.9776729419317896\n",
      "tensor(1678.8361, device='cuda:0') tensor([0., 0., 1., 6., 1., 9., 1., 7., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1., 1., 1., 2., 1., 4., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(0.6200, device='cuda:0') tensor([8.7506, 8.7229, 8.5910, 8.6756], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1646.5936, device='cuda:0') total reward  and actions tensor([3203.,  797.]) 1.8787892948352\n",
      "tensor(1646.5936, device='cuda:0') tensor([1., 7., 1., 6., 1., 4., 0., 0., 1., 5., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 5.0000, 1.0000, 1.0000, 1.0000, 8.0000, 1.0000, 1.0000, 1.0000,\n",
      "        2.0000, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0.4000, device='cuda:0') tensor([9.0991, 9.1446, 9.0643, 9.1062], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1633.0729, device='cuda:0') total reward  and actions tensor([3253.,  747.]) 1.78484983009344\n",
      "tensor(1633.0729, device='cuda:0') tensor([ 1.,  3.,  1., 10.,  1.,  5.,  1.,  8.,  1.,  5.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([1., 2., 1., 1., 1., 2., 1., 5., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(1.2000, device='cuda:0') tensor([8.2945, 8.3829, 8.1212, 8.2800], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1427.7262, device='cuda:0') total reward  and actions tensor([2711., 1289.]) 1.6956073385887678\n",
      "tensor(1427.7262, device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000,  4.0000,  1.0000,  2.0000,  1.0000,  3.0000,\n",
      "         1.0000, 10.0000,  1.0000,  6.0000,  0.3543,  1.0000,  6.0000,  0.4374,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 4.0000, 1.0000, 3.0000, 1.0000,\n",
      "        2.0000, 1.0000, 3.0000, 0.1968, 1.0000, 2.0000, 0.1458, 1.0000, 4.0000,\n",
      "        0.2592, 1.0000, 3.0000, 0.2430, 1.0000, 4.0000, 0.2880, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0.8363, device='cuda:0') tensor([9.0264, 9.1132, 9.0183, 9.0920], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1475.4966, device='cuda:0') total reward  and actions tensor([2390., 1610.]) 1.6108269716593293\n",
      "tensor(1475.4966, device='cuda:0') tensor([1.0000, 7.0000, 1.0000, 6.0000, 1.0000, 3.0000, 1.0000, 8.0000, 1.0000,\n",
      "        1.0000, 1.0000, 2.0000, 0.1440, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1., 2., 0., 0., 1., 3., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0.6000, device='cuda:0') tensor([9.1567, 9.1981, 9.1119, 9.1064], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1483.9088, device='cuda:0') total reward  and actions tensor([2480., 1520.]) 1.5302856230763626\n",
      "tensor(1483.9088, device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 7.0000, 1.0000, 4.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 2.0000, 0.1166, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000,\n",
      "        9.0000, 1.0000, 4.0000, 0.2880, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.5040, device='cuda:0') tensor([9.2194, 9.1595, 9.1536, 9.1709], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1535.4152, device='cuda:0') total reward  and actions tensor([2753., 1247.]) 1.4537713419225444\n",
      "tensor(1535.4152, device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 8.0000, 1.0000, 8.0000, 1.0000, 3.0000, 1.0000,\n",
      "        3.0000, 1.0000, 4.0000, 0.2333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  3.0000,  1.0000, 10.0000,  1.0000,  5.0000,\n",
      "         1.0000,  1.0000,  1.0000,  4.0000,  0.3600,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1.3580, device='cuda:0') tensor([8.9105, 8.8758, 8.8113, 8.9012], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1558.6331, device='cuda:0') total reward  and actions tensor([2775., 1225.]) 1.3810827748264172\n",
      "tensor(1558.6331, device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 1.0000, 1.0000, 4.0000, 1.0000, 3.0000, 1.0000,\n",
      "        1.0000, 1.0000, 2.0000, 0.1050, 1.0000, 4.0000, 0.2333, 1.0000, 3.0000,\n",
      "        0.1944, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 5.0000, 1.0000, 3.0000, 1.0000, 3.0000, 1.0000, 1.0000, 1.0000,\n",
      "        4.0000, 1.0000, 4.0000, 0.2592, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.4692, device='cuda:0') tensor([9.0443, 8.9821, 8.9795, 8.9185], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1551.0466, device='cuda:0') total reward  and actions tensor([2789., 1211.]) 1.3120286360850963\n",
      "tensor(1551.0466, device='cuda:0') tensor([ 1.0000,  6.0000,  1.0000,  4.0000,  1.0000,  1.0000,  1.0000,  4.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.9000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  2.0000,  1.0000,  2.0000,  1.0000,  1.0000,\n",
      "         1.0000,  3.0000,  1.0000, 10.0000,  0.6480,  1.0000,  4.0000,  0.3600,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0.2430, device='cuda:0') tensor([8.7042, 8.7179, 8.5332, 8.6109], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1594.9529, device='cuda:0') total reward  and actions tensor([2852., 1148.]) 1.2464272042808415\n",
      "tensor(1594.9529, device='cuda:0') tensor([1.0000, 7.0000, 1.0000, 2.0000, 1.0000, 9.0000, 1.0000, 1.0000, 1.0000,\n",
      "        4.0000, 1.0000, 4.0000, 0.3240, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  7.0000,  1.0000,  4.0000,  1.0000,  2.0000,\n",
      "         1.0000,  1.0000,  1.0000, 10.0000,  0.7200,  1.0000,  2.0000,  0.1800,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.8460, device='cuda:0') tensor([8.1181, 8.0858, 8.0812, 8.0725], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1625.1554, device='cuda:0') total reward  and actions tensor([3100.,  900.]) 1.1841058440667993\n",
      "tensor(1625.1554, device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  5.0000,  1.0000,  2.0000,  1.0000,  1.0000,\n",
      "         1.0000,  1.0000,  1.0000, 10.0000,  0.7290,  1.0000,  4.0000,  0.3240,\n",
      "         1.0000, 10.0000,  0.9000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 1., 1., 3., 1., 1., 1., 7., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0.5700, device='cuda:0') tensor([8.6552, 8.7183, 8.4690, 8.6128], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1576.6890, device='cuda:0') total reward  and actions tensor([3010.,  990.]) 1.1249005518634594\n",
      "tensor(1576.6890, device='cuda:0') tensor([1., 2., 1., 4., 1., 4., 1., 3., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 4.0000, 1.0000, 1.0000, 1.0000, 7.0000, 1.0000,\n",
      "        1.0000, 1.0000, 2.0000, 0.1620, 1.0000, 4.0000, 0.2880, 1.0000, 3.0000,\n",
      "        0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.3600, device='cuda:0') tensor([9.1734, 9.1330, 9.0951, 9.0744], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1584.5039, device='cuda:0') total reward  and actions tensor([2964., 1036.]) 1.0686555242702864\n",
      "tensor(1584.5039, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  6.0000,  1.0000,  3.0000,  1.0000,  6.0000,\n",
      "         1.0000,  8.0000,  1.0000, 10.0000,  0.8100,  1.0000,  6.0000,  0.5400,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 6.0000, 1.0000, 1.0000, 1.0000, 4.0000, 1.0000,\n",
      "        2.0000, 1.0000, 3.0000, 0.2430, 1.0000, 2.0000, 0.1800, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.4860, device='cuda:0') tensor([7.9496, 7.9395, 7.8766, 7.9111], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1634.5656, device='cuda:0') total reward  and actions tensor([3037.,  963.]) 1.015222748056772\n",
      "tensor(1634.5656, device='cuda:0') tensor([ 1.0000, 10.0000,  1.0000,  3.0000,  1.0000, 10.0000,  1.0000,  2.0000,\n",
      "         1.0000,  4.0000,  1.0000,  6.0000,  0.5400,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 7.0000, 1.0000, 6.0000, 1.0000, 2.0000, 1.0000,\n",
      "        2.0000, 1.0000, 3.0000, 0.1771, 1.0000, 4.0000, 0.2624, 1.0000, 2.0000,\n",
      "        0.1458, 1.0000, 2.0000, 0.1800, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(2.1115, device='cuda:0') tensor([7.4944, 7.4614, 7.3925, 7.4257], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1626.1013, device='cuda:0') total reward  and actions tensor([3043.,  957.]) 0.9644616106539333\n",
      "tensor(1626.1013, device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  3.0000,  1.0000,  1.0000,  1.0000,  4.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.8100,  1.0000, 10.0000,  0.9000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 5.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 4.0000, 0.3240, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.1620, device='cuda:0') tensor([9.2005, 9.1654, 9.1136, 9.1628], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1638.2471, device='cuda:0') total reward  and actions tensor([3049.,  951.]) 0.9162385301212366\n",
      "tensor(1638.2471, device='cuda:0') tensor([ 1.0000,  6.0000,  1.0000,  5.0000,  1.0000,  2.0000,  1.0000,  2.0000,\n",
      "         1.0000,  8.0000,  1.0000, 10.0000,  0.8100,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 3.0000, 1.0000, 3.0000, 1.0000, 6.0000, 1.0000,\n",
      "        5.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1.4304, device='cuda:0') tensor([8.3094, 8.3102, 8.2731, 8.2489], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1600.9087, device='cuda:0') total reward  and actions tensor([3114.,  886.]) 0.8704266036151747\n",
      "tensor(1600.9087, device='cuda:0') tensor([1., 2., 1., 8., 1., 5., 1., 1., 1., 6., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  3.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "         1.0000, 10.0000,  1.0000,  3.0000,  0.2700,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1.3400, device='cuda:0') tensor([8.7142, 8.6758, 8.5651, 8.5982], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1676.0610, device='cuda:0') total reward  and actions tensor([3310.,  690.]) 0.8269052734344159\n",
      "tensor(1676.0610, device='cuda:0') tensor([1., 4., 1., 1., 1., 1., 1., 5., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1., 2., 1., 2., 1., 2., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(0.6000, device='cuda:0') tensor([8.1101, 8.0248, 8.0832, 8.0597], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1551.1289, device='cuda:0') total reward  and actions tensor([3174.,  826.]) 0.785560009762695\n",
      "tensor(1551.1289, device='cuda:0') tensor([1., 6., 1., 4., 1., 5., 1., 3., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1., 6., 1., 2., 1., 2., 1., 1., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0.8000, device='cuda:0') tensor([8.7120, 8.7151, 8.5713, 8.6611], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1634.5673, device='cuda:0') total reward  and actions tensor([3258.,  742.]) 0.7462820092745603\n",
      "tensor(1634.5673, device='cuda:0') tensor([ 1.0000, 10.0000,  1.0000,  3.0000,  1.0000,  2.0000,  1.0000,  6.0000,\n",
      "         1.0000,  1.0000,  1.0000,  4.0000,  0.3600,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 3., 1., 1., 1., 2., 1., 2., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(1.4700, device='cuda:0') tensor([8.8621, 8.8603, 8.7372, 8.8066], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1645.2791, device='cuda:0') total reward  and actions tensor([3214.,  786.]) 0.7089679088108323\n",
      "tensor(1645.2791, device='cuda:0') tensor([1.0000, 6.0000, 1.0000, 6.0000, 1.0000, 1.0000, 1.0000, 3.0000, 1.0000,\n",
      "        2.0000, 1.0000, 6.0000, 0.5400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1., 2., 1., 9., 1., 4., 1., 3., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(1.0974, device='cuda:0') tensor([8.5757, 8.5830, 8.4300, 8.5439], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1600.2833, device='cuda:0') total reward  and actions tensor([3150.,  850.]) 0.6735195133702906\n",
      "tensor(1600.2833, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  6.0000,  1.0000,  3.0000,  1.0000, 10.0000,\n",
      "         1.0000,  1.0000,  1.0000,  4.0000,  0.3600,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 3.0000, 1.0000, 3.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1.6560, device='cuda:0') tensor([9.1059, 9.0733, 9.0536, 9.0791], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1650.0990, device='cuda:0') total reward  and actions tensor([3176.,  824.]) 0.639843537701776\n",
      "tensor(1650.0990, device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 4.0000, 1.0000, 6.0000, 1.0000, 5.0000, 1.0000,\n",
      "        1.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 6.0000, 1.0000,\n",
      "        2.0000, 1.0000, 2.0000, 0.1312, 1.0000, 3.0000, 0.2187, 1.0000, 4.0000,\n",
      "        0.2592, 1.0000, 3.0000, 0.2430, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(2, device='cuda:0') tensor(0.8359, device='cuda:0') tensor([8.8305, 8.8142, 8.8408, 8.8375], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1654.9861, device='cuda:0') total reward  and actions tensor([3193.,  807.]) 0.6078513608166871\n",
      "tensor(1654.9861, device='cuda:0') tensor([1., 9., 1., 7., 1., 2., 1., 4., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 3.0000, 1.0000, 3.0000, 1.0000,\n",
      "        6.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.4800, device='cuda:0') tensor([8.4795, 8.4633, 8.3750, 8.4382], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1641.6005, device='cuda:0') total reward  and actions tensor([3178.,  822.]) 0.5774587927758528\n",
      "tensor(1641.6005, device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 7.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000,\n",
      "        4.0000, 1.0000, 6.0000, 0.4374, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1., 3., 1., 9., 1., 1., 1., 4., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(0.8900, device='cuda:0') tensor([8.7103, 8.6895, 8.6504, 8.6601], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1665.4148, device='cuda:0') total reward  and actions tensor([3212.,  788.]) 0.5485858531370601\n",
      "tensor(1665.4148, device='cuda:0') tensor([1., 7., 0., 0., 1., 9., 1., 2., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.,  1.,  1.,  2.,  1.,  2.,  1., 10.,  1.,  4.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor(0, device='cuda:0') tensor(1.3800, device='cuda:0') tensor([8.5532, 8.5032, 8.4123, 8.4660], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1627.3123, device='cuda:0') total reward  and actions tensor([3265.,  735.]) 0.5211565604802071\n",
      "tensor(1627.3123, device='cuda:0') tensor([ 1.0000,  7.0000,  1.0000,  2.0000,  1.0000,  2.0000,  1.0000,  3.0000,\n",
      "         1.0000,  1.0000,  1.0000,  6.0000,  0.4860,  1.0000, 10.0000,  0.9000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  4.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "         1.0000,  1.0000,  1.0000,  2.0000,  0.1312,  1.0000, 10.0000,  0.5832,\n",
      "         1.0000,  4.0000,  0.2916,  1.0000,  4.0000,  0.3240,  1.0000,  2.0000,\n",
      "         0.1800,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0., device='cuda:0') tensor([8.3321, 8.3227, 8.2731, 8.2767], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1699.1797, device='cuda:0') total reward  and actions tensor([3330.,  670.]) 0.49509873245619673\n",
      "tensor(1699.1797, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  4.0000,  1.0000,  1.0000,  1.0000,  3.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.6561,  1.0000, 10.0000,  0.8100,\n",
      "         1.0000,  6.0000,  0.5400,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 8.0000, 1.0000,\n",
      "        4.0000, 1.0000, 3.0000, 0.2430, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0.3240, device='cuda:0') tensor([8.3170, 8.3316, 8.2428, 8.2208], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1648.7476, device='cuda:0') total reward  and actions tensor([3189.,  811.]) 0.4703437958333868\n",
      "tensor(1648.7476, device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000,  5.0000,  1.0000,  1.0000,  1.0000,  3.0000,\n",
      "         1.0000,  2.0000,  1.0000,  3.0000,  0.1575,  1.0000, 10.0000,  0.7290,\n",
      "         1.0000,  2.0000,  0.1166,  1.0000,  6.0000,  0.4860,  1.0000,  3.0000,\n",
      "         0.1944,  1.0000,  6.0000,  0.5400], device='cuda:0') tensor([1., 1., 1., 4., 1., 3., 1., 2., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(0.0362, device='cuda:0') tensor([8.4797, 8.4307, 8.4384, 8.4179], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1632.3217, device='cuda:0') total reward  and actions tensor([3206.,  794.]) 0.4468266060417175\n",
      "tensor(1632.3217, device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 6.0000, 1.0000, 6.0000, 1.0000, 3.0000, 1.0000,\n",
      "        1.0000, 1.0000, 4.0000, 0.3240, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  3.0000,  1.0000,  4.0000,  1.0000,  3.0000,\n",
      "         1.0000,  7.0000,  1.0000,  2.0000,  0.1620,  1.0000, 10.0000,  0.7200,\n",
      "         1.0000,  3.0000,  0.2700,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.9477, device='cuda:0') tensor([8.3047, 8.2855, 8.2424, 8.2608], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1624.0684, device='cuda:0') total reward  and actions tensor([3149.,  851.]) 0.42448527573963163\n",
      "tensor(1624.0684, device='cuda:0') tensor([1., 6., 1., 3., 1., 3., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1., 2., 1., 5., 1., 1., 1., 3., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(1.2700, device='cuda:0') tensor([8.9847, 8.8998, 8.9363, 8.8485], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Main Simulation\n",
    "\n",
    "# configs\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "EPSILON = 1\n",
    "\n",
    "\n",
    "# Check if GPU is available and if so, use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create Data Centers\n",
    "data_center_num = 2\n",
    "dataCenter1 = DataCenter(device)\n",
    "dataCenter2 = DataCenter(device)\n",
    "\n",
    "\n",
    "model = SingleAgentNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "if False:\n",
    "    print(\"trained model loaded from file\")\n",
    "    model = torch.load(\"SingleAgentBaseline.pth\")\n",
    "    EPSILON = 0.95**60\n",
    "else:\n",
    "    print(\"model initialized randomly\")\n",
    "\n",
    "replay_buffer = ReplayBuffer(200000)\n",
    "dummy_value = torch.zeros(1).to(device)\n",
    "\n",
    "\n",
    "M = 120 #500\n",
    "N = 2000 #3000\n",
    "\n",
    "\n",
    "for episode in range(M):\n",
    "    EPSILON *= 0.95\n",
    "    # keep track of rewards\n",
    "    total_rewards = 0\n",
    "    actions_record = torch.zeros((2,))\n",
    "\n",
    "    # create a loss function\n",
    "    dataCenter1.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    dataCenter2.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    total_rewards = 0\n",
    "\n",
    "    jobGenerator = JobGenerator(data_center_num)\n",
    "\n",
    "    jobs = jobGenerator.generate_job()\n",
    "\n",
    "    # used for replay buffer\n",
    "    curr_state = torch.cat((dataCenter1.state, dataCenter2.state, jobs[0].to(device), jobs[1].to(device)), 0)\n",
    "\n",
    "    # get initial actions\n",
    "    q_values = model.forward_pass(curr_state)\n",
    "    action, q_value = epsilon_greedy(q_values, EPSILON)\n",
    "\n",
    "    for timestep in range(N):\n",
    "        # update according to action\n",
    "\n",
    "        reward1 = 0\n",
    "        reward2 = 0\n",
    "\n",
    "        reward = torch.tensor(0.0).to(device)\n",
    "\n",
    "        reward_from_1 = 0\n",
    "        reward_from_2 = 0\n",
    "\n",
    "        if action % 2 == 0:\n",
    "            reward_from_1 += dataCenter1.add_job(jobs[0])\n",
    "        else:\n",
    "            jobs[0][1] *= 0.8\n",
    "            reward_from_2 += dataCenter2.add_job(jobs[0])\n",
    "\n",
    "        if action // 2 == 0:\n",
    "            reward_from_2 +=  dataCenter2.add_job(jobs[1])\n",
    "        else:\n",
    "            jobs[1][1] *= 0.8\n",
    "            reward_from_1 += dataCenter1.add_job(jobs[1])\n",
    "        actions_record[action % 2 ] += 1\n",
    "        actions_record[action // 2] += 1\n",
    "\n",
    "\n",
    "        # print(\"state before update:\", dataCenter1.state, q_value_1)\n",
    "\n",
    "        reward_from_1 += dataCenter1.update(1)\n",
    "        reward_from_2 += dataCenter2.update(1)\n",
    "\n",
    "        reward1 = reward_from_1 * 0.5 + reward_from_2 * 0.5\n",
    "        reward2 = reward_from_2 * 0.5 + reward_from_1 * 0.5\n",
    "        \n",
    "        reward = reward1 + reward2\n",
    "\n",
    "        jobs = jobGenerator.generate_job()\n",
    "\n",
    "        next_state = torch.cat((dataCenter1.state, dataCenter2.state, jobs[0].to(device), jobs[1].to(device)), 0)\n",
    "\n",
    "        total_rewards += reward\n",
    "\n",
    "        ############################## update replay buffer ##############################\n",
    "\n",
    "        replay_buffer.push(curr_state, dummy_value, jobs[0].to(device), action.view(-1).to(device), reward1, next_state, dummy_value, jobs[1].to(device))\n",
    "        # print(curr_state, dummy_value, jobs[0].to(device), action, reward1, next_state, dummy_value, jobs[1].to(device))\n",
    "        sample_state, _, _, sample_action, sample_reward, sample_next_state, _, _ = replay_buffer.sample(BATCH_SIZE)\n",
    "        replay_actual_q_values = model.forward_pass(sample_state.detach())[torch.arange(sample_state.size(0)), sample_action.view(-1)]\n",
    "        replay_next_q_values = model.forward_pass(sample_next_state.detach())\n",
    "        # print(torch.max(replay_next_q_values, 1).size())\n",
    "        replay_expected_values = sample_reward + 0.95 * torch.max(replay_next_q_values, 1)[0]\n",
    "        loss = torch.nn.MSELoss()(replay_expected_values.detach(), replay_actual_q_values)\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        curr_state = torch.cat((dataCenter1.state, dataCenter2.state, jobs[0].to(device), jobs[1].to(device)), 0)\n",
    "        # get next actions\n",
    "        q_values = model.forward_pass(curr_state)\n",
    "        action, q_value = epsilon_greedy(q_values, EPSILON)\n",
    "\n",
    "\n",
    "        # print(cur_state)\n",
    "    print(\"we got \", total_rewards, \"total reward\", \" and actions\", actions_record, EPSILON*200)\n",
    "    print(total_rewards, dataCenter1.state, dataCenter2.state, action, reward, q_values)\n",
    "\n",
    "    #print(total_rewards, l_time, r_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "d8cd5666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not saving the model to avoid overwriting\n"
     ]
    }
   ],
   "source": [
    "if None:\n",
    "    print(\"saving the model!\")\n",
    "    torch.save(model, \"SingleAgentBaseline.pth\")\n",
    "else:\n",
    "    print(\"not saving the model to avoid overwriting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fc35ac",
   "metadata": {},
   "source": [
    "## Independent Learners\n",
    "Now we provide a baseline of independent learners\n",
    "\n",
    "We further examined two cases:\n",
    "\n",
    "1. With reward sharing: reward for each job is shared between two agents equally. Converge to ~1450\n",
    "2. Without reward sharing: reward for finishing each job is shared only with local agent. Converge to ~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de843f60",
   "metadata": {},
   "source": [
    "### with reward sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "8db55fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1489.5868, device='cuda:0') total reward\n",
      "actions tensor([2172., 1828.]) 87.53261807520869\n",
      "tensor(1489.5868, device='cuda:0') tensor([1., 7., 1., 2., 1., 8., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.,  6.,  1., 10.,  1.,  3.,  1.,  6.,  1.,  3.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(1.6760, device='cuda:0') tensor([7.9454, 7.7798], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.7113, 7.9592], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1424.6742, device='cuda:0') total reward\n",
      "actions tensor([2268., 1732.]) 83.15598717144826\n",
      "tensor(1424.6742, device='cuda:0') tensor([1.0000, 6.0000, 1.0000, 1.0000, 1.0000, 9.0000, 1.0000, 2.0000, 1.0000,\n",
      "        3.0000, 1.0000, 4.0000, 0.2880, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.,  2.,  1.,  6.,  1., 10.,  1.,  4.,  1.,  4.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(1.9219, device='cuda:0') tensor([7.8495, 8.0068], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.9955, 7.8118], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1435.7406, device='cuda:0') total reward\n",
      "actions tensor([2094., 1906.]) 78.99818781287584\n",
      "tensor(1435.7406, device='cuda:0') tensor([ 1., 10.,  1.,  3.,  1.,  1.,  0.,  0.,  1.,  9.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([1., 2., 1., 4., 1., 8., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(1.5800, device='cuda:0') tensor([7.9766, 8.0370], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.5145, 8.1852], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1444.7629, device='cuda:0') total reward\n",
      "actions tensor([2151., 1849.]) 75.04827842223204\n",
      "tensor(1444.7629, device='cuda:0') tensor([1., 4., 1., 3., 1., 4., 1., 3., 1., 5., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000, 10.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "         1.0000,  1.0000,  1.0000,  3.0000,  0.1968,  1.0000,  2.0000,  0.1620,\n",
      "         1.0000,  3.0000,  0.2700,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0') tensor(0.9249, device='cuda:0') tensor([7.9750, 7.9334], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.8385, 8.9171], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1428.2466, device='cuda:0') total reward\n",
      "actions tensor([2113., 1887.]) 71.29586450112045\n",
      "tensor(1428.2466, device='cuda:0') tensor([ 1., 10.,  1.,  3.,  1.,  2.,  1.,  3.,  1.,  1.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000,\n",
      "        2.0000, 1.0000, 4.0000, 0.2333, 1.0000, 2.0000, 0.1458, 1.0000, 4.0000,\n",
      "        0.2592, 1.0000, 3.0000, 0.2430, 1.0000, 4.0000, 0.2880, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0') tensor(1.0419, device='cuda:0') tensor([7.9712, 7.8250], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.4953, 8.6355], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1408.0763, device='cuda:0') total reward\n",
      "actions tensor([2109., 1891.]) 67.73107127606443\n",
      "tensor(1408.0763, device='cuda:0') tensor([1., 8., 1., 6., 1., 9., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1., 3., 1., 3., 1., 2., 1., 4., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(1.2230, device='cuda:0') tensor([7.9213, 7.7380], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.2336, 7.9696], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1435.1292, device='cuda:0') total reward\n",
      "actions tensor([2080., 1920.]) 64.3445177122612\n",
      "tensor(1435.1292, device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 2.0000, 1.0000,\n",
      "        3.0000, 1.0000, 4.0000, 0.2916, 1.0000, 6.0000, 0.5400, 1.0000, 3.0000,\n",
      "        0.2160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1., 4., 1., 3., 1., 9., 1., 1., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor([1]) tensor(0.6746, device='cuda:0') tensor([8.2255, 8.2571], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.7888, 8.4773], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1467.9492, device='cuda:0') total reward\n",
      "actions tensor([2116., 1884.]) 61.12729182664813\n",
      "tensor(1467.9492, device='cuda:0') tensor([ 1.,  9.,  1., 10.,  1.,  7.,  1.,  2.,  1.,  9.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000,  2.0000,  1.0000,  2.0000,  1.0000,  6.0000,\n",
      "         1.0000,  7.0000,  1.0000, 10.0000,  0.7200,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([0]) tensor(0, device='cuda:0') tensor(1.0600, device='cuda:0') tensor([7.6745, 7.7739], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.3050, 8.2599], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1474.0314, device='cuda:0') total reward\n",
      "actions tensor([2135., 1865.]) 58.07092723531572\n",
      "tensor(1474.0314, device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000,  6.0000,  1.0000,  1.0000,  1.0000,  7.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.7290,  1.0000, 10.0000,  0.8100,\n",
      "         1.0000,  3.0000,  0.1944,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1., 10.,  1.,  6.,  1.,  1.,  1.,  1.,  1.,  3.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0') tensor(1.1000, device='cuda:0') tensor([7.9154, 7.8642], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.3888, 8.4833], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1469.2209, device='cuda:0') total reward\n",
      "actions tensor([2210., 1790.]) 55.16738087354993\n",
      "tensor(1469.2209, device='cuda:0') tensor([ 1.,  2.,  1.,  4.,  1.,  4.,  1.,  2.,  1., 10.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 8.0000, 1.0000,\n",
      "        4.0000, 1.0000, 6.0000, 0.3888, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0') tensor(1.4680, device='cuda:0') tensor([8.2468, 7.9677], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.2440, 8.3116], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1521.6836, device='cuda:0') total reward\n",
      "actions tensor([2236., 1764.]) 52.40901182987243\n",
      "tensor(1521.6836, device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 5.0000, 1.0000, 3.0000, 1.0000,\n",
      "        2.0000, 1.0000, 2.0000, 0.1296, 1.0000, 6.0000, 0.5400, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 7.0000, 1.0000, 3.0000, 1.0000, 6.0000, 1.0000,\n",
      "        8.0000, 1.0000, 6.0000, 0.3888, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(0.4131, device='cuda:0') tensor([8.2769, 8.2475], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.1454, 7.8495], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1453.9310, device='cuda:0') total reward\n",
      "actions tensor([2178., 1822.]) 49.78856123837881\n",
      "tensor(1453.9310, device='cuda:0') tensor([ 1.0000, 10.0000,  1.0000,  8.0000,  1.0000,  3.0000,  1.0000,  6.0000,\n",
      "         1.0000,  7.0000,  1.0000,  2.0000,  0.1440,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 3.0000, 1.0000, 2.0000, 1.0000, 4.0000, 1.0000,\n",
      "        1.0000, 1.0000, 3.0000, 0.2430, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(1.5067, device='cuda:0') tensor([6.9626, 7.5317], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.6616, 8.4197], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1445.8156, device='cuda:0') total reward\n",
      "actions tensor([2142., 1858.]) 47.29913317645987\n",
      "tensor(1445.8156, device='cuda:0') tensor([ 1.0000,  6.0000,  1.0000,  3.0000,  1.0000,  8.0000,  1.0000,  2.0000,\n",
      "         1.0000,  2.0000,  1.0000,  6.0000,  0.3937,  1.0000, 10.0000,  0.8100,\n",
      "         1.0000,  6.0000,  0.5400,  1.0000,  4.0000,  0.2880,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 4.0000, 1.0000, 3.0000, 1.0000, 1.0000, 1.0000,\n",
      "        9.0000, 1.0000, 3.0000, 0.2430, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(0.3240, device='cuda:0') tensor([7.7227, 7.5835], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.5522, 8.3557], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1434.4200, device='cuda:0') total reward\n",
      "actions tensor([2148., 1852.]) 44.93417651763687\n",
      "tensor(1434.4200, device='cuda:0') tensor([ 1.0000,  9.0000,  1.0000,  3.0000,  1.0000,  5.0000,  1.0000,  2.0000,\n",
      "         1.0000,  3.0000,  1.0000,  4.0000,  0.2333,  1.0000, 10.0000,  0.8100,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 3.0000, 1.0000,\n",
      "        4.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(0.4366, device='cuda:0') tensor([7.6453, 7.5730], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.9109, 8.8184], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1412.8617, device='cuda:0') total reward\n",
      "actions tensor([2044., 1956.]) 42.687467691755025\n",
      "tensor(1412.8617, device='cuda:0') tensor([1., 2., 1., 8., 1., 3., 1., 2., 1., 9., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  9.0000,  1.0000,  2.0000,  1.0000,  2.0000,\n",
      "         1.0000,  1.0000,  1.0000, 10.0000,  0.5249,  1.0000,  3.0000,  0.1968,\n",
      "         1.0000,  4.0000,  0.2916,  1.0000,  6.0000,  0.4320,  1.0000,  3.0000,\n",
      "         0.2700,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor([1]) tensor(0.2752, device='cuda:0') tensor([7.9566, 7.7166], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.6179, 8.4595], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1457.8337, device='cuda:0') total reward\n",
      "actions tensor([2224., 1776.]) 40.55309430716728\n",
      "tensor(1457.8337, device='cuda:0') tensor([ 1.,  5.,  1.,  3.,  1.,  2.,  1., 10.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 3.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000,\n",
      "        2.0000, 1.0000, 3.0000, 0.2430, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(1.2430, device='cuda:0') tensor([8.0608, 8.1131], device='cuda:0', grad_fn=<ViewBackward0>) tensor([9.0723, 8.8044], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1457.7288, device='cuda:0') total reward\n",
      "actions tensor([2182., 1818.]) 38.52543959180891\n",
      "tensor(1457.7288, device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  3.0000,  1.0000,  2.0000,  1.0000,  2.0000,\n",
      "         1.0000,  1.0000,  1.0000,  2.0000,  0.1166,  1.0000,  2.0000,  0.1296,\n",
      "         1.0000, 10.0000,  0.9000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 9.0000, 1.0000, 7.0000, 1.0000, 6.0000, 1.0000,\n",
      "        2.0000, 1.0000, 4.0000, 0.2333, 1.0000, 4.0000, 0.2592, 1.0000, 3.0000,\n",
      "        0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(0.3499, device='cuda:0') tensor([8.0794, 8.3275], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.9750, 7.9596], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1471.1217, device='cuda:0') total reward\n",
      "actions tensor([2199., 1801.]) 36.599167612218466\n",
      "tensor(1471.1217, device='cuda:0') tensor([1.0000, 6.0000, 1.0000, 8.0000, 1.0000, 6.0000, 1.0000, 4.0000, 1.0000,\n",
      "        1.0000, 1.0000, 6.0000, 0.4860, 1.0000, 2.0000, 0.1296, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  1.0000,  1.0000,  4.0000,  1.0000,  1.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.5249,  1.0000, 10.0000,  0.7200,\n",
      "         1.0000,  2.0000,  0.1800,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(1.0076, device='cuda:0') tensor([7.7297, 7.9924], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.5523, 8.2864], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1463.2195, device='cuda:0') total reward\n",
      "actions tensor([2182., 1818.]) 34.76920923160754\n",
      "tensor(1463.2195, device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 5.0000, 1.0000, 3.0000, 1.0000, 3.0000, 1.0000,\n",
      "        2.0000, 1.0000, 2.0000, 0.1440, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  1.0000,  1.0000,  4.0000,  1.0000,  1.0000,\n",
      "         1.0000,  1.0000,  1.0000,  4.0000,  0.2592,  1.0000,  3.0000,  0.2430,\n",
      "         1.0000, 10.0000,  0.7200,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(0.6172, device='cuda:0') tensor([8.0989, 8.2484], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.5783, 8.8989], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1481.1339, device='cuda:0') total reward\n",
      "actions tensor([2222., 1778.]) 33.03074877002717\n",
      "tensor(1481.1339, device='cuda:0') tensor([1.0000, 5.0000, 1.0000, 1.0000, 1.0000, 6.0000, 1.0000, 6.0000, 1.0000,\n",
      "        6.0000, 1.0000, 4.0000, 0.2880, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([0., 0., 1., 2., 1., 3., 1., 7., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(1.0860, device='cuda:0') tensor([7.4252, 7.5072], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.7269, 8.5426], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1449.1931, device='cuda:0') total reward\n",
      "actions tensor([2070., 1930.]) 31.379211331525806\n",
      "tensor(1449.1931, device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  2.0000,  1.0000,  2.0000,  1.0000,  7.0000,\n",
      "         1.0000,  1.0000,  1.0000, 10.0000,  0.9000,  1.0000,  4.0000,  0.2880,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  8.0000,  1.0000,  2.0000,  1.0000,  7.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.5832,  1.0000,  3.0000,  0.2187,\n",
      "         1.0000,  4.0000,  0.2592,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(0., device='cuda:0') tensor([8.4667, 8.1798], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.0527, 7.9120], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [315], line 152\u001b[0m\n\u001b[0;32m    149\u001b[0m loss_1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()(replay_expected_values_1\u001b[38;5;241m.\u001b[39mdetach(), replay_actual_q_values_1)\n\u001b[0;32m    150\u001b[0m loss_2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()(replay_expected_values_2\u001b[38;5;241m.\u001b[39mdetach(), replay_actual_q_values_2)\n\u001b[1;32m--> 152\u001b[0m \u001b[43mloss_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m loss_2\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    155\u001b[0m optimizer_1\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define IL DQN model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class IndependentLearnerNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IndependentLearnerNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(30, 512)\n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.layer3 = nn.Linear(256, 256)\n",
    "        self.layer4 = nn.Linear(256, 256)\n",
    "        self.layer5 = nn.Linear(256, 2)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Neural Network with input layer {self.input_layer}, hidden layer 1 {self.hidden_layer_1}, hidden layer 2 {self.hidden_layer_2}, hidden layer 3 {self.hidden_layer_3}, hidden layer 4 {self.hidden_layer_4}, and output layer {self.output_layer}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "    def forward_pass(self, input_data):\n",
    "        x = self.layer1(input_data)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer4(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer5(x)\n",
    "        return x\n",
    "\n",
    "# Main Simulation\n",
    "\n",
    "# configs\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "EPSILON = 1\n",
    "\n",
    "# Check if GPU is available and if so, use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if True:\n",
    "    # Create Data Centers\n",
    "    data_center_num = 2\n",
    "    dataCenter1 = DataCenter(device)\n",
    "    dataCenter2 = DataCenter(device)\n",
    "\n",
    "    model_1 = IndependentLearnerNN().to(device)\n",
    "    model_2 = IndependentLearnerNN().to(device)\n",
    "\n",
    "    optimizer_1 = torch.optim.Adam(model_1.parameters(), lr=0.001)\n",
    "    optimizer_2 = torch.optim.Adam(model_2.parameters(), lr=0.001)\n",
    "\n",
    "    # Initialize Replay Buffer\n",
    "    replay_buffer_1 = ReplayBuffer(200000)\n",
    "    replay_buffer_2 = ReplayBuffer(200000)\n",
    "    dummy_value = torch.zeros(1).to(device)\n",
    "else:\n",
    "    EPSILON = 0.95**60\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "M = 100 # Number of episodes\n",
    "N = 2000 # Number of timesteps per episode\n",
    "\n",
    "for episode in range(M):\n",
    "    EPSILON *= 0.95\n",
    "    # keep track of rewards\n",
    "    total_rewards = 0\n",
    "    actions_record = torch.zeros((2,))\n",
    "\n",
    "    # Reset states\n",
    "    dataCenter1.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    dataCenter2.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    total_rewards = 0\n",
    "\n",
    "    jobGenerator = JobGenerator(data_center_num)\n",
    "\n",
    "    jobs = jobGenerator.generate_job()\n",
    "\n",
    "    curr_state_1 = torch.cat((torch.zeros(STATE_SIZE).to(device), jobs[0].to(device)), 0)\n",
    "    curr_state_2 = torch.cat((torch.zeros(STATE_SIZE).to(device), jobs[1].to(device)), 0)\n",
    "\n",
    "    # Get initial actions\n",
    "    q_values_1 = model_1.forward_pass(curr_state_1)\n",
    "    q_values_2 = model_2.forward_pass(curr_state_2)\n",
    "\n",
    "    action1, q_value_1 = epsilon_greedy(q_values_1, EPSILON)\n",
    "    action2, q_value_2 = epsilon_greedy(q_values_2, EPSILON)\n",
    "\n",
    "    print(\"initial actions\", action1, action2)\n",
    "\n",
    "    for timestep in range(N):\n",
    "        reward1 = 0\n",
    "        reward2 = 0\n",
    "        reward = torch.tensor(0.0).to(device)\n",
    "        reward_from_1 = 0\n",
    "        reward_from_2 = 0\n",
    "\n",
    "        if action1 == 0:\n",
    "            reward_from_1 += dataCenter1.add_job(jobs[0])\n",
    "        else:\n",
    "            jobs[0][1] *= 0.8\n",
    "            reward_from_2 += dataCenter2.add_job(jobs[0])\n",
    "\n",
    "        if action2 == 0:\n",
    "            reward_from_2 += dataCenter2.add_job(jobs[1])\n",
    "        else:\n",
    "            jobs[1][1] *= 0.8\n",
    "            reward_from_1 += dataCenter1.add_job(jobs[1])\n",
    "        \n",
    "        # print(action1, actions_record)\n",
    "        actions_record[action1] += 1\n",
    "        actions_record[action2] += 1\n",
    "\n",
    "        reward_from_1 += dataCenter1.update(1)\n",
    "        reward_from_2 += dataCenter2.update(1)\n",
    "\n",
    "        reward1 = reward_from_1 * 0.5 + reward_from_2 * 0.5\n",
    "        reward2 = reward_from_2 * 0.5 + reward_from_1 * 0.5\n",
    "        \n",
    "        reward = reward1 + reward2\n",
    "\n",
    "        jobs = jobGenerator.generate_job()\n",
    "\n",
    "        next_state_1 = torch.cat((dataCenter1.state, jobs[0].to(device)), 0)\n",
    "        next_state_2 = torch.cat((dataCenter2.state, jobs[1].to(device)), 0)\n",
    "\n",
    "        total_rewards += reward\n",
    "\n",
    "        ############################## update replay buffer ##############################\n",
    "\n",
    "        replay_buffer_1.push(curr_state_1, dummy_value, jobs[0].to(device), action1.view(-1).to(device), reward1, next_state_1, dummy_value, jobs[1].to(device))\n",
    "        replay_buffer_2.push(curr_state_2, dummy_value, jobs[1].to(device), action2.view(-1).to(device), reward2, next_state_2, dummy_value, jobs[0].to(device))\n",
    "\n",
    "        sample_state_1, _, _, sample_action_1, sample_reward_1, sample_next_state_1, _, _ = replay_buffer_1.sample(BATCH_SIZE)\n",
    "        sample_state_2, _, _, sample_action_2, sample_reward_2, sample_next_state_2, _, _ = replay_buffer_2.sample(BATCH_SIZE)\n",
    "\n",
    "        replay_actual_q_values_1 = model_1.forward_pass(sample_state_1.detach())[torch.arange(sample_state_1.size(0)), sample_action_1.view(-1)]\n",
    "        replay_actual_q_values_2 = model_2.forward_pass(sample_state_2.detach())[torch.arange(sample_state_2.size(0)), sample_action_2.view(-1)]\n",
    "\n",
    "        replay_next_q_values_1 = model_1.forward_pass(sample_next_state_1.detach())\n",
    "        replay_next_q_values_2 = model_2.forward_pass(sample_next_state_2.detach())\n",
    "\n",
    "        replay_expected_values_1 = sample_reward_1 + 0.95 * torch.max(replay_next_q_values_1, 1)[0]\n",
    "        replay_expected_values_2 = sample_reward_2 + 0.95 * torch.max(replay_next_q_values_2, 1)[0]\n",
    "\n",
    "        loss_1 = torch.nn.MSELoss()(replay_expected_values_1.detach(), replay_actual_q_values_1)\n",
    "        loss_2 = torch.nn.MSELoss()(replay_expected_values_2.detach(), replay_actual_q_values_2)\n",
    "\n",
    "        loss_1.backward(retain_graph=True)\n",
    "        loss_2.backward(retain_graph=True)\n",
    "\n",
    "        optimizer_1.step()\n",
    "        optimizer_2.step()\n",
    "\n",
    "        optimizer_1.zero_grad()\n",
    "        optimizer_2.zero_grad()\n",
    "\n",
    "        ############################## get next actions ##############################\n",
    "        # Update states and actions\n",
    "\n",
    "        curr_state_1 = torch.cat((dataCenter1.state, jobs[0].to(device)), 0)\n",
    "        curr_state_2 = torch.cat((dataCenter2.state, jobs[1].to(device)), 0)\n",
    "\n",
    "        q_values_1 = model_1.forward_pass(curr_state_1)\n",
    "        q_values_2 = model_2.forward_pass(curr_state_2)\n",
    "        action1, q_value_1 = epsilon_greedy(q_values_1, EPSILON)\n",
    "        action2, q_value_2 = epsilon_greedy(q_values_2, EPSILON)\n",
    "\n",
    "    print(\"we got \", total_rewards, \"total reward\")\n",
    "    print(\"actions\", actions_record, EPSILON * 2000)\n",
    "    print(total_rewards, dataCenter1.state, dataCenter2.state, action1, action2, reward, q_values_1, q_values_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04ff16a",
   "metadata": {},
   "source": [
    "### no reward sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "ba13e03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "initial actions tensor([0]) tensor([0])\n",
      "we got  tensor(1321.8208, device='cuda:0') total reward\n",
      "actions tensor([2029., 1971.]) 1900.0\n",
      "tensor(1321.8208, device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 3.0000, 1.0000, 8.0000, 1.0000, 7.0000, 1.0000,\n",
      "        1.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  8.0000,  1.0000,  2.0000,  1.0000,  2.0000,  1.0000,  2.0000,\n",
      "         1.0000,  1.0000,  1.0000,  4.0000,  0.2362,  1.0000, 10.0000,  0.5249,\n",
      "         1.0000,  6.0000,  0.3499,  1.0000,  4.0000,  0.2592,  1.0000,  2.0000,\n",
      "         0.1800,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1]) tensor([1]) tensor(0.2160, device='cuda:0') tensor([5.9406e+11, 5.2835e+11], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.8034, 8.0016], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([0]) tensor([1])\n",
      "we got  tensor(1307.5090, device='cuda:0') total reward\n",
      "actions tensor([2113., 1887.]) 1805.0\n",
      "tensor(1307.5090, device='cuda:0') tensor([1., 3., 1., 6., 1., 2., 1., 1., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  4.0000,\n",
      "         1.0000,  5.0000,  1.0000,  2.0000,  0.1063,  1.0000,  6.0000,  0.2834,\n",
      "         1.0000, 10.0000,  0.5249,  1.0000,  4.0000,  0.2333,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1]) tensor([1]) tensor(0.7600, device='cuda:0') tensor([1.6187e+11, 1.4537e+11], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.2429, 8.2135], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([1]) tensor([1])\n",
      "we got  tensor(1286.2142, device='cuda:0') total reward\n",
      "actions tensor([2234., 1766.]) 1714.7499999999998\n",
      "tensor(1286.2142, device='cuda:0') tensor([1.0000, 6.0000, 1.0000, 3.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        5.0000, 1.0000, 2.0000, 0.1296, 1.0000, 6.0000, 0.5400, 1.0000, 3.0000,\n",
      "        0.2160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1., 2., 1., 9., 1., 6., 1., 2., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1]) tensor([0]) tensor(0.4860, device='cuda:0') tensor([4.4909e+10, 4.0604e+10], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.5402, 7.4759], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([0]) tensor([0])\n",
      "we got  tensor(1280.4819, device='cuda:0') total reward\n",
      "actions tensor([2237., 1763.]) 1629.0124999999998\n",
      "tensor(1280.4819, device='cuda:0') tensor([ 1.0000,  5.0000,  1.0000,  5.0000,  1.0000,  9.0000,  1.0000, 10.0000,\n",
      "         1.0000,  1.0000,  1.0000,  3.0000,  0.1417,  1.0000,  6.0000,  0.3937,\n",
      "         1.0000,  4.0000,  0.2333,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  8.0000,  1.0000, 10.0000,  1.0000,  5.0000,\n",
      "         1.0000,  1.0000,  1.0000,  2.0000,  0.1800,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1]) tensor([0]) tensor(1.3905, device='cuda:0') tensor([7.9374e+09, 7.2067e+09], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.0069, 8.0394], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([1]) tensor([0])\n",
      "we got  tensor(1245.9419, device='cuda:0') total reward\n",
      "actions tensor([2315., 1685.]) 1547.5618749999996\n",
      "tensor(1245.9419, device='cuda:0') tensor([1., 5., 1., 1., 1., 4., 1., 5., 1., 6., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000,  5.0000,  1.0000,  7.0000,  1.0000,  3.0000,\n",
      "         1.0000,  7.0000,  1.0000, 10.0000,  0.5832,  1.0000,  3.0000,  0.2187,\n",
      "         1.0000,  4.0000,  0.3240,  1.0000,  3.0000,  0.2700,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor([0]) tensor(0.6000, device='cuda:0') tensor([1.0064e+08, 9.1540e+07], device='cuda:0', grad_fn=<ViewBackward0>) tensor([5.6474, 5.6242], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([1]) tensor(0, device='cuda:0')\n",
      "we got  tensor(1234.5475, device='cuda:0') total reward\n",
      "actions tensor([2362., 1638.]) 1470.1837812499996\n",
      "tensor(1234.5475, device='cuda:0') tensor([1.0000, 7.0000, 1.0000, 4.0000, 1.0000, 6.0000, 1.0000, 2.0000, 1.0000,\n",
      "        3.0000, 1.0000, 6.0000, 0.3937, 1.0000, 4.0000, 0.2100, 1.0000, 6.0000,\n",
      "        0.4860, 1.0000, 3.0000, 0.1944, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1., 4., 1., 5., 1., 1., 1., 3., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([0]) tensor([1]) tensor(0.4280, device='cuda:0') tensor([-2197580.2500, -8774480.0000], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>) tensor([7.9375, 7.8100], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor([1])\n",
      "we got  tensor(1244.5890, device='cuda:0') total reward\n",
      "actions tensor([2488., 1512.]) 1396.6745921874995\n",
      "tensor(1244.5890, device='cuda:0') tensor([ 1.0000,  6.0000,  1.0000,  6.0000,  1.0000,  2.0000,  1.0000, 10.0000,\n",
      "         1.0000,  4.0000,  1.0000, 10.0000,  0.6561,  1.0000,  4.0000,  0.3240,\n",
      "         1.0000,  6.0000,  0.5400,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 2.0000, 1.0000, 6.0000, 1.0000, 1.0000, 1.0000,\n",
      "        4.0000, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1]) tensor([0]) tensor(0.9944, device='cuda:0') tensor([-13742722., -55277404.], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.0278, 8.1510], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([1]) tensor(0, device='cuda:0')\n",
      "we got  tensor(1228.2781, device='cuda:0') total reward\n",
      "actions tensor([2427., 1573.]) 1326.8408625781244\n",
      "tensor(1228.2781, device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  3.0000,  1.0000,  3.0000,  1.0000, 10.0000,\n",
      "         1.0000,  4.0000,  1.0000,  4.0000,  0.2362,  1.0000, 10.0000,  0.7290,\n",
      "         1.0000,  6.0000,  0.5400,  1.0000,  2.0000,  0.1440,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 9., 1., 1., 1., 1., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1]) tensor([0]) tensor(0.5905, device='cuda:0') tensor([ -5040603., -20493758.], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.5300, 8.2338], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor([0])\n",
      "we got  tensor(1234.0627, device='cuda:0') total reward\n",
      "actions tensor([2625., 1375.]) 1260.4988194492182\n",
      "tensor(1234.0627, device='cuda:0') tensor([1.0000, 6.0000, 1.0000, 5.0000, 1.0000, 1.0000, 1.0000, 7.0000, 1.0000,\n",
      "        1.0000, 1.0000, 4.0000, 0.2592, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  9.0000,  1.0000,  1.0000,  1.0000,  7.0000,  1.0000,  1.0000,\n",
      "         1.0000,  7.0000,  1.0000,  2.0000,  0.1181,  1.0000,  6.0000,  0.3149,\n",
      "         1.0000, 10.0000,  0.7200,  1.0000,  2.0000,  0.1800,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([0]) tensor([0]) tensor(0.5400, device='cuda:0') tensor([ -694707.5000, -2860905.5000], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>) tensor([6.7228, 6.9525], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([1]) tensor(0, device='cuda:0')\n",
      "we got  tensor(1232.7317, device='cuda:0') total reward\n",
      "actions tensor([2629., 1371.]) 1197.4738784767571\n",
      "tensor(1232.7317, device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 4.0000, 1.0000, 6.0000, 1.0000, 8.0000, 1.0000,\n",
      "        9.0000, 1.0000, 4.0000, 0.3240, 1.0000, 3.0000, 0.2160, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  7.0000,  1.0000,  1.0000,  1.0000,  2.0000,\n",
      "         1.0000,  5.0000,  1.0000,  3.0000,  0.2430,  1.0000, 10.0000,  0.7200,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([0]) tensor([0]) tensor(0.4860, device='cuda:0') tensor([1101127.2500, -658429.5000], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.8907, 7.8557], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1207.4578, device='cuda:0') total reward\n",
      "actions tensor([2741., 1259.]) 1137.600184552919\n",
      "tensor(1207.4578, device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  1.0000,  1.0000,  5.0000,  1.0000, 10.0000,\n",
      "         1.0000,  3.0000,  1.0000,  4.0000,  0.1531,  1.0000, 10.0000,  0.5314,\n",
      "         1.0000, 10.0000,  0.5905,  1.0000,  2.0000,  0.1440,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 4., 1., 2., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor([0]) tensor(0.8514, device='cuda:0') tensor([2861070.7500, 2557786.0000], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.5026, 8.3073], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([0]) tensor([0])\n",
      "we got  tensor(1211.1113, device='cuda:0') total reward\n",
      "actions tensor([2793., 1207.]) 1080.7201753252732\n",
      "tensor(1211.1113, device='cuda:0') tensor([ 1.0000,  6.0000,  1.0000,  1.0000,  1.0000,  2.0000,  1.0000,  7.0000,\n",
      "         1.0000,  2.0000,  1.0000,  2.0000,  0.0945,  1.0000,  3.0000,  0.1575,\n",
      "         1.0000, 10.0000,  0.7290,  1.0000, 10.0000,  0.8100,  1.0000,  6.0000,\n",
      "         0.5400,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 4., 1., 1., 1., 3., 1., 1., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1]) tensor(0, device='cuda:0') tensor(0.5937, device='cuda:0') tensor([2941802.5000, 2638737.7500], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.2138, 7.8734], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([1]) tensor(0, device='cuda:0')\n",
      "we got  tensor(1209.2531, device='cuda:0') total reward\n",
      "actions tensor([2846., 1154.]) 1026.6841665590093\n",
      "tensor(1209.2531, device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  5.0000,  1.0000,  1.0000,  1.0000,  9.0000,\n",
      "         1.0000,  6.0000,  1.0000,  4.0000,  0.2624,  1.0000,  2.0000,  0.1050,\n",
      "         1.0000, 10.0000,  0.7290,  1.0000,  4.0000,  0.2333,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.,  2.,  1.,  9.,  1.,  2.,  1., 10.,  1.,  2.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(1., device='cuda:0') tensor([2462158., 2206268.], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.8002, 7.7416], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1171.1711, device='cuda:0') total reward\n",
      "actions tensor([2891., 1109.]) 975.3499582310588\n",
      "tensor(1171.1711, device='cuda:0') tensor([ 1.0000,  5.0000,  1.0000,  4.0000,  1.0000,  2.0000,  1.0000,  4.0000,\n",
      "         1.0000,  1.0000,  1.0000,  3.0000,  0.1417,  1.0000, 10.0000,  0.6561,\n",
      "         1.0000,  6.0000,  0.4374,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  4.0000,  1.0000,  1.0000,  1.0000,  3.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.7200,  1.0000,  2.0000,  0.1800,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([0]) tensor([1]) tensor(0.2624, device='cuda:0') tensor([822428.0000, 735784.6875], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.6681, 8.6330], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([0]) tensor(0, device='cuda:0')\n",
      "we got  tensor(1153.8835, device='cuda:0') total reward\n",
      "actions tensor([2986., 1014.]) 926.5824603195059\n",
      "tensor(1153.8835, device='cuda:0') tensor([ 1.0000,  6.0000,  1.0000,  3.0000,  1.0000,  5.0000,  1.0000,  2.0000,\n",
      "         1.0000,  6.0000,  1.0000, 10.0000,  0.5905,  1.0000,  4.0000,  0.2624,\n",
      "         1.0000,  4.0000,  0.2100,  1.0000, 10.0000,  0.9000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 3., 1., 2., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1]) tensor(0, device='cuda:0') tensor(0.6018, device='cuda:0') tensor([691998.6250, 619068.4375], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.5882, 8.3224], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor([1])\n",
      "we got  tensor(1141.8881, device='cuda:0') total reward\n",
      "actions tensor([2994., 1006.]) 880.2533373035305\n",
      "tensor(1141.8881, device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000,  1.0000,  1.0000,  2.0000,  1.0000,  5.0000,\n",
      "         1.0000,  2.0000,  1.0000,  6.0000,  0.3937,  1.0000, 10.0000,  0.7290,\n",
      "         1.0000,  6.0000,  0.4860,  1.0000, 10.0000,  0.9000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 3., 1., 3., 1., 6., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(0.5700, device='cuda:0') tensor([562467.5000, 505269.5625], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.9229, 7.8006], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1147.5399, device='cuda:0') total reward\n",
      "actions tensor([3040.,  960.]) 836.240670438354\n",
      "tensor(1147.5399, device='cuda:0') tensor([ 1.0000,  6.0000,  1.0000,  2.0000,  1.0000,  9.0000,  1.0000,  5.0000,\n",
      "         1.0000,  3.0000,  1.0000, 10.0000,  0.5905,  1.0000, 10.0000,  0.6561,\n",
      "         1.0000,  6.0000,  0.4374,  1.0000, 10.0000,  0.8100,  1.0000, 10.0000,\n",
      "         0.9000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 3., 1., 3., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([0]) tensor([1]) tensor(0.3000, device='cuda:0') tensor([571845.0000, 510889.6250], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.5681, 8.1554], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1151.2262, device='cuda:0') total reward\n",
      "actions tensor([3109.,  891.]) 794.4286369164362\n",
      "tensor(1151.2262, device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  8.0000,  1.0000,  7.0000,  1.0000,  6.0000,\n",
      "         1.0000,  4.0000,  1.0000, 10.0000,  0.9000,  1.0000,  2.0000,  0.1440,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 6., 1., 4., 1., 2., 1., 1., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([0]) tensor(0, device='cuda:0') tensor(1.0385, device='cuda:0') tensor([202798.0156, 163479.7812], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.8853, 7.8083], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1121.4171, device='cuda:0') total reward\n",
      "actions tensor([3137.,  863.]) 754.7072050706142\n",
      "tensor(1121.4171, device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  3.0000,  1.0000,  6.0000,  1.0000,  8.0000,\n",
      "         1.0000,  2.0000,  1.0000,  4.0000,  0.1722,  1.0000, 10.0000,  0.4783,\n",
      "         1.0000, 10.0000,  0.5314,  1.0000,  6.0000,  0.3937,  1.0000,  6.0000,\n",
      "         0.4860,  1.0000,  6.0000,  0.5400], device='cuda:0') tensor([1., 4., 1., 1., 1., 2., 1., 3., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([0]) tensor([0]) tensor(-0.2000, device='cuda:0') tensor([223976.8906, 198905.4375], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.1523, 7.9477], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1146.3265, device='cuda:0') total reward\n",
      "actions tensor([3182.,  818.]) 716.9718448170836\n",
      "tensor(1146.3265, device='cuda:0') tensor([ 1.0000,  5.0000,  1.0000,  4.0000,  1.0000,  2.0000,  1.0000,  2.0000,\n",
      "         1.0000,  2.0000,  1.0000,  4.0000,  0.1913,  1.0000,  3.0000,  0.1148,\n",
      "         1.0000,  4.0000,  0.2126,  1.0000,  6.0000,  0.3543,  1.0000, 10.0000,\n",
      "         0.8100,  1.0000,  4.0000,  0.3600], device='cuda:0') tensor([1., 3., 0., 0., 1., 8., 0., 0., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor([0]) tensor(-0.2000, device='cuda:0') tensor([52143.2148, 45107.8398], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.9903, 8.0349], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([0]) tensor([0])\n",
      "we got  tensor(1148.8265, device='cuda:0') total reward\n",
      "actions tensor([3052.,  948.]) 681.1232525762293\n",
      "tensor(1148.8265, device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000,  4.0000,  1.0000,  7.0000,  1.0000,  8.0000,\n",
      "         1.0000,  4.0000,  1.0000, 10.0000,  0.5905,  1.0000,  4.0000,  0.2624,\n",
      "         1.0000,  6.0000,  0.4374,  1.0000,  2.0000,  0.1166,  1.0000,  6.0000,\n",
      "         0.4860,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(-0.1638, device='cuda:0') tensor([14772.3398, 14570.6670], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.1514, 7.8374], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor([0])\n",
      "we got  tensor(1264.1748, device='cuda:0') total reward\n",
      "actions tensor([1457., 2543.]) 647.0670899474178\n",
      "tensor(1264.1748, device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 5.0000, 1.0000, 2.0000, 1.0000, 3.0000, 1.0000,\n",
      "        1.0000, 1.0000, 6.0000, 0.4374, 1.0000, 3.0000, 0.1750, 1.0000, 6.0000,\n",
      "        0.4860, 1.0000, 3.0000, 0.1944, 1.0000, 6.0000, 0.5400, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 5.0000, 1.0000,\n",
      "        7.0000, 1.0000, 2.0000, 0.1800, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([0]) tensor(0, device='cuda:0') tensor(0., device='cuda:0') tensor([2504.8298, 2740.0723], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.8864, 7.8440], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor([0])\n",
      "we got  tensor(1417.4520, device='cuda:0') total reward\n",
      "actions tensor([2243., 1757.]) 614.7137354500469\n",
      "tensor(1417.4520, device='cuda:0') tensor([ 1.0000,  6.0000,  1.0000,  8.0000,  1.0000,  1.0000,  1.0000,  2.0000,\n",
      "         1.0000, 10.0000,  1.0000,  3.0000,  0.2160,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 4., 1., 1., 1., 5., 1., 2., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1]) tensor(0, device='cuda:0') tensor(1.7200, device='cuda:0') tensor([1372.5483,  914.5396], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.1231, 7.8123], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor([0])\n",
      "we got  tensor(1350.8330, device='cuda:0') total reward\n",
      "actions tensor([2467., 1533.]) 583.9780486775445\n",
      "tensor(1350.8330, device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 2.0000, 1.0000, 6.0000, 1.0000, 3.0000, 1.0000,\n",
      "        1.0000, 1.0000, 4.0000, 0.1913, 1.0000, 4.0000, 0.2126, 1.0000, 6.0000,\n",
      "        0.3543, 1.0000, 6.0000, 0.3937, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1., 5., 1., 4., 1., 3., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor([1]) tensor(1.0403, device='cuda:0') tensor([1881.8068, 1988.9802], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.8659, 7.8751], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1392.0759, device='cuda:0') total reward\n",
      "actions tensor([2612., 1388.]) 554.7791462436674\n",
      "tensor(1392.0759, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  5.0000,  1.0000,  5.0000,  1.0000,  2.0000,\n",
      "         1.0000,  9.0000,  1.0000, 10.0000,  0.4305,  1.0000,  6.0000,  0.3543,\n",
      "         1.0000, 10.0000,  0.6561,  1.0000,  6.0000,  0.4860,  1.0000, 10.0000,\n",
      "         0.9000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 4., 1., 1., 1., 3., 1., 8., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(0.4000, device='cuda:0') tensor([2951.5059, 2994.0818], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.9562, 7.8706], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([0]) tensor([0])\n",
      "we got  tensor(1292.4695, device='cuda:0') total reward\n",
      "actions tensor([2035., 1965.]) 527.040188931484\n",
      "tensor(1292.4695, device='cuda:0') tensor([ 1.0000,  6.0000,  1.0000,  5.0000,  1.0000,  2.0000,  1.0000,  1.0000,\n",
      "         1.0000,  1.0000,  1.0000,  6.0000,  0.3937,  1.0000,  3.0000,  0.1575,\n",
      "         1.0000, 10.0000,  0.7290,  1.0000,  6.0000,  0.4860,  1.0000,  3.0000,\n",
      "         0.2160,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000,\n",
      "        8.0000, 1.0000, 4.0000, 0.2880, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor([0]) tensor(0., device='cuda:0') tensor([2817.5039, 2656.3677], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.1444, 8.1239], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1393.1260, device='cuda:0') total reward\n",
      "actions tensor([2188., 1812.]) 500.6881794849097\n",
      "tensor(1393.1260, device='cuda:0') tensor([1.0000, 5.0000, 1.0000, 9.0000, 1.0000, 2.0000, 1.0000, 6.0000, 1.0000,\n",
      "        2.0000, 1.0000, 6.0000, 0.3937, 1.0000, 6.0000, 0.4374, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 4.0000, 1.0000, 3.0000, 1.0000, 5.0000, 1.0000,\n",
      "        2.0000, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([0]) tensor(0, device='cuda:0') tensor(1.1786, device='cuda:0') tensor([2732.0400, 2386.9019], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.7291, 7.6864], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([0]) tensor([1])\n",
      "we got  tensor(1366.4746, device='cuda:0') total reward\n",
      "actions tensor([2388., 1612.]) 475.65377051066423\n",
      "tensor(1366.4746, device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 5.0000, 1.0000, 8.0000, 1.0000, 2.0000, 1.0000,\n",
      "        4.0000, 1.0000, 4.0000, 0.2880, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 8.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000,\n",
      "        2.0000, 1.0000, 4.0000, 0.2592, 1.0000, 2.0000, 0.1620, 1.0000, 4.0000,\n",
      "        0.2880, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(0.4925, device='cuda:0') tensor([2750.2095, 2058.3970], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.8657, 7.8564], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1308.1348, device='cuda:0') total reward\n",
      "actions tensor([2447., 1553.]) 451.87108198513096\n",
      "tensor(1308.1348, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  6.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "         1.0000,  2.0000,  1.0000,  4.0000,  0.1722,  1.0000, 10.0000,  0.5314,\n",
      "         1.0000, 10.0000,  0.6561,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  2.0000,  1.0000,  1.0000,  1.0000,  3.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.7200,  1.0000,  4.0000,  0.3600,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(0.1800, device='cuda:0') tensor([2545.8481, 3485.9053], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.2752, 8.3588], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1379.5167, device='cuda:0') total reward\n",
      "actions tensor([2470., 1530.]) 429.2775278858744\n",
      "tensor(1379.5167, device='cuda:0') tensor([1., 8., 1., 1., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  4.0000,  1.0000,  8.0000,  1.0000,  3.0000,\n",
      "         1.0000,  1.0000,  1.0000,  4.0000,  0.1531,  1.0000,  4.0000,  0.1701,\n",
      "         1.0000, 10.0000,  0.4724,  1.0000,  2.0000,  0.1181,  1.0000,  4.0000,\n",
      "         0.2592,  1.0000, 10.0000,  0.7200], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(0.1600, device='cuda:0') tensor([19562.7090, 19986.5137], device='cuda:0', grad_fn=<ViewBackward0>) tensor([5.5570, 5.7040], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([1]) tensor(0, device='cuda:0')\n",
      "we got  tensor(1436.2749, device='cuda:0') total reward\n",
      "actions tensor([2159., 1841.]) 407.8136514915807\n",
      "tensor(1436.2749, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  6.0000,  1.0000, 10.0000,  1.0000,  4.0000,\n",
      "         1.0000,  2.0000,  1.0000,  3.0000,  0.1575,  1.0000,  6.0000,  0.4374,\n",
      "         1.0000,  2.0000,  0.1166,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        4.0000, 1.0000, 4.0000, 0.2880, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(1.1322, device='cuda:0') tensor([2964.2341, 2750.1350], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.3905, 8.3836], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1411.0352, device='cuda:0') total reward\n",
      "actions tensor([2491., 1509.]) 387.42296891700164\n",
      "tensor(1411.0352, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000, 10.0000,  1.0000,  5.0000,  1.0000,  9.0000,\n",
      "         1.0000,  2.0000,  1.0000,  2.0000,  0.1440,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 2., 1., 9., 1., 7., 1., 1., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor([0]) tensor(1.2700, device='cuda:0') tensor([2232.1628, 1934.3861], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.6531, 7.6047], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor([1])\n",
      "we got  tensor(1373.5088, device='cuda:0') total reward\n",
      "actions tensor([2503., 1497.]) 368.05182047115153\n",
      "tensor(1373.5088, device='cuda:0') tensor([ 1.0000,  9.0000,  1.0000,  2.0000,  1.0000,  3.0000,  1.0000,  8.0000,\n",
      "         1.0000,  3.0000,  1.0000, 10.0000,  0.6561,  1.0000,  4.0000,  0.2592,\n",
      "         1.0000, 10.0000,  0.9000,  1.0000,  3.0000,  0.2160,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 2., 1., 7., 1., 1., 1., 3., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(0.1575, device='cuda:0') tensor([2465.0962, 2419.6550], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.9732, 7.8995], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1354.8143, device='cuda:0') total reward\n",
      "actions tensor([2348., 1652.]) 349.649229447594\n",
      "tensor(1354.8143, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  2.0000,  1.0000,  3.0000,  1.0000,  9.0000,\n",
      "         1.0000,  1.0000,  1.0000,  2.0000,  0.0850,  1.0000,  6.0000,  0.3543,\n",
      "         1.0000,  6.0000,  0.3937,  1.0000, 10.0000,  0.9000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 5., 1., 1., 1., 2., 1., 2., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(0.2000, device='cuda:0') tensor([1870.5255, 2232.7998], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.1223, 7.8225], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1442.9031, device='cuda:0') total reward\n",
      "actions tensor([2375., 1625.]) 332.16676797521427\n",
      "tensor(1442.9031, device='cuda:0') tensor([1.0000, 7.0000, 1.0000, 9.0000, 1.0000, 1.0000, 1.0000, 3.0000, 1.0000,\n",
      "        2.0000, 1.0000, 6.0000, 0.5400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1., 3., 1., 3., 1., 3., 1., 1., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(0.3000, device='cuda:0') tensor([1382.1525, 1262.2416], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.2699, 8.2169], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1422.8990, device='cuda:0') total reward\n",
      "actions tensor([2244., 1756.]) 315.55842957645353\n",
      "tensor(1422.8990, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  2.0000,  1.0000,  7.0000,  1.0000,  1.0000,\n",
      "         1.0000,  4.0000,  1.0000, 10.0000,  0.7290,  1.0000,  3.0000,  0.2160,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 2., 1., 4., 1., 4., 1., 7., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(1.0846, device='cuda:0') tensor([669.0245, 941.5583], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.4285, 7.4643], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1372.1993, device='cuda:0') total reward\n",
      "actions tensor([2099., 1901.]) 299.78050809763084\n",
      "tensor(1372.1993, device='cuda:0') tensor([ 1.0000, 10.0000,  1.0000,  2.0000,  1.0000,  2.0000,  1.0000,  1.0000,\n",
      "         1.0000,  3.0000,  1.0000, 10.0000,  0.4783,  1.0000,  4.0000,  0.2916,\n",
      "         1.0000,  3.0000,  0.1750,  1.0000,  6.0000,  0.4860,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 5.0000, 1.0000, 3.0000, 1.0000,\n",
      "        3.0000, 1.0000, 4.0000, 0.2880, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor([1]) tensor(0.7722, device='cuda:0') tensor([2926.9600, 3284.8313], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.1157, 8.1028], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1390.3793, device='cuda:0') total reward\n",
      "actions tensor([2439., 1561.]) 284.7914826927493\n",
      "tensor(1390.3793, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  4.0000,  1.0000,  2.0000,  1.0000,  2.0000,\n",
      "         1.0000, 10.0000,  1.0000, 10.0000,  0.5314,  1.0000, 10.0000,  0.7290,\n",
      "         1.0000,  2.0000,  0.1166,  1.0000,  2.0000,  0.1440,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000, 10.0000,  1.0000,  4.0000,  1.0000,  2.0000,\n",
      "         1.0000,  3.0000,  1.0000,  6.0000,  0.4320,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(1.7305, device='cuda:0') tensor([4242.6226, 4794.5776], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.5345, 7.5530], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor([1])\n",
      "we got  tensor(1283.1432, device='cuda:0') total reward\n",
      "actions tensor([1526., 2474.]) 270.5519085581118\n",
      "tensor(1283.1432, device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 3.0000, 1.0000,\n",
      "        7.0000, 1.0000, 2.0000, 0.0945, 1.0000, 2.0000, 0.1166, 1.0000, 4.0000,\n",
      "        0.2880, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  4.0000,  1.0000,  5.0000,  1.0000,  3.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.5832,  1.0000,  6.0000,  0.3888,\n",
      "         1.0000,  4.0000,  0.3240,  1.0000, 10.0000,  0.7200,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(0.3118, device='cuda:0') tensor([1830.1693, 2022.1592], device='cuda:0', grad_fn=<ViewBackward0>) tensor([6.6666, 6.8123], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([0]) tensor(0, device='cuda:0')\n",
      "we got  tensor(927.6019, device='cuda:0') total reward\n",
      "actions tensor([ 655., 3345.]) 257.02431313020617\n",
      "tensor(927.6019, device='cuda:0') tensor([1., 3., 1., 2., 1., 5., 0., 0., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000,  3.0000,  1.0000,  2.0000,  1.0000,  6.0000,\n",
      "         1.0000,  5.0000,  1.0000,  3.0000,  0.1594,  1.0000,  6.0000,  0.2834,\n",
      "         1.0000, 10.0000,  0.5249,  1.0000, 10.0000,  0.5832,  1.0000,  6.0000,\n",
      "         0.3888,  1.0000,  6.0000,  0.4320], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(0.2400, device='cuda:0') tensor([2011.1578, 2219.8906], device='cuda:0', grad_fn=<ViewBackward0>) tensor([4.9069, 5.0145], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([1]) tensor(1, device='cuda:0')\n",
      "we got  tensor(755.6595, device='cuda:0') total reward\n",
      "actions tensor([ 534., 3466.]) 244.17309747369586\n",
      "tensor(755.6595, device='cuda:0') tensor([1., 2., 1., 4., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  5.0000,  1.0000,  6.0000,  1.0000,  6.0000,\n",
      "         1.0000,  5.0000,  1.0000, 10.0000,  0.6480,  1.0000, 10.0000,  0.7200,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1]) tensor(0, device='cuda:0') tensor(1.0587, device='cuda:0') tensor([1584.5085, 1777.1594], device='cuda:0', grad_fn=<ViewBackward0>) tensor([4.9578, 4.8671], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(818.1415, device='cuda:0') total reward\n",
      "actions tensor([ 549., 3451.]) 231.96444260001107\n",
      "tensor(818.1415, device='cuda:0') tensor([1., 1., 1., 4., 1., 4., 1., 2., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 6.0000, 1.0000, 1.0000, 1.0000, 4.0000, 1.0000,\n",
      "        3.0000, 1.0000, 2.0000, 0.1181, 1.0000, 4.0000, 0.2100, 1.0000, 4.0000,\n",
      "        0.2333, 1.0000, 4.0000, 0.2880, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(0.8134, device='cuda:0') tensor([1605.6204, 1759.1017], device='cuda:0', grad_fn=<ViewBackward0>) tensor([6.8189, 6.6208], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([1]) tensor([1])\n",
      "we got  tensor(940.6434, device='cuda:0') total reward\n",
      "actions tensor([ 845., 3155.]) 220.36622047001052\n",
      "tensor(940.6434, device='cuda:0') tensor([1., 3., 1., 5., 1., 3., 1., 2., 1., 6., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 5.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 3.0000, 1.0000,\n",
      "        7.0000, 1.0000, 6.0000, 0.3499, 1.0000, 3.0000, 0.2187, 1.0000, 6.0000,\n",
      "        0.3888, 1.0000, 3.0000, 0.2430, 1.0000, 6.0000, 0.4320, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([0]) tensor([1]) tensor(0.3350, device='cuda:0') tensor([1196.9462, 1300.8896], device='cuda:0', grad_fn=<ViewBackward0>) tensor([6.2861, 6.2218], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1127.1833, device='cuda:0') total reward\n",
      "actions tensor([1090., 2910.]) 209.34790944650996\n",
      "tensor(1127.1833, device='cuda:0') tensor([1., 2., 1., 2., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000,\n",
      "        2.0000, 1.0000, 4.0000, 0.1701, 1.0000, 4.0000, 0.1890, 1.0000, 6.0000,\n",
      "        0.3149, 1.0000, 6.0000, 0.3499, 1.0000, 3.0000, 0.2187, 1.0000, 6.0000,\n",
      "        0.3888], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(-0.0400, device='cuda:0') tensor([500.5650, 572.4407], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.0650, 7.1157], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1251.2054, device='cuda:0') total reward\n",
      "actions tensor([1448., 2552.]) 198.88051397418445\n",
      "tensor(1251.2054, device='cuda:0') tensor([ 1., 10.,  1.,  8.,  1.,  2.,  1.,  3.,  1.,  3.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([ 1.0000,  8.0000,  1.0000,  4.0000,  1.0000,  1.0000,  1.0000,  3.0000,\n",
      "         1.0000,  2.0000,  1.0000,  6.0000,  0.2834,  1.0000, 10.0000,  0.5249,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0') tensor(1.3490, device='cuda:0') tensor([ 94.8139, -12.1678], device='cuda:0', grad_fn=<ViewBackward0>) tensor([6.6988, 6.8473], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1296.2894, device='cuda:0') total reward\n",
      "actions tensor([1642., 2358.]) 188.93648827547523\n",
      "tensor(1296.2894, device='cuda:0') tensor([ 1.0000, 10.0000,  1.0000,  2.0000,  1.0000,  6.0000,  1.0000,  5.0000,\n",
      "         1.0000,  4.0000,  1.0000, 10.0000,  0.8100,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 3.0000, 1.0000, 3.0000, 1.0000, 4.0000, 1.0000,\n",
      "        2.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(1.4000, device='cuda:0') tensor([498.0548, 507.0038], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.2662, 8.1946], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1256.1936, device='cuda:0') total reward\n",
      "actions tensor([1959., 2041.]) 179.48966386170147\n",
      "tensor(1256.1936, device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  7.0000,  1.0000,  4.0000,  1.0000,  5.0000,\n",
      "         1.0000,  8.0000,  1.0000,  4.0000,  0.2100,  1.0000,  6.0000,  0.4374,\n",
      "         1.0000,  4.0000,  0.3240,  1.0000, 10.0000,  0.9000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 3., 1., 1., 1., 1., 1., 3., 1., 5., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(0.5100, device='cuda:0') tensor([-782.6479, -875.8077], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.3856, 8.0191], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1347.3163, device='cuda:0') total reward\n",
      "actions tensor([2120., 1880.]) 170.5151806686164\n",
      "tensor(1347.3163, device='cuda:0') tensor([ 1.0000,  9.0000,  1.0000,  8.0000,  1.0000,  4.0000,  1.0000, 10.0000,\n",
      "         1.0000,  9.0000,  1.0000,  4.0000,  0.1890,  1.0000,  6.0000,  0.3937,\n",
      "         1.0000, 10.0000,  0.8100,  1.0000, 10.0000,  0.9000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 2., 0., 0., 0., 0., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1]) tensor(0, device='cuda:0') tensor(0.8561, device='cuda:0') tensor([-823.5911, -968.3256], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.0222, 7.7047], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1324.9291, device='cuda:0') total reward\n",
      "actions tensor([2260., 1740.]) 161.98942163518558\n",
      "tensor(1324.9291, device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  4.0000,  1.0000,  4.0000,  1.0000,  2.0000,\n",
      "         1.0000,  5.0000,  1.0000,  4.0000,  0.2592,  1.0000, 10.0000,  0.9000,\n",
      "         1.0000,  3.0000,  0.2160,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 4.0000, 1.0000, 5.0000, 1.0000, 7.0000, 1.0000,\n",
      "        4.0000, 1.0000, 4.0000, 0.2333, 1.0000, 6.0000, 0.3888, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0') tensor(0.5728, device='cuda:0') tensor([455.5376, 391.1208], device='cuda:0', grad_fn=<ViewBackward0>) tensor([6.7064, 6.7733], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([0]) tensor([0])\n",
      "we got  tensor(1280.2587, device='cuda:0') total reward\n",
      "actions tensor([2023., 1977.]) 153.88995055342627\n",
      "tensor(1280.2587, device='cuda:0') tensor([ 1.0000,  9.0000,  1.0000,  3.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "         1.0000, 10.0000,  1.0000,  3.0000,  0.1750,  1.0000,  4.0000,  0.3240,\n",
      "         1.0000,  3.0000,  0.1944,  1.0000, 10.0000,  0.9000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 5., 1., 3., 1., 6., 1., 2., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(1.1100, device='cuda:0') tensor([-479.9331, -709.0956], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.5439, 7.4720], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1342.3702, device='cuda:0') total reward\n",
      "actions tensor([2153., 1847.]) 146.19545302575494\n",
      "tensor(1342.3702, device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 4.0000, 1.0000,\n",
      "        6.0000, 1.0000, 4.0000, 0.2362, 1.0000, 4.0000, 0.2880, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 6.0000, 1.0000, 2.0000, 1.0000,\n",
      "        2.0000, 1.0000, 2.0000, 0.1620, 1.0000, 6.0000, 0.4320, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(0.7863, device='cuda:0') tensor([1038.6708, 1132.2552], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.0611, 8.1848], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1225.4480, device='cuda:0') total reward\n",
      "actions tensor([1669., 2331.]) 138.8856803744672\n",
      "tensor(1225.4480, device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 3.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000,\n",
      "        2.0000, 1.0000, 4.0000, 0.2333, 1.0000, 3.0000, 0.1944, 1.0000, 3.0000,\n",
      "        0.2160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  6.0000,  1.0000,  8.0000,  1.0000,  1.0000,\n",
      "         1.0000,  9.0000,  1.0000,  3.0000,  0.1771,  1.0000,  4.0000,  0.2100,\n",
      "         1.0000,  4.0000,  0.2333,  1.0000,  6.0000,  0.3888,  1.0000, 10.0000,\n",
      "         0.7200,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(0.1166, device='cuda:0') tensor([284.5822, 301.5752], device='cuda:0', grad_fn=<ViewBackward0>) tensor([4.4635, 4.6324], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1333.1710, device='cuda:0') total reward\n",
      "actions tensor([1857., 2143.]) 131.94139635574382\n",
      "tensor(1333.1710, device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  3.0000,  1.0000, 10.0000,  1.0000,  5.0000,\n",
      "         1.0000,  2.0000,  1.0000,  6.0000,  0.3189,  1.0000, 10.0000,  0.5905,\n",
      "         1.0000,  4.0000,  0.2916,  1.0000,  6.0000,  0.4860,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 6., 1., 2., 1., 3., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(1.3114, device='cuda:0') tensor([162.9017, 224.4700], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.1341, 7.6876], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1312.7677, device='cuda:0') total reward\n",
      "actions tensor([1653., 2347.]) 125.3443265379566\n",
      "tensor(1312.7677, device='cuda:0') tensor([1.0000, 7.0000, 1.0000, 6.0000, 1.0000, 5.0000, 1.0000, 3.0000, 1.0000,\n",
      "        3.0000, 1.0000, 4.0000, 0.2592, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 9.0000, 1.0000, 7.0000, 1.0000,\n",
      "        4.0000, 1.0000, 2.0000, 0.1800, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0') tensor(0., device='cuda:0') tensor([ -83.1378, -143.7750], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.2646, 7.3186], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1226.5500, device='cuda:0') total reward\n",
      "actions tensor([1449., 2551.]) 119.07711021105877\n",
      "tensor(1226.5500, device='cuda:0') tensor([ 1.0000,  6.0000,  1.0000,  9.0000,  1.0000,  3.0000,  1.0000,  2.0000,\n",
      "         1.0000,  1.0000,  1.0000,  4.0000,  0.3240,  1.0000, 10.0000,  0.9000,\n",
      "         1.0000,  2.0000,  0.1440,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 3., 1., 5., 1., 2., 1., 1., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(0.4644, device='cuda:0') tensor([782.7303, 658.1727], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.9772, 7.9729], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor([0])\n",
      "we got  tensor(1285.8369, device='cuda:0') total reward\n",
      "actions tensor([1579., 2421.]) 113.12325470050583\n",
      "tensor(1285.8369, device='cuda:0') tensor([1., 2., 1., 2., 1., 2., 1., 6., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  2.0000,  1.0000,  7.0000,  1.0000,  3.0000,\n",
      "         1.0000,  8.0000,  1.0000,  2.0000,  0.1181,  1.0000, 10.0000,  0.5249,\n",
      "         1.0000,  3.0000,  0.1968,  1.0000,  6.0000,  0.3499,  1.0000,  2.0000,\n",
      "         0.1458,  1.0000, 10.0000,  0.6480], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(0.1040, device='cuda:0') tensor([299.2975, 319.3353], device='cuda:0', grad_fn=<ViewBackward0>) tensor([4.9294, 4.9860], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1268.3781, device='cuda:0') total reward\n",
      "actions tensor([1556., 2444.]) 107.46709196548053\n",
      "tensor(1268.3781, device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  7.0000,  1.0000,  2.0000,  1.0000,  2.0000,\n",
      "         1.0000,  5.0000,  1.0000, 10.0000,  0.5905,  1.0000,  4.0000,  0.1890,\n",
      "         1.0000,  4.0000,  0.2624,  1.0000,  6.0000,  0.4374,  1.0000,  4.0000,\n",
      "         0.2592,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.,  1.,  1., 10.,  1.,  1.,  1.,  9.,  1.,  4.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(1.2000, device='cuda:0') tensor([50.2756, 53.7202], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.1629, 7.1266], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1352.5558, device='cuda:0') total reward\n",
      "actions tensor([1612., 2388.]) 102.0937373672065\n",
      "tensor(1352.5558, device='cuda:0') tensor([1., 2., 1., 2., 1., 9., 1., 5., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 6.0000, 1.0000, 6.0000, 1.0000,\n",
      "        4.0000, 1.0000, 2.0000, 0.1312, 1.0000, 2.0000, 0.1620, 1.0000, 6.0000,\n",
      "        0.4320, 1.0000, 2.0000, 0.1800, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(0.3499, device='cuda:0') tensor([38.4776, 40.2789], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.2336, 7.2545], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1382.5420, device='cuda:0') total reward\n",
      "actions tensor([1889., 2111.]) 96.98905049884618\n",
      "tensor(1382.5420, device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 4.0000, 1.0000, 4.0000, 1.0000, 3.0000, 1.0000,\n",
      "        3.0000, 1.0000, 4.0000, 0.3600, 1.0000, 3.0000, 0.2160, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 4.0000, 1.0000,\n",
      "        3.0000, 1.0000, 6.0000, 0.3888, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(1.2010, device='cuda:0') tensor([21.5915, 26.8423], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.0187, 7.9704], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1415.6730, device='cuda:0') total reward\n",
      "actions tensor([2106., 1894.]) 92.13959797390386\n",
      "tensor(1415.6730, device='cuda:0') tensor([1., 6., 1., 4., 1., 2., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  7.0000,  1.0000,  3.0000,  1.0000,  8.0000,  1.0000,  2.0000,\n",
      "         1.0000,  5.0000,  1.0000, 10.0000,  0.7200,  1.0000,  3.0000,  0.2700,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(0., device='cuda:0') tensor([28.3753, 33.2109], device='cuda:0', grad_fn=<ViewBackward0>) tensor([6.4094, 6.6492], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1415.0808, device='cuda:0') total reward\n",
      "actions tensor([2010., 1990.]) 87.53261807520866\n",
      "tensor(1415.0808, device='cuda:0') tensor([1., 5., 1., 1., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  4.0000,  1.0000,  4.0000,  1.0000,  5.0000,\n",
      "         1.0000,  8.0000,  1.0000,  4.0000,  0.2916,  1.0000, 10.0000,  0.6480,\n",
      "         1.0000,  6.0000,  0.4320,  1.0000,  4.0000,  0.3600,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(0.2592, device='cuda:0') tensor([73.5764, 75.1115], device='cuda:0', grad_fn=<ViewBackward0>) tensor([5.0141, 4.9624], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1441.2445, device='cuda:0') total reward\n",
      "actions tensor([2030., 1970.]) 83.15598717144823\n",
      "tensor(1441.2445, device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 3.0000, 1.0000, 1.0000, 1.0000, 3.0000, 1.0000,\n",
      "        2.0000, 1.0000, 3.0000, 0.1944, 1.0000, 4.0000, 0.3600, 1.0000, 4.0000,\n",
      "        0.2880, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000,  3.0000,  1.0000,  8.0000,  1.0000,  2.0000,\n",
      "         1.0000,  2.0000,  1.0000,  4.0000,  0.2126,  1.0000, 10.0000,  0.4724,\n",
      "         1.0000,  6.0000,  0.3149,  1.0000, 10.0000,  0.5832,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0') tensor(0., device='cuda:0') tensor([8.4507, 3.8325], device='cuda:0', grad_fn=<ViewBackward0>) tensor([5.3456, 5.4090], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1465.3126, device='cuda:0') total reward\n",
      "actions tensor([2060., 1940.]) 78.99818781287581\n",
      "tensor(1465.3126, device='cuda:0') tensor([1., 3., 1., 7., 1., 1., 1., 2., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 9.0000, 1.0000, 4.0000, 1.0000, 1.0000, 1.0000,\n",
      "        3.0000, 1.0000, 4.0000, 0.2880, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(0.2430, device='cuda:0') tensor([111.5981, 113.4633], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.4160, 7.5447], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1463.9602, device='cuda:0') total reward\n",
      "actions tensor([2075., 1925.]) 75.04827842223202\n",
      "tensor(1463.9602, device='cuda:0') tensor([1.0000, 9.0000, 1.0000, 9.0000, 1.0000, 5.0000, 1.0000, 2.0000, 1.0000,\n",
      "        1.0000, 1.0000, 6.0000, 0.5400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1., 8., 1., 2., 1., 2., 1., 1., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(0.3440, device='cuda:0') tensor([30.1977, 32.5606], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.8396, 7.7170], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1499.8636, device='cuda:0') total reward\n",
      "actions tensor([2142., 1858.]) 71.29586450112042\n",
      "tensor(1499.8636, device='cuda:0') tensor([1.0000, 5.0000, 1.0000, 4.0000, 1.0000, 2.0000, 1.0000, 4.0000, 1.0000,\n",
      "        1.0000, 1.0000, 4.0000, 0.2100, 1.0000, 6.0000, 0.5400, 1.0000, 4.0000,\n",
      "        0.2880, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1., 2., 1., 3., 1., 4., 1., 5., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(0.2700, device='cuda:0') tensor([0.7515, 3.9109], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.9451, 7.7647], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1473.2836, device='cuda:0') total reward\n",
      "actions tensor([2069., 1931.]) 67.7310712760644\n",
      "tensor(1473.2836, device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 5.0000, 1.0000, 6.0000, 1.0000, 1.0000, 1.0000,\n",
      "        4.0000, 1.0000, 2.0000, 0.1166, 1.0000, 4.0000, 0.2880, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  5.0000,  1.0000,  9.0000,  1.0000,  4.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.7200,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(1.0210, device='cuda:0') tensor([49.9646, 50.2192], device='cuda:0', grad_fn=<ViewBackward0>) tensor([6.8161, 7.1009], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1488.8313, device='cuda:0') total reward\n",
      "actions tensor([2092., 1908.]) 64.34451771226117\n",
      "tensor(1488.8313, device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 4.0000, 1.0000, 8.0000, 1.0000, 7.0000, 1.0000,\n",
      "        2.0000, 1.0000, 4.0000, 0.1890, 1.0000, 4.0000, 0.2333, 1.0000, 6.0000,\n",
      "        0.4860, 1.0000, 4.0000, 0.3600, 1.0000, 2.0000, 0.1440, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1., 5., 1., 7., 1., 4., 1., 2., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(0.6224, device='cuda:0') tensor([42.1370, 39.6108], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.5024, 7.4900], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor([1])\n",
      "we got  tensor(1462.9133, device='cuda:0') total reward\n",
      "actions tensor([2143., 1857.]) 61.12729182664811\n",
      "tensor(1462.9133, device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 4.0000, 1.0000, 5.0000, 1.0000, 9.0000, 1.0000,\n",
      "        1.0000, 1.0000, 3.0000, 0.2160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 5.0000, 1.0000, 2.0000, 1.0000, 2.0000, 1.0000,\n",
      "        5.0000, 1.0000, 4.0000, 0.2880, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0') tensor(0.3240, device='cuda:0') tensor([59.8668, 59.5236], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.4223, 7.5208], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1483.1855, device='cuda:0') total reward\n",
      "actions tensor([2148., 1852.]) 58.07092723531571\n",
      "tensor(1483.1855, device='cuda:0') tensor([1., 4., 1., 8., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  1.0000,  1.0000,  3.0000,  1.0000,  1.0000,\n",
      "         1.0000,  4.0000,  1.0000, 10.0000,  0.7200,  1.0000,  4.0000,  0.3600,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0') tensor(0.3600, device='cuda:0') tensor([38.1084, 34.9707], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.1064, 8.1674], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1451.1547, device='cuda:0') total reward\n",
      "actions tensor([1970., 2030.]) 55.16738087354992\n",
      "tensor(1451.1547, device='cuda:0') tensor([1.0000, 9.0000, 1.0000, 4.0000, 1.0000, 6.0000, 1.0000, 1.0000, 1.0000,\n",
      "        6.0000, 1.0000, 3.0000, 0.2160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 7.0000, 1.0000, 4.0000, 1.0000, 2.0000, 1.0000,\n",
      "        1.0000, 1.0000, 2.0000, 0.1620, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(1.1504, device='cuda:0') tensor([-56.3117, -57.2914], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.0852, 7.8743], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1471.8137, device='cuda:0') total reward\n",
      "actions tensor([2018., 1982.]) 52.40901182987242\n",
      "tensor(1471.8137, device='cuda:0') tensor([ 1.,  3.,  1., 10.,  1.,  3.,  1.,  8.,  1.,  2.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 4.0000, 1.0000, 4.0000, 1.0000, 5.0000, 1.0000,\n",
      "        5.0000, 1.0000, 6.0000, 0.3149, 1.0000, 2.0000, 0.1458, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(1.2400, device='cuda:0') tensor([270.9857, 281.0211], device='cuda:0', grad_fn=<ViewBackward0>) tensor([6.8210, 6.8419], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1421.9653, device='cuda:0') total reward\n",
      "actions tensor([1856., 2144.]) 49.7885612383788\n",
      "tensor(1421.9653, device='cuda:0') tensor([1.0000, 8.0000, 1.0000, 1.0000, 1.0000, 8.0000, 1.0000, 2.0000, 1.0000,\n",
      "        2.0000, 1.0000, 4.0000, 0.2100, 1.0000, 3.0000, 0.1750, 1.0000, 4.0000,\n",
      "        0.2592, 1.0000, 4.0000, 0.2880, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  6.0000,  1.0000,  6.0000,  1.0000,  4.0000,\n",
      "         1.0000,  7.0000,  1.0000, 10.0000,  0.6480,  1.0000, 10.0000,  0.7200,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(0.3888, device='cuda:0') tensor([18.0568, 18.7568], device='cuda:0', grad_fn=<ViewBackward0>) tensor([5.8740, 6.0608], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1441.8511, device='cuda:0') total reward\n",
      "actions tensor([2038., 1962.]) 47.299133176459854\n",
      "tensor(1441.8511, device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000,  4.0000,  1.0000,  6.0000,  1.0000,  7.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.6561,  1.0000,  4.0000,  0.2880,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 4.0000, 1.0000, 4.0000, 1.0000, 3.0000, 1.0000,\n",
      "        1.0000, 1.0000, 6.0000, 0.4320, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(0.7537, device='cuda:0') tensor([179.2370, 178.9842], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.9404, 7.9395], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1455.1335, device='cuda:0') total reward\n",
      "actions tensor([2004., 1996.]) 44.93417651763686\n",
      "tensor(1455.1335, device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 9.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        2.0000, 1.0000, 6.0000, 0.3937, 1.0000, 6.0000, 0.4374, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1., 9., 1., 3., 1., 4., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(1.1000, device='cuda:0') tensor([148.1081, 151.2425], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.6774, 7.5212], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1493.3925, device='cuda:0') total reward\n",
      "actions tensor([2005., 1995.]) 42.68746769175502\n",
      "tensor(1493.3925, device='cuda:0') tensor([1.0000, 9.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 3.0000, 1.0000,\n",
      "        6.0000, 1.0000, 3.0000, 0.1750, 1.0000, 6.0000, 0.5400, 1.0000, 3.0000,\n",
      "        0.2160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000, 10.0000,  1.0000,  9.0000,  1.0000,  1.0000,  1.0000,  3.0000,\n",
      "         1.0000,  6.0000,  1.0000,  4.0000,  0.3240,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0') tensor(0.8950, device='cuda:0') tensor([-23.7502, -25.1323], device='cuda:0', grad_fn=<ViewBackward0>) tensor([6.5964, 6.8254], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1460.1853, device='cuda:0') total reward\n",
      "actions tensor([1930., 2070.]) 40.553094307167264\n",
      "tensor(1460.1853, device='cuda:0') tensor([1., 1., 1., 7., 1., 1., 1., 8., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  7.0000,  1.0000,  2.0000,  1.0000,  4.0000,  1.0000,  1.0000,\n",
      "         1.0000,  1.0000,  1.0000, 10.0000,  0.7200,  1.0000,  4.0000,  0.3600,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(0.3600, device='cuda:0') tensor([13.5099, 14.3819], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.8118, 7.8327], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1470.3447, device='cuda:0') total reward\n",
      "actions tensor([1996., 2004.]) 38.5254395918089\n",
      "tensor(1470.3447, device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  2.0000,  1.0000,  2.0000,  1.0000,  2.0000,\n",
      "         1.0000,  1.0000,  1.0000,  4.0000,  0.2624,  1.0000,  4.0000,  0.2100,\n",
      "         1.0000, 10.0000,  0.7290,  1.0000,  2.0000,  0.1440,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 2.0000, 1.0000, 3.0000, 1.0000, 9.0000, 1.0000,\n",
      "        7.0000, 1.0000, 6.0000, 0.4320, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(0.2700, device='cuda:0') tensor([33.3346, 34.9972], device='cuda:0', grad_fn=<ViewBackward0>) tensor([6.8695, 6.9775], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1499.9364, device='cuda:0') total reward\n",
      "actions tensor([2049., 1951.]) 36.59916761221845\n",
      "tensor(1499.9364, device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  1.0000,  1.0000,  5.0000,  1.0000,  2.0000,\n",
      "         1.0000,  4.0000,  1.0000,  6.0000,  0.4374,  1.0000, 10.0000,  0.8100,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 4.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000,\n",
      "        3.0000, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(0.3200, device='cuda:0') tensor([75.2266, 77.4036], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.1615, 8.0702], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1454.8699, device='cuda:0') total reward\n",
      "actions tensor([2032., 1968.]) 34.769209231607526\n",
      "tensor(1454.8699, device='cuda:0') tensor([1., 4., 1., 5., 1., 4., 1., 2., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  3.0000,  1.0000,  2.0000,  1.0000,  8.0000,  1.0000,  5.0000,\n",
      "         1.0000,  6.0000,  1.0000,  6.0000,  0.2551,  1.0000, 10.0000,  0.4724,\n",
      "         1.0000,  4.0000,  0.2362,  1.0000,  6.0000,  0.3149,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(1.1831, device='cuda:0') tensor([144.3976, 149.2626], device='cuda:0', grad_fn=<ViewBackward0>) tensor([5.5019, 5.5232], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1414.9703, device='cuda:0') total reward\n",
      "actions tensor([1910., 2090.]) 33.03074877002715\n",
      "tensor(1414.9703, device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 1.0000, 1.0000, 8.0000, 1.0000, 4.0000, 1.0000,\n",
      "        4.0000, 1.0000, 6.0000, 0.4374, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 4.0000, 1.0000, 1.0000, 1.0000, 5.0000, 1.0000,\n",
      "        1.0000, 1.0000, 2.0000, 0.1800, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(1.0233, device='cuda:0') tensor([32.4510, 34.7712], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.1032, 8.0965], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1475.4313, device='cuda:0') total reward\n",
      "actions tensor([2175., 1825.]) 31.37921133152579\n",
      "tensor(1475.4313, device='cuda:0') tensor([ 1.0000,  6.0000,  1.0000,  3.0000,  1.0000,  1.0000,  1.0000,  2.0000,\n",
      "         1.0000,  4.0000,  1.0000,  6.0000,  0.4860,  1.0000,  4.0000,  0.2592,\n",
      "         1.0000, 10.0000,  0.9000,  1.0000,  3.0000,  0.2160,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 4., 1., 8., 1., 7., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(0.1944, device='cuda:0') tensor([16.7221, 18.7105], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.4589, 7.4447], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1486.8988, device='cuda:0') total reward\n",
      "actions tensor([2081., 1919.]) 29.8102507649495\n",
      "tensor(1486.8988, device='cuda:0') tensor([1., 2., 1., 5., 1., 1., 1., 3., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  3.0000,  1.0000,  8.0000,  1.0000,  1.0000,\n",
      "         1.0000,  5.0000,  1.0000,  3.0000,  0.2430,  1.0000, 10.0000,  0.7200,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(0.3200, device='cuda:0') tensor([67.8515, 68.4529], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.4048, 7.6014], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1472.7288, device='cuda:0') total reward\n",
      "actions tensor([2062., 1938.]) 28.31973822670202\n",
      "tensor(1472.7288, device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 2.0000, 1.0000, 4.0000, 1.0000, 3.0000, 1.0000,\n",
      "        4.0000, 1.0000, 3.0000, 0.1750, 1.0000, 4.0000, 0.2592, 1.0000, 2.0000,\n",
      "        0.1440, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 6.0000, 1.0000, 3.0000, 1.0000, 8.0000, 1.0000,\n",
      "        1.0000, 1.0000, 4.0000, 0.2880, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(0.8811, device='cuda:0') tensor([60.9892, 58.9906], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.5560, 7.5335], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1451.9902, device='cuda:0') total reward\n",
      "actions tensor([1934., 2066.]) 26.90375131536692\n",
      "tensor(1451.9902, device='cuda:0') tensor([ 1., 10.,  1.,  2.,  1.,  2.,  1.,  3.,  1.,  3.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 2.0000, 1.0000, 4.0000, 1.0000, 1.0000, 1.0000,\n",
      "        2.0000, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(1.5170, device='cuda:0') tensor([-29.9084, -35.0692], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.1121, 8.0629], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1507.2926, device='cuda:0') total reward\n",
      "actions tensor([2078., 1922.]) 25.558563749598573\n",
      "tensor(1507.2926, device='cuda:0') tensor([ 1.0000, 10.0000,  1.0000,  1.0000,  1.0000,  3.0000,  1.0000,  6.0000,\n",
      "         1.0000,  7.0000,  1.0000,  4.0000,  0.3240,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 4.0000, 1.0000, 1.0000, 1.0000, 3.0000, 1.0000,\n",
      "        1.0000, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(1.5350, device='cuda:0') tensor([1.0713, 2.2627], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.0925, 7.9294], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1478.1105, device='cuda:0') total reward\n",
      "actions tensor([2062., 1938.]) 24.280635562118643\n",
      "tensor(1478.1105, device='cuda:0') tensor([ 1.0000,  2.0000,  1.0000,  1.0000,  1.0000,  3.0000,  1.0000,  3.0000,\n",
      "         1.0000,  4.0000,  1.0000, 10.0000,  0.6561,  1.0000, 10.0000,  0.7290,\n",
      "         1.0000,  4.0000,  0.3240,  1.0000,  4.0000,  0.3600,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 4., 1., 3., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(0.7650, device='cuda:0') tensor([-64.6932, -61.6447], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.1447, 8.0865], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor([0]) tensor(1, device='cuda:0')\n",
      "we got  tensor(1502.4288, device='cuda:0') total reward\n",
      "actions tensor([2052., 1948.]) 23.06660378401271\n",
      "tensor(1502.4288, device='cuda:0') tensor([ 1.0000,  5.0000,  1.0000,  7.0000,  1.0000,  2.0000,  1.0000,  9.0000,\n",
      "         1.0000,  1.0000,  1.0000,  2.0000,  0.1050,  1.0000, 10.0000,  0.7290,\n",
      "         1.0000,  3.0000,  0.1750,  1.0000, 10.0000,  0.8100,  1.0000, 10.0000,\n",
      "         0.9000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1., 2., 1., 3., 1., 1., 1., 8., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(0.3000, device='cuda:0') tensor([-75.2307, -71.1681], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.8869, 7.7545], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1507.9462, device='cuda:0') total reward\n",
      "actions tensor([1995., 2005.]) 21.913273594812075\n",
      "tensor(1507.9462, device='cuda:0') tensor([1.0000, 6.0000, 1.0000, 1.0000, 1.0000, 9.0000, 1.0000, 4.0000, 1.0000,\n",
      "        3.0000, 1.0000, 3.0000, 0.2160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1., 5., 1., 6., 1., 4., 1., 5., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(1.4414, device='cuda:0') tensor([30.1288, 31.2336], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.0560, 7.2136], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1490.1970, device='cuda:0') total reward\n",
      "actions tensor([2176., 1824.]) 20.817609915071472\n",
      "tensor(1490.1970, device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 4.0000, 1.0000, 1.0000, 1.0000, 6.0000, 1.0000,\n",
      "        8.0000, 1.0000, 4.0000, 0.2100, 1.0000, 6.0000, 0.4374, 1.0000, 4.0000,\n",
      "        0.3240, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1., 3., 1., 1., 1., 6., 1., 1., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0') tensor(1.4874, device='cuda:0') tensor([35.6247, 37.6518], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.1061, 7.8284], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1505.4458, device='cuda:0') total reward\n",
      "actions tensor([2116., 1884.]) 19.776729419317896\n",
      "tensor(1505.4458, device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 1.0000, 1.0000, 5.0000, 1.0000, 2.0000, 1.0000,\n",
      "        4.0000, 1.0000, 4.0000, 0.2362, 1.0000, 4.0000, 0.2624, 1.0000, 3.0000,\n",
      "        0.1575, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  2.0000,  1.0000,  4.0000,  1.0000,  2.0000,\n",
      "         1.0000,  3.0000,  1.0000, 10.0000,  0.7200,  1.0000,  2.0000,  0.1800,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0') tensor(0.7673, device='cuda:0') tensor([ -6.1050, -10.2285], device='cuda:0', grad_fn=<ViewBackward0>) tensor([8.1253, 8.2158], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1494.4127, device='cuda:0') total reward\n",
      "actions tensor([2028., 1972.]) 18.787892948352003\n",
      "tensor(1494.4127, device='cuda:0') tensor([1., 4., 1., 8., 0., 0., 1., 1., 1., 7., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 7.0000, 1.0000, 4.0000, 1.0000, 2.0000, 1.0000,\n",
      "        4.0000, 1.0000, 4.0000, 0.2592, 1.0000, 2.0000, 0.1620, 1.0000, 4.0000,\n",
      "        0.2880, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(0.8708, device='cuda:0') tensor([42.1178, 42.8193], device='cuda:0', grad_fn=<ViewBackward0>) tensor([6.9325, 7.0607], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "we got  tensor(1522.1589, device='cuda:0') total reward\n",
      "actions tensor([2096., 1904.]) 17.8484983009344\n",
      "tensor(1522.1589, device='cuda:0') tensor([ 1.,  7.,  1., 10.,  1.,  5.,  1.,  4.,  1.,  7.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 5.0000, 1.0000, 3.0000, 1.0000, 4.0000, 1.0000,\n",
      "        3.0000, 1.0000, 3.0000, 0.2430, 1.0000, 2.0000, 0.1800, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0') tensor(1.5871, device='cuda:0') tensor([130.6882, 112.7914], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.7588, 7.8532], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1516.3657, device='cuda:0') total reward\n",
      "actions tensor([2217., 1783.]) 16.956073385887677\n",
      "tensor(1516.3657, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  3.0000,  1.0000, 10.0000,  1.0000,  1.0000,\n",
      "         1.0000,  4.0000,  1.0000,  4.0000,  0.2333,  1.0000,  4.0000,  0.2592,\n",
      "         1.0000,  6.0000,  0.5400,  1.0000,  3.0000,  0.2160,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1., 10.,  1.,  6.,  1.,  1.,  1.,  6.,  1.,  4.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(1.5300, device='cuda:0') tensor([18.7031, 19.1560], device='cuda:0', grad_fn=<ViewBackward0>) tensor([7.0467, 7.0962], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "we got  tensor(1500.7014, device='cuda:0') total reward\n",
      "actions tensor([2051., 1949.]) 16.10826971659329\n",
      "tensor(1500.7014, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  5.0000,  1.0000,  1.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.6561,  1.0000,  3.0000,  0.1575,\n",
      "         1.0000, 10.0000,  0.7290,  1.0000,  4.0000,  0.2333,  1.0000,  3.0000,\n",
      "         0.1944,  1.0000,  3.0000,  0.2160], device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  6.0000,  1.0000,  7.0000,  1.0000,  2.0000,\n",
      "         1.0000,  5.0000,  1.0000, 10.0000,  0.7200,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(1, device='cuda:0') tensor(0.4320, device='cuda:0') tensor([34.5168, 34.8801], device='cuda:0', grad_fn=<ViewBackward0>) tensor([6.9232, 7.0817], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "initial actions tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [316], line 143\u001b[0m\n\u001b[0;32m    140\u001b[0m replay_actual_q_values_1 \u001b[38;5;241m=\u001b[39m model_1\u001b[38;5;241m.\u001b[39mforward_pass(sample_state_1\u001b[38;5;241m.\u001b[39mdetach())[torch\u001b[38;5;241m.\u001b[39marange(sample_state_1\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)), sample_action_1\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m    141\u001b[0m replay_actual_q_values_2 \u001b[38;5;241m=\u001b[39m model_2\u001b[38;5;241m.\u001b[39mforward_pass(sample_state_2\u001b[38;5;241m.\u001b[39mdetach())[torch\u001b[38;5;241m.\u001b[39marange(sample_state_2\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)), sample_action_2\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m--> 143\u001b[0m replay_next_q_values_1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_next_state_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m replay_next_q_values_2 \u001b[38;5;241m=\u001b[39m model_2\u001b[38;5;241m.\u001b[39mforward_pass(sample_next_state_2\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[0;32m    146\u001b[0m replay_expected_values_1 \u001b[38;5;241m=\u001b[39m sample_reward_1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.95\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(replay_next_q_values_1, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn [316], line 25\u001b[0m, in \u001b[0;36mIndependentLearnerNN.forward_pass\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mleaky_relu(x)\n\u001b[1;32m---> 25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mleaky_relu(x)\n\u001b[0;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\fx\\traceback.py:68\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_list(\u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\traceback.py:227\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 227\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\traceback.py:379\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    376\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[0;32m    377\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals))\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m--> 379\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\compilerop.py:193\u001b[0m, in \u001b[0;36mcheck_linecache_ipython\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call linecache.checkcache() safely protecting our cached values.\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# First call the original checkcache as intended\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkcache_ori\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# Then, update back the cache with our data, so that tracebacks related\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# to our compiled codes can be produced.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m linecache\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mupdate(linecache\u001b[38;5;241m.\u001b[39m_ipython_cache)\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define IL DQN model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class IndependentLearnerNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IndependentLearnerNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(30, 512)\n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.layer3 = nn.Linear(256, 256)\n",
    "        self.layer4 = nn.Linear(256, 256)\n",
    "        self.layer5 = nn.Linear(256, 2)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Neural Network with input layer {self.input_layer}, hidden layer 1 {self.hidden_layer_1}, hidden layer 2 {self.hidden_layer_2}, hidden layer 3 {self.hidden_layer_3}, hidden layer 4 {self.hidden_layer_4}, and output layer {self.output_layer}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "    def forward_pass(self, input_data):\n",
    "        x = self.layer1(input_data)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer4(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer5(x)\n",
    "        return x\n",
    "\n",
    "# Main Simulation\n",
    "\n",
    "# configs\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "EPSILON = 1\n",
    "\n",
    "# Check if GPU is available and if so, use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if True:\n",
    "    # Create Data Centers\n",
    "    data_center_num = 2\n",
    "    dataCenter1 = DataCenter(device)\n",
    "    dataCenter2 = DataCenter(device)\n",
    "\n",
    "    model_1 = IndependentLearnerNN().to(device)\n",
    "    model_2 = IndependentLearnerNN().to(device)\n",
    "\n",
    "    optimizer_1 = torch.optim.Adam(model_1.parameters(), lr=0.001)\n",
    "    optimizer_2 = torch.optim.Adam(model_2.parameters(), lr=0.001)\n",
    "\n",
    "    # Initialize Replay Buffer\n",
    "    replay_buffer_1 = ReplayBuffer(200000)\n",
    "    replay_buffer_2 = ReplayBuffer(200000)\n",
    "    dummy_value = torch.zeros(1).to(device)\n",
    "else:\n",
    "    EPSILON = 0.95**60\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "M = 100 # Number of episodes\n",
    "N = 2000 # Number of timesteps per episode\n",
    "\n",
    "for episode in range(M):\n",
    "    EPSILON *= 0.95\n",
    "    # keep track of rewards\n",
    "    total_rewards = 0\n",
    "    actions_record = torch.zeros((2,))\n",
    "\n",
    "    # Reset states\n",
    "    dataCenter1.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    dataCenter2.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    total_rewards = 0\n",
    "\n",
    "    jobGenerator = JobGenerator(data_center_num)\n",
    "\n",
    "    jobs = jobGenerator.generate_job()\n",
    "\n",
    "    curr_state_1 = torch.cat((torch.zeros(STATE_SIZE).to(device), jobs[0].to(device)), 0)\n",
    "    curr_state_2 = torch.cat((torch.zeros(STATE_SIZE).to(device), jobs[1].to(device)), 0)\n",
    "\n",
    "    # Get initial actions\n",
    "    q_values_1 = model_1.forward_pass(curr_state_1)\n",
    "    q_values_2 = model_2.forward_pass(curr_state_2)\n",
    "\n",
    "    action1, q_value_1 = epsilon_greedy(q_values_1, EPSILON)\n",
    "    action2, q_value_2 = epsilon_greedy(q_values_2, EPSILON)\n",
    "\n",
    "    print(\"initial actions\", action1, action2)\n",
    "\n",
    "    for timestep in range(N):\n",
    "        reward1 = 0\n",
    "        reward2 = 0\n",
    "        reward = torch.tensor(0.0).to(device)\n",
    "        reward_from_1 = 0\n",
    "        reward_from_2 = 0\n",
    "\n",
    "        if action1 == 0:\n",
    "            reward_from_1 += dataCenter1.add_job(jobs[0])\n",
    "        else:\n",
    "            jobs[0][1] *= 0.8\n",
    "            reward_from_2 += dataCenter2.add_job(jobs[0])\n",
    "\n",
    "        if action2 == 0:\n",
    "            reward_from_2 += dataCenter2.add_job(jobs[1])\n",
    "        else:\n",
    "            jobs[1][1] *= 0.8\n",
    "            reward_from_1 += dataCenter1.add_job(jobs[1])\n",
    "        \n",
    "        # print(action1, actions_record)\n",
    "        actions_record[action1] += 1\n",
    "        actions_record[action2] += 1\n",
    "\n",
    "        reward_from_1 += dataCenter1.update(1)\n",
    "        reward_from_2 += dataCenter2.update(1)\n",
    "\n",
    "        reward1 = reward_from_1\n",
    "        reward2 = reward_from_2\n",
    "        \n",
    "        reward = reward1 + reward2\n",
    "\n",
    "        jobs = jobGenerator.generate_job()\n",
    "\n",
    "        next_state_1 = torch.cat((dataCenter1.state, jobs[0].to(device)), 0)\n",
    "        next_state_2 = torch.cat((dataCenter2.state, jobs[1].to(device)), 0)\n",
    "\n",
    "        total_rewards += reward\n",
    "\n",
    "        ############################## update replay buffer ##############################\n",
    "\n",
    "        replay_buffer_1.push(curr_state_1, dummy_value, jobs[0].to(device), action1.view(-1).to(device), reward1, next_state_1, dummy_value, jobs[1].to(device))\n",
    "        replay_buffer_2.push(curr_state_2, dummy_value, jobs[1].to(device), action2.view(-1).to(device), reward2, next_state_2, dummy_value, jobs[0].to(device))\n",
    "\n",
    "        sample_state_1, _, _, sample_action_1, sample_reward_1, sample_next_state_1, _, _ = replay_buffer_1.sample(BATCH_SIZE)\n",
    "        sample_state_2, _, _, sample_action_2, sample_reward_2, sample_next_state_2, _, _ = replay_buffer_2.sample(BATCH_SIZE)\n",
    "\n",
    "        replay_actual_q_values_1 = model_1.forward_pass(sample_state_1.detach())[torch.arange(sample_state_1.size(0)), sample_action_1.view(-1)]\n",
    "        replay_actual_q_values_2 = model_2.forward_pass(sample_state_2.detach())[torch.arange(sample_state_2.size(0)), sample_action_2.view(-1)]\n",
    "\n",
    "        replay_next_q_values_1 = model_1.forward_pass(sample_next_state_1.detach())\n",
    "        replay_next_q_values_2 = model_2.forward_pass(sample_next_state_2.detach())\n",
    "\n",
    "        replay_expected_values_1 = sample_reward_1 + 0.95 * torch.max(replay_next_q_values_1, 1)[0]\n",
    "        replay_expected_values_2 = sample_reward_2 + 0.95 * torch.max(replay_next_q_values_2, 1)[0]\n",
    "\n",
    "        loss_1 = torch.nn.MSELoss()(replay_expected_values_1.detach(), replay_actual_q_values_1)\n",
    "        loss_2 = torch.nn.MSELoss()(replay_expected_values_2.detach(), replay_actual_q_values_2)\n",
    "\n",
    "        loss_1.backward(retain_graph=True)\n",
    "        loss_2.backward(retain_graph=True)\n",
    "\n",
    "        optimizer_1.step()\n",
    "        optimizer_2.step()\n",
    "\n",
    "        optimizer_1.zero_grad()\n",
    "        optimizer_2.zero_grad()\n",
    "\n",
    "        ############################## get next actions ##############################\n",
    "        # Update states and actions\n",
    "\n",
    "        curr_state_1 = torch.cat((dataCenter1.state, jobs[0].to(device)), 0)\n",
    "        curr_state_2 = torch.cat((dataCenter2.state, jobs[1].to(device)), 0)\n",
    "\n",
    "        q_values_1 = model_1.forward_pass(curr_state_1)\n",
    "        q_values_2 = model_2.forward_pass(curr_state_2)\n",
    "        action1, q_value_1 = epsilon_greedy(q_values_1, EPSILON)\n",
    "        action2, q_value_2 = epsilon_greedy(q_values_2, EPSILON)\n",
    "\n",
    "    print(\"we got \", total_rewards, \"total reward\")\n",
    "    print(\"actions\", actions_record, EPSILON * 2000)\n",
    "    print(total_rewards, dataCenter1.state, dataCenter2.state, action1, action2, reward, q_values_1, q_values_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb2fe44",
   "metadata": {},
   "source": [
    "## State-Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "94ac8558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x34 and 30x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [327], line 93\u001b[0m\n\u001b[0;32m     90\u001b[0m curr_state_2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((dataCenter2\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mto(device), jobs[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), compressed_state(dataCenter1\u001b[38;5;241m.\u001b[39mstate)), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Get initial actions\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m q_values_1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurr_state_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m q_values_2 \u001b[38;5;241m=\u001b[39m model_2\u001b[38;5;241m.\u001b[39mforward_pass(curr_state_2)\n\u001b[0;32m     96\u001b[0m action1, q_value_1 \u001b[38;5;241m=\u001b[39m epsilon_greedy(q_values_1, EPSILON)\n",
      "Cell \u001b[1;32mIn [325], line 21\u001b[0m, in \u001b[0;36mAdvantageMARL.forward_pass\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_pass\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_data):\n\u001b[1;32m---> 21\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mleaky_relu(x)\n\u001b[0;32m     23\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x34 and 30x512)"
     ]
    }
   ],
   "source": [
    "# define IL DQN model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class StateCompressionNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StateCompressionNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(34, 512)\n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.layer3 = nn.Linear(256, 256)\n",
    "        self.layer4 = nn.Linear(256, 256)\n",
    "        self.layer5 = nn.Linear(256, 2)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Neural Network with input layer {self.input_layer}, hidden layer 1 {self.hidden_layer_1}, hidden layer 2 {self.hidden_layer_2}, hidden layer 3 {self.hidden_layer_3}, hidden layer 4 {self.hidden_layer_4}, and output layer {self.output_layer}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "    def forward_pass(self, input_data):\n",
    "        x = self.layer1(input_data)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer4(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer5(x)\n",
    "        return x\n",
    "\n",
    "# Main Simulation\n",
    "\n",
    "# configs\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "EPSILON = 1\n",
    "\n",
    "# Check if GPU is available and if so, use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if False:\n",
    "    # Create Data Centers\n",
    "    data_center_num = 2\n",
    "    dataCenter1 = DataCenter(device)\n",
    "    dataCenter2 = DataCenter(device)\n",
    "\n",
    "    model_1 = StateCompressionNN().to(device)\n",
    "    model_2 = StateCompressionNN().to(device)\n",
    "\n",
    "    optimizer_1 = torch.optim.Adam(model_1.parameters(), lr=0.001)\n",
    "    optimizer_2 = torch.optim.Adam(model_2.parameters(), lr=0.001)\n",
    "\n",
    "    # Initialize Replay Buffer\n",
    "    replay_buffer_1 = ReplayBuffer(200000)\n",
    "    replay_buffer_2 = ReplayBuffer(200000)\n",
    "    dummy_value = torch.zeros(1).to(device)\n",
    "else:\n",
    "    EPSILON = 0.95**100\n",
    "\n",
    "\n",
    "def compressed_state(tensor):\n",
    "    machines = tensor[:10].view(5, 2).clone()\n",
    "    queues = tensor[10:].view(6, 3).clone()\n",
    "    return torch.cat((machines.sum(0), queues.sum(0)[:2]), 0)\n",
    "\n",
    "    \n",
    "\n",
    "# Hyperparameters\n",
    "M = 100 # Number of episodes\n",
    "N = 2000 # Number of timesteps per episode\n",
    "\n",
    "for episode in range(M):\n",
    "    EPSILON *= 0.95\n",
    "    # keep track of rewards\n",
    "    total_rewards = 0\n",
    "    actions_record = torch.zeros((2,))\n",
    "\n",
    "    # Reset states\n",
    "    dataCenter1.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    dataCenter2.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    total_rewards = 0\n",
    "\n",
    "    jobGenerator = JobGenerator(data_center_num)\n",
    "\n",
    "    jobs = jobGenerator.generate_job()\n",
    "\n",
    "    curr_state_1 = torch.cat((dataCenter1.state.to(device), jobs[0].to(device), compressed_state(dataCenter2.state)), 0)\n",
    "    curr_state_2 = torch.cat((dataCenter2.state.to(device), jobs[1].to(device), compressed_state(dataCenter1.state)), 0)\n",
    "\n",
    "    # Get initial actions\n",
    "    q_values_1 = model_1.forward_pass(curr_state_1)\n",
    "    q_values_2 = model_2.forward_pass(curr_state_2)\n",
    "\n",
    "    action1, q_value_1 = epsilon_greedy(q_values_1, EPSILON)\n",
    "    action2, q_value_2 = epsilon_greedy(q_values_2, EPSILON)\n",
    "\n",
    "    print(\"initial actions\", action1, action2)\n",
    "\n",
    "    for timestep in range(N):\n",
    "        reward1 = 0\n",
    "        reward2 = 0\n",
    "        reward = torch.tensor(0.0).to(device)\n",
    "        reward_from_1 = 0\n",
    "        reward_from_2 = 0\n",
    "\n",
    "        if action1 == 0:\n",
    "            reward_from_1 += dataCenter1.add_job(jobs[0])\n",
    "        else:\n",
    "            jobs[0][1] *= 0.8\n",
    "            reward_from_2 += dataCenter2.add_job(jobs[0])\n",
    "\n",
    "        if action2 == 0:\n",
    "            reward_from_2 += dataCenter2.add_job(jobs[1])\n",
    "        else:\n",
    "            jobs[1][1] *= 0.8\n",
    "            reward_from_1 += dataCenter1.add_job(jobs[1])\n",
    "        \n",
    "        # print(action1, actions_record)\n",
    "        actions_record[action1] += 1\n",
    "        actions_record[action2] += 1\n",
    "\n",
    "        reward_from_1 += dataCenter1.update(1)\n",
    "        reward_from_2 += dataCenter2.update(1)\n",
    "\n",
    "        reward1 = reward_from_1 * 0.5 + reward_from_2 * 0.5\n",
    "        reward2 = reward_from_2 * 0.5 + reward_from_1 * 0.5\n",
    "        \n",
    "        reward = reward1 + reward2\n",
    "\n",
    "        jobs = jobGenerator.generate_job()\n",
    "\n",
    "        next_state_1 = torch.cat((dataCenter1.state, jobs[0].to(device), compressed_state(dataCenter2.state)), 0)\n",
    "        next_state_2 = torch.cat((dataCenter2.state, jobs[1].to(device), compressed_state(dataCenter1.state)), 0)\n",
    "\n",
    "        total_rewards += reward\n",
    "\n",
    "        ############################## update replay buffer ##############################\n",
    "\n",
    "        replay_buffer_1.push(curr_state_1, dummy_value, jobs[0].to(device), action1.view(-1).to(device), reward1, next_state_1, dummy_value, jobs[1].to(device))\n",
    "        replay_buffer_2.push(curr_state_2, dummy_value, jobs[1].to(device), action2.view(-1).to(device), reward2, next_state_2, dummy_value, jobs[0].to(device))\n",
    "\n",
    "        sample_state_1, _, _, sample_action_1, sample_reward_1, sample_next_state_1, _, _ = replay_buffer_1.sample(BATCH_SIZE)\n",
    "        sample_state_2, _, _, sample_action_2, sample_reward_2, sample_next_state_2, _, _ = replay_buffer_2.sample(BATCH_SIZE)\n",
    "\n",
    "        replay_actual_q_values_1 = model_1.forward_pass(sample_state_1.detach())[torch.arange(sample_state_1.size(0)), sample_action_1.view(-1)]\n",
    "        replay_actual_q_values_2 = model_2.forward_pass(sample_state_2.detach())[torch.arange(sample_state_2.size(0)), sample_action_2.view(-1)]\n",
    "\n",
    "        replay_next_q_values_1 = model_1.forward_pass(sample_next_state_1.detach())\n",
    "        replay_next_q_values_2 = model_2.forward_pass(sample_next_state_2.detach())\n",
    "\n",
    "        replay_expected_values_1 = sample_reward_1 + 0.95 * torch.max(replay_next_q_values_1, 1)[0]\n",
    "        replay_expected_values_2 = sample_reward_2 + 0.95 * torch.max(replay_next_q_values_2, 1)[0]\n",
    "\n",
    "        loss_1 = torch.nn.MSELoss()(replay_expected_values_1.detach(), replay_actual_q_values_1)\n",
    "        loss_2 = torch.nn.MSELoss()(replay_expected_values_2.detach(), replay_actual_q_values_2)\n",
    "\n",
    "        loss_1.backward(retain_graph=True)\n",
    "        loss_2.backward(retain_graph=True)\n",
    "\n",
    "        optimizer_1.step()\n",
    "        optimizer_2.step()\n",
    "\n",
    "        optimizer_1.zero_grad()\n",
    "        optimizer_2.zero_grad()\n",
    "\n",
    "        ############################## get next actions ##############################\n",
    "        # Update states and actions\n",
    "\n",
    "        curr_state_1 = torch.cat((dataCenter1.state.to(device), jobs[0].to(device), compressed_state(dataCenter2.state)), 0)\n",
    "        curr_state_2 = torch.cat((dataCenter2.state.to(device), jobs[1].to(device), compressed_state(dataCenter1.state)), 0)\n",
    "\n",
    "        q_values_1 = model_1.forward_pass(curr_state_1)\n",
    "        q_values_2 = model_2.forward_pass(curr_state_2)\n",
    "        action1, q_value_1 = epsilon_greedy(q_values_1, EPSILON)\n",
    "        action2, q_value_2 = epsilon_greedy(q_values_2, EPSILON)\n",
    "\n",
    "    print(\"we got \", total_rewards, \"total reward\")\n",
    "    print(\"actions\", actions_record, EPSILON * 2000)\n",
    "    print(total_rewards, dataCenter1.state, dataCenter2.state, action1, action2, reward, q_values_1, q_values_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2555a165",
   "metadata": {},
   "source": [
    "## Action Advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1c917d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ReplayBuffer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m optimizer_advantage_2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(advantage_model_2\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Initialize Replay Buffer\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m replay_buffer_1 \u001b[38;5;241m=\u001b[39m \u001b[43mReplayBuffer\u001b[49m(\u001b[38;5;241m200000\u001b[39m)\n\u001b[0;32m     66\u001b[0m replay_buffer_2 \u001b[38;5;241m=\u001b[39m ReplayBuffer(\u001b[38;5;241m200000\u001b[39m)\n\u001b[0;32m     67\u001b[0m dummy_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ReplayBuffer' is not defined"
     ]
    }
   ],
   "source": [
    "# define IL DQN model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AdvantageMARL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdvantageMARL, self).__init__()\n",
    "        self.layer1 = nn.Linear(30, 256)\n",
    "        self.layer2 = nn.Linear(256, 128)\n",
    "        self.layer3 = nn.Linear(128, 128)\n",
    "        self.layer4 = nn.Linear(128, 128)\n",
    "        self.layer5 = nn.Linear(128, 2)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Neural Network with input layer {self.input_layer}, hidden layer 1 {self.hidden_layer_1}, hidden layer 2 {self.hidden_layer_2}, hidden layer 3 {self.hidden_layer_3}, hidden layer 4 {self.hidden_layer_4}, and output layer {self.output_layer}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "    def forward_pass(self, input_data):\n",
    "        x = self.layer1(input_data)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer4(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer5(x)\n",
    "        return x\n",
    "\n",
    "# Main Simulation\n",
    "\n",
    "# configs\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "EPSILON = 1\n",
    "\n",
    "# Check if GPU is available and if so, use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if True:\n",
    "    # Create Data Centers\n",
    "    data_center_num = 2\n",
    "    dataCenter1 = DataCenter(device)\n",
    "    dataCenter2 = DataCenter(device)\n",
    "\n",
    "    model_1 = AdvantageMARL().to(device)\n",
    "    model_2 = AdvantageMARL().to(device)\n",
    "\n",
    "    # for double-DQN\n",
    "    model_1_target = AdvantageMARL().to(device)\n",
    "    model_2_target = AdvantageMARL().to(device)\n",
    "\n",
    "    advantage_model_1 = AdvantageMARL().to(device)\n",
    "    advantage_model_2 = AdvantageMARL().to(device)\n",
    "\n",
    "    optimizer_1 = torch.optim.Adam(model_1.parameters(), lr=0.001)\n",
    "    optimizer_2 = torch.optim.Adam(model_2.parameters(), lr=0.001)\n",
    "    optimizer_advantage_1 = torch.optim.Adam(advantage_model_1.parameters(), lr=0.001)\n",
    "    optimizer_advantage_2 = torch.optim.Adam(advantage_model_2.parameters(), lr=0.001)\n",
    "\n",
    "    # Initialize Replay Buffer\n",
    "    replay_buffer_1 = ReplayBuffer(200000)\n",
    "    replay_buffer_2 = ReplayBuffer(200000)\n",
    "    dummy_value = torch.zeros(1).to(device)\n",
    "else:\n",
    "    EPSILON = 0.95**100\n",
    "\n",
    "# Hyperparameters\n",
    "M = 200 # Number of episodes\n",
    "N = 2000 # Number of timesteps per episode\n",
    "\n",
    "for episode in range(M):\n",
    "    EPSILON *= 0.95\n",
    "    # keep track of rewards\n",
    "    total_rewards = 0\n",
    "    actions_record = torch.zeros((2,))\n",
    "\n",
    "    # Reset states\n",
    "    dataCenter1.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    dataCenter2.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    total_rewards = 0\n",
    "\n",
    "    jobGenerator = JobGenerator(data_center_num)\n",
    "\n",
    "    jobs = jobGenerator.generate_job()\n",
    "\n",
    "    curr_state_1 = torch.cat((dataCenter1.state.to(device), jobs[0].to(device)), 0)\n",
    "    curr_state_2 = torch.cat((dataCenter2.state.to(device), jobs[1].to(device)), 0)\n",
    "\n",
    "    advantage_state_1 = torch.cat((dataCenter1.state.to(device), jobs[1].to(device)), 0)\n",
    "    advantage_state_2 = torch.cat((dataCenter2.state.to(device), jobs[0].to(device)), 0)\n",
    "\n",
    "    advantage_value_1 = advantage_model_1.forward_pass(advantage_state_1)\n",
    "    advantage_value_2 = advantage_model_2.forward_pass(advantage_state_2)\n",
    "\n",
    "    q_values_1 = model_1.forward_pass(curr_state_1)\n",
    "    q_values_2 = model_2.forward_pass(curr_state_2)\n",
    "\n",
    "    action1, q_value_1 = epsilon_greedy(q_values_1 + advantage_value_2, EPSILON)\n",
    "    action2, q_value_2 = epsilon_greedy(q_values_2 + advantage_value_1, EPSILON)\n",
    "\n",
    "\n",
    "    print(\"initial actions\", action1, action2)\n",
    "\n",
    "    for timestep in range(N):\n",
    "        reward1 = 0\n",
    "        reward2 = 0\n",
    "        reward = torch.tensor(0.0).to(device)\n",
    "        reward_from_1 = 0\n",
    "        reward_from_2 = 0\n",
    "\n",
    "        if action1 == 0:\n",
    "            reward_from_1 += dataCenter1.add_job(jobs[0])\n",
    "        else:\n",
    "            jobs[0][1] *= 0.8\n",
    "            reward_from_1 += dataCenter2.add_job(jobs[0])\n",
    "\n",
    "        if action2 == 0:\n",
    "            reward_from_2 += dataCenter2.add_job(jobs[1])\n",
    "        else:\n",
    "            jobs[1][1] *= 0.8\n",
    "            reward_from_2 += dataCenter1.add_job(jobs[1])\n",
    "        \n",
    "        # print(action1, actions_record)\n",
    "        actions_record[action1] += 1\n",
    "        actions_record[action2] += 1\n",
    "\n",
    "        reward_from_1 += dataCenter1.update(1)\n",
    "        reward_from_2 += dataCenter2.update(1)\n",
    "\n",
    "        # equal reward sharing\n",
    "        # reward1 = (reward_from_1 + reward_from_2) * 0.5\n",
    "        # reward2 = (reward_from_1 + reward_from_2) * 0.5\n",
    "        \n",
    "        # reward sharing based on local work\n",
    "        reward1 = reward_from_1\n",
    "        reward2 = reward_from_2\n",
    "\n",
    "        # reward sharing 70/30 split\n",
    "        # reward1 = reward_from_1 * 0.7 + reward_from_2 * 0.3\n",
    "        # reward2 = reward_from_2 * 0.7 + reward_from_1 * 0.3\n",
    "\n",
    "        # reward sharing with competition penalty\n",
    "        # reward1 = reward_from_1 * 1.1 - reward_from_2 * 0.1\n",
    "        # reward2 = reward_from_2 * 1.1 - reward_from_1 * 0.1\n",
    "\n",
    "        reward = reward1 + reward2\n",
    "\n",
    "        jobs = jobGenerator.generate_job()\n",
    "\n",
    "        next_state_1 = torch.cat((dataCenter1.state, jobs[0].to(device)), 0)\n",
    "        next_state_2 = torch.cat((dataCenter2.state, jobs[1].to(device)), 0)\n",
    "\n",
    "        total_rewards += reward\n",
    "\n",
    "        ############################## update replay buffer ##############################\n",
    "\n",
    "        replay_buffer_1.push(curr_state_1, advantage_state_1, jobs[0].to(device), action1.view(-1).to(device), reward1, next_state_1, action2.view(-1).to(device), jobs[1].to(device))\n",
    "        replay_buffer_2.push(curr_state_2, advantage_state_2, jobs[1].to(device), action2.view(-1).to(device), reward2, next_state_2, action1.view(-1).to(device), jobs[0].to(device))\n",
    "\n",
    "        sample_state_1, sample_advantage_state_1, _, sample_action_1, sample_reward_1, sample_next_state_1, sample_action_1_2, _ = replay_buffer_1.sample(BATCH_SIZE)\n",
    "        sample_state_2, sample_advantage_state_2, _, sample_action_2, sample_reward_2, sample_next_state_2, sample_action_2_1, _ = replay_buffer_2.sample(BATCH_SIZE)\n",
    "\n",
    "        ############################## update Q-value model ##############################\n",
    "\n",
    "        replay_q_values_1 = model_1.forward_pass(sample_state_1.detach())\n",
    "        replay_q_values_2 = model_2.forward_pass(sample_state_2.detach())\n",
    "\n",
    "        # replay_actual_q_values_1 = model_1.forward_pass(sample_state_1.detach())[torch.arange(sample_state_1.size(0)), sample_action_1.view(-1)]\n",
    "        # replay_actual_q_values_2 = model_2.forward_pass(sample_state_2.detach())[torch.arange(sample_state_2.size(0)), sample_action_2.view(-1)]\n",
    "        replay_actual_q_values_1 = replay_q_values_1[torch.arange(sample_state_1.size(0)), sample_action_1.view(-1)]\n",
    "        replay_actual_q_values_2 = replay_q_values_2[torch.arange(sample_state_2.size(0)), sample_action_2.view(-1)]\n",
    "\n",
    "        # replay_next_q_values_1 = model_1.forward_pass(sample_next_state_1.detach())\n",
    "        # replay_next_q_values_2 = model_2.forward_pass(sample_next_state_2.detach())\n",
    "\n",
    "        replay_next_q_values_1 = model_1_target.forward_pass(sample_next_state_1.detach())\n",
    "        replay_next_q_values_2 = model_2_target.forward_pass(sample_next_state_2.detach())\n",
    "\n",
    "        replay_expected_values_1 = sample_reward_1 + 0.95 * torch.max(replay_next_q_values_1, 1)[0]\n",
    "        replay_expected_values_2 = sample_reward_2 + 0.95 * torch.max(replay_next_q_values_2, 1)[0]\n",
    "\n",
    "        loss_1 = torch.nn.MSELoss()(replay_expected_values_1.detach(), replay_actual_q_values_1)\n",
    "        loss_2 = torch.nn.MSELoss()(replay_expected_values_2.detach(), replay_actual_q_values_2)\n",
    "\n",
    "        loss_1.backward(retain_graph=True)\n",
    "        loss_2.backward(retain_graph=True)\n",
    "\n",
    "        optimizer_1.step()\n",
    "        optimizer_2.step()\n",
    "\n",
    "        optimizer_1.zero_grad()\n",
    "        optimizer_2.zero_grad()\n",
    "\n",
    "        ############################## update Advantage model ##############################\n",
    "\n",
    "        replay_actual_advantage_values_1 = advantage_model_1.forward_pass(sample_advantage_state_1.detach())[torch.arange(sample_advantage_state_1.size(0)), sample_action_1_2.view(-1)]\n",
    "        replay_actual_advantage_values_2 = advantage_model_2.forward_pass(sample_advantage_state_2.detach())[torch.arange(sample_advantage_state_2.size(0)), sample_action_2_1.view(-1)]\n",
    "\n",
    "        replay_expected_advantage_values_1 = replay_expected_values_1 - replay_actual_q_values_1 \n",
    "        replay_expected_advantage_values_2 = replay_expected_values_2 - replay_actual_q_values_2\n",
    "        # replay_expected_advantage_values_1 = torch.max(replay_q_values_1, 1)[0] - replay_actual_q_values_1\n",
    "        # replay_expected_advantage_values_2 = torch.max(replay_q_values_2, 1)[0] - replay_actual_q_values_2\n",
    "\n",
    "        loss_advantage_1 = torch.nn.MSELoss()(replay_expected_advantage_values_1.detach(), replay_actual_advantage_values_1)\n",
    "        loss_advantage_2 = torch.nn.MSELoss()(replay_expected_advantage_values_2.detach(), replay_actual_advantage_values_2)\n",
    "\n",
    "        loss_advantage_1.backward(retain_graph=True)\n",
    "        loss_advantage_2.backward(retain_graph=True)\n",
    "\n",
    "        optimizer_advantage_1.step()\n",
    "        optimizer_advantage_2.step()\n",
    "\n",
    "        optimizer_advantage_1.zero_grad()\n",
    "        optimizer_advantage_2.zero_grad()\n",
    "\n",
    "        ############################## get next actions ##############################\n",
    "        # Update states and actions\n",
    "\n",
    "        curr_state_1 = torch.cat((dataCenter1.state.to(device), jobs[0].to(device)), 0)\n",
    "        curr_state_2 = torch.cat((dataCenter2.state.to(device), jobs[1].to(device)), 0)\n",
    "\n",
    "        advantage_state_1 = torch.cat((dataCenter1.state.to(device), jobs[1].to(device)), 0)\n",
    "        advantage_state_2 = torch.cat((dataCenter2.state.to(device), jobs[0].to(device)), 0)\n",
    "\n",
    "        advantage_value_1 = advantage_model_1.forward_pass(advantage_state_1)\n",
    "        advantage_value_2 = advantage_model_2.forward_pass(advantage_state_2)\n",
    "\n",
    "        q_values_1 = model_1.forward_pass(curr_state_1)\n",
    "        q_values_2 = model_2.forward_pass(curr_state_2)\n",
    "\n",
    "        action1, q_value_1 = epsilon_greedy(q_values_1 + advantage_value_2, EPSILON)\n",
    "        action2, q_value_2 = epsilon_greedy(q_values_2 + advantage_value_1, EPSILON)\n",
    "        \n",
    "        # print(total_rewards, dataCenter1.state, dataCenter2.state, action1, action2, reward, q_values_1, q_values_2, advantage_value_1, advantage_value_2)\n",
    "\n",
    "        # update target network\n",
    "        if timestep % 100 == 0:\n",
    "            model_1_target.load_state_dict(model_1.state_dict())\n",
    "            model_2_target.load_state_dict(model_2.state_dict())\n",
    "\n",
    "    print(\"we got \", total_rewards, \"total reward\")\n",
    "    print(\"actions\", actions_record, EPSILON * 2000)\n",
    "    print(total_rewards, dataCenter1.state, dataCenter2.state, action1, action2, reward, q_values_1, q_values_2, advantage_value_1, advantage_value_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "5586383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the model, optimizer, and replay buffer in a dictionary\n",
    "\n",
    "# torch.save({\n",
    "#     'model_1': model_1.state_dict(),\n",
    "#     'model_2': model_2.state_dict(),\n",
    "#     'advantage_model_1': advantage_model_1.state_dict(),\n",
    "#     'advantage_model_2': advantage_model_2.state_dict(),\n",
    "#     'optimizer_1': optimizer_1.state_dict(),\n",
    "#     'optimizer_2': optimizer_2.state_dict(),\n",
    "#     'optimizer_advantage_1': optimizer_advantage_1.state_dict(),\n",
    "#     'optimizer_advantage_2': optimizer_advantage_2.state_dict(),\n",
    "# }, 'advantage_competition_sharing_double_q.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "02fce43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43037\n"
     ]
    }
   ],
   "source": [
    "fit_model = AdvantageMARL()\n",
    "\n",
    "optimzer = torch.optim.Adam(fit_model.parameters(), lr=0.001)\n",
    "\n",
    "for i in range(1000):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384b4eea",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ba4033a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\l\\AppData\\Local\\Temp\\ipykernel_28352\\2790792578.py:39: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = torch.nn.functional.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we got  tensor(125.3600, device='cuda:0') total reward; actions taken are tensor([207., 193.]) 190.0\n",
      "we got  tensor(129.6600, device='cuda:0') total reward; actions taken are tensor([225., 175.]) 180.5\n",
      "we got  tensor(119.1600, device='cuda:0') total reward; actions taken are tensor([223., 177.]) 171.47499999999997\n",
      "we got  tensor(98.8400, device='cuda:0') total reward; actions taken are tensor([238., 162.]) 162.90124999999998\n",
      "we got  tensor(123.1400, device='cuda:0') total reward; actions taken are tensor([243., 157.]) 154.75618749999998\n",
      "we got  tensor(115.6800, device='cuda:0') total reward; actions taken are tensor([246., 154.]) 147.01837812499997\n",
      "we got  tensor(116.1000, device='cuda:0') total reward; actions taken are tensor([250., 150.]) 139.66745921874994\n",
      "we got  tensor(129.1600, device='cuda:0') total reward; actions taken are tensor([255., 145.]) 132.68408625781245\n",
      "we got  tensor(107.8000, device='cuda:0') total reward; actions taken are tensor([270., 130.]) 126.04988194492182\n",
      "we got  tensor(122.8600, device='cuda:0') total reward; actions taken are tensor([259., 141.]) 119.74738784767571\n",
      "we got  tensor(119.6200, device='cuda:0') total reward; actions taken are tensor([211., 189.]) 113.76001845529191\n",
      "we got  tensor(109.0001, device='cuda:0') total reward; actions taken are tensor([242., 158.]) 108.07201753252731\n",
      "we got  tensor(123.9600, device='cuda:0') total reward; actions taken are tensor([242., 158.]) 102.66841665590094\n",
      "we got  tensor(131.9001, device='cuda:0') total reward; actions taken are tensor([261., 139.]) 97.53499582310589\n",
      "we got  tensor(125.9400, device='cuda:0') total reward; actions taken are tensor([238., 162.]) 92.65824603195058\n",
      "we got  tensor(137.9600, device='cuda:0') total reward; actions taken are tensor([260., 140.]) 88.02533373035305\n",
      "we got  tensor(123.9400, device='cuda:0') total reward; actions taken are tensor([268., 132.]) 83.6240670438354\n",
      "we got  tensor(112.8200, device='cuda:0') total reward; actions taken are tensor([296., 104.]) 79.44286369164362\n",
      "we got  tensor(127.1200, device='cuda:0') total reward; actions taken are tensor([244., 156.]) 75.47072050706143\n",
      "we got  tensor(123.9200, device='cuda:0') total reward; actions taken are tensor([266., 134.]) 71.69718448170835\n",
      "we got  tensor(125.5600, device='cuda:0') total reward; actions taken are tensor([290., 110.]) 68.11232525762293\n",
      "we got  tensor(92.7800, device='cuda:0') total reward; actions taken are tensor([286., 114.]) 64.70670899474177\n",
      "we got  tensor(126.5600, device='cuda:0') total reward; actions taken are tensor([317.,  83.]) 61.471373545004695\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\l\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_28352\\\\2790792578.py'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [169], line 135\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# # need to re-calculate the q_values to avoid issues in the backpropagation\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# get the representations\u001b[39;00m\n\u001b[0;32m    134\u001b[0m dataCenter1\u001b[38;5;241m.\u001b[39mupdate_rep(dataCenter2\u001b[38;5;241m.\u001b[39mrepresentations\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m--> 135\u001b[0m \u001b[43mdataCenter2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_rep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataCenter1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# get initial actions\u001b[39;00m\n\u001b[0;32m    138\u001b[0m q_values_1 \u001b[38;5;241m=\u001b[39m dataCenter1\u001b[38;5;241m.\u001b[39mget_q_values(dataCenter2\u001b[38;5;241m.\u001b[39mrepresentations\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n",
      "Cell \u001b[1;32mIn [151], line 48\u001b[0m, in \u001b[0;36mDataCenter.update_rep\u001b[1;34m(self, remote_info)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_rep\u001b[39m(\u001b[38;5;28mself\u001b[39m, remote_info):\n\u001b[1;32m---> 48\u001b[0m     new_reps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremote_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# print(new_reps.size(), self.representations.size())\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m new_reps\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentations\u001b[38;5;241m.\u001b[39msize()\n",
      "Cell \u001b[1;32mIn [3], line 40\u001b[0m, in \u001b[0;36mStateCompressor.forward_pass\u001b[1;34m(self, local_state, remote_info)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# print(x.size())\u001b[39;00m\n\u001b[0;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(x)\n\u001b[1;32m---> 40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m local_info \u001b[38;5;241m+\u001b[39m x\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\fx\\traceback.py:68\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_list(\u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\traceback.py:227\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 227\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\traceback.py:379\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    376\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[0;32m    377\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals))\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m--> 379\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\compilerop.py:193\u001b[0m, in \u001b[0;36mcheck_linecache_ipython\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call linecache.checkcache() safely protecting our cached values.\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# First call the original checkcache as intended\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkcache_ori\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# Then, update back the cache with our data, so that tracebacks related\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# to our compiled codes can be produced.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m linecache\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mupdate(linecache\u001b[38;5;241m.\u001b[39m_ipython_cache)\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main Simulation\n",
    "\n",
    "EPSILON = 1\n",
    "\n",
    "# configs\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "# Check if GPU is available and if so, use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create Data Centers\n",
    "data_center_num = 2\n",
    "dataCenter1 = DataCenter(device)\n",
    "dataCenter2 = DataCenter(device)\n",
    "\n",
    "\n",
    "M = 100 #500\n",
    "N = 2000 #3000\n",
    "\n",
    "# M = 500\n",
    "# N = 3000\n",
    "\n",
    "for episode in range(M):\n",
    "    EPSILON *= 0.95\n",
    "    # keep track of rewards\n",
    "    total_rewards = 0\n",
    "    actions = torch.zeros((2,))\n",
    "\n",
    "    # for debugging\n",
    "    current_episode_jobs = []\n",
    "    current_episode_actions = []\n",
    "\n",
    "    # create a loss function\n",
    "    dataCenter1.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    dataCenter2.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    total_rewards = 0\n",
    "\n",
    "    jobGenerator = JobGenerator(data_center_num)\n",
    "\n",
    "    l_time = 0\n",
    "    r_time = 0\n",
    "    import time\n",
    "\n",
    "    jobs = jobGenerator.generate_job()\n",
    "    current_episode_jobs.append(jobs)\n",
    "\n",
    "    # get initial actions\n",
    "    q_values_1 = dataCenter1.get_q_values(dataCenter2.representations.unsqueeze(0), jobs[0].to(device))\n",
    "    q_values_2 = dataCenter2.get_q_values(dataCenter1.representations.unsqueeze(0), jobs[1].to(device))\n",
    "\n",
    "    action1, q_value_1 = epsilon_greedy(q_values_1, EPSILON)\n",
    "    action2, q_value_2 = epsilon_greedy(q_values_2, EPSILON)\n",
    "    current_episode_actions.append((action1, action2))\n",
    "\n",
    "    for timestep in range(N):\n",
    "        # update according to action\n",
    "        pre = time.time()\n",
    "\n",
    "        reward1 = 0\n",
    "        reward2 = 0\n",
    "\n",
    "        reward = torch.tensor(0.0).to(device)\n",
    "\n",
    "        if action1 == 0:\n",
    "            reward += dataCenter1.add_job(jobs[0])\n",
    "        else:\n",
    "            jobs[0][1] *= 0.8\n",
    "            reward += dataCenter2.add_job(jobs[0])\n",
    "\n",
    "        if action2 == 0:\n",
    "            reward += dataCenter2.add_job(jobs[1])\n",
    "        else:\n",
    "            jobs[1][1] *= 0.8\n",
    "            reward += dataCenter1.add_job(jobs[1])\n",
    "\n",
    "        actions[action1] += 1\n",
    "        actions[action2] += 1\n",
    "\n",
    "        reward += dataCenter1.update(1)\n",
    "        reward += dataCenter2.update(1)\n",
    "\n",
    "        post = time.time()\n",
    "        l_time += post - pre\n",
    "        \n",
    "\n",
    "        \n",
    "        # update representations\n",
    "        pre = time.time()\n",
    "        jobs = jobGenerator.generate_job()\n",
    "        current_episode_jobs.append(jobs)\n",
    "\n",
    "        # get the representations\n",
    "        dataCenter1.update_rep(dataCenter2.representations.unsqueeze(0))\n",
    "        dataCenter2.update_rep(dataCenter1.representations.unsqueeze(0))\n",
    "\n",
    "        # get next actions\n",
    "        new_q_values_1 = dataCenter1.get_q_values(dataCenter2.representations.unsqueeze(0), jobs[0].to(device))\n",
    "        new_q_values_2 = dataCenter2.get_q_values(dataCenter1.representations.unsqueeze(0), jobs[1].to(device))\n",
    "\n",
    "        new_action1, new_q_value_1 = torch.argmax(new_q_values_1), torch.max(new_q_values_1)\n",
    "        new_action2, new_q_value_2 = torch.argmax(new_q_values_2), torch.max(new_q_values_2)\n",
    "\n",
    "        post = time.time()\n",
    "        r_time += post - pre\n",
    "\n",
    "        # handle rewards\n",
    "        total_rewards += reward\n",
    "        reward1 = reward / 2\n",
    "        reward2 = reward / 2\n",
    "\n",
    "        # print(f\"{timestep}th loop\", reward, total_rewards, dataCenter1.state, dataCenter1.representations, action1, action2)\n",
    "\n",
    "        # backprop\n",
    "        expected_value_1 = reward1 + 0.9 * torch.max(new_q_values_1)\n",
    "        actual_value_1 = q_value_1.to(device)\n",
    "        loss_1 = torch.nn.MSELoss()(expected_value_1.detach(), actual_value_1)\n",
    "        loss_1.backward(retain_graph=True)\n",
    "\n",
    "        expected_value_2 = reward2 + 0.9 * torch.max(new_q_values_2)\n",
    "        actual_value_2 = q_value_2.to(device)\n",
    "        loss_2 = torch.nn.MSELoss()(expected_value_2.detach(), actual_value_2)\n",
    "        loss_2.backward(retain_graph=True)\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            dataCenter1.backprop()\n",
    "            dataCenter2.backprop()\n",
    "\n",
    "        # # need to re-calculate the q_values to avoid issues in the backpropagation\n",
    "        \n",
    "        # get the representations\n",
    "        dataCenter1.update_rep(dataCenter2.representations.unsqueeze(0))\n",
    "        dataCenter2.update_rep(dataCenter1.representations.unsqueeze(0))\n",
    "\n",
    "        # get initial actions\n",
    "        q_values_1 = dataCenter1.get_q_values(dataCenter2.representations.unsqueeze(0), jobs[0].to(device))\n",
    "        q_values_2 = dataCenter2.get_q_values(dataCenter1.representations.unsqueeze(0), jobs[1].to(device))\n",
    "\n",
    "        action1, q_value_1 = epsilon_greedy(q_values_1, EPSILON)\n",
    "        action2, q_value_2 = epsilon_greedy(q_values_2, EPSILON)\n",
    "        current_episode_actions.append((action1, action2))\n",
    "\n",
    "        # action1, q_value_1 = new_action1, new_q_value_1\n",
    "        # action2, q_value_2 = new_action2, new_q_value_2\n",
    "\n",
    "    print(\"we got \", total_rewards, \"total reward; actions taken are\", actions, 200*EPSILON)\n",
    "\n",
    "    #print(total_rewards, l_time, r_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "8a947c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([2., 0.])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2., 0.])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([2., 0.]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([2., 0.])], [tensor([2., 0.]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([2., 0.]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([2., 0.])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([2., 0.]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([2., 0.])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([2., 0.])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([8.0000, 0.6000]), tensor([2., 0.])], [tensor([4.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.2000])], [tensor([2., 0.]), tensor([2., 0.])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([2., 0.]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([2., 0.])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([2., 0.]), tensor([4.0000, 0.2000])], [tensor([2., 0.]), tensor([2., 0.])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.6000])], [tensor([2., 0.]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.6000]), tensor([2., 0.])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.6000])], [tensor([2., 0.]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2., 0.]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([2., 0.])], [tensor([2., 0.]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2., 0.])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2., 0.])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])]] [(tensor(1), tensor(0)), (tensor(0), tensor(0)), (tensor(1), tensor(0)), (tensor(0), tensor(0)), (tensor(1), tensor(1)), (tensor(1), tensor(0)), (tensor(1), tensor(0)), (tensor(1), tensor(0)), (tensor(1), tensor(0)), (tensor(0), tensor(0)), (tensor(1), tensor(0)), (tensor(1), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([0]), tensor(0)), (tensor(1), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(0)), (tensor(1), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(1), tensor(0)), (tensor(1), tensor(0)), (tensor(1), tensor(0)), (tensor(1), tensor(0)), (tensor(1), tensor([1])), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor([0]), tensor(1)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(1)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(1)), (tensor(0), tensor(0)), (tensor([0]), tensor(1)), (tensor(0), tensor(1)), (tensor([1]), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor([1])), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor([1])), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor([1]), tensor(1)), (tensor([0]), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor([1]), tensor([1])), (tensor(0), tensor(1)), (tensor(0), tensor([1])), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(1), tensor(1)), (tensor([1]), tensor(1)), (tensor([1]), tensor([0])), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor([0]), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor([0]), tensor([0])), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor([0]), tensor(1)), (tensor(0), tensor(1)), (tensor([0]), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor([0])), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor([0]), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor([0])), (tensor([0]), tensor(0)), (tensor(0), tensor(1)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(1)), (tensor([1]), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor([1]), tensor(1)), (tensor([0]), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(0)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor([1]), tensor(0)), (tensor([0]), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor([0]), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor([0]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor([0])), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(1), tensor([0])), (tensor(1), tensor([1])), (tensor(1), tensor(0)), (tensor(1), tensor([0])), (tensor(1), tensor(0)), (tensor(1), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor([0])), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor([0]), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor([0])), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor([0]), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor([0]), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor([1]), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor([1])), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor([1])), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor([0]), tensor([0])), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([0]), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0))]\n"
     ]
    }
   ],
   "source": [
    "print(current_episode_jobs, current_episode_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7727db7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8000, device='cuda:0') [0, 1]\n",
      "tensor(0.8000, device='cuda:0') [0, 0]\n",
      "tensor(2.3000, device='cuda:0') [0, 1]\n",
      "tensor(3.2200, device='cuda:0') [1, 1]\n",
      "tensor(3.8200, device='cuda:0') [0, 1]\n",
      "tensor(3.8200, device='cuda:0') [0, 0]\n",
      "tensor(5.6000, device='cuda:0') [0, 1]\n",
      "tensor(6.9000, device='cuda:0') [0, 1]\n",
      "tensor(7.8000, device='cuda:0') [0, 1]\n",
      "tensor(8.6000, device='cuda:0') [0, 1]\n",
      "tensor(8.6000, device='cuda:0') [0, 0]\n",
      "tensor(10., device='cuda:0') [0, 1]\n",
      "tensor(10., device='cuda:0') [0, 0]\n",
      "tensor(11.5000, device='cuda:0') [0, 1]\n",
      "tensor(12.8000, device='cuda:0') [0, 1]\n",
      "tensor(12.8000, device='cuda:0') [0, 0]\n",
      "tensor(13.7600, device='cuda:0') [1, 1]\n",
      "tensor(14.7300, device='cuda:0') [0, 1]\n",
      "tensor(15.2300, device='cuda:0') [0, 1]\n",
      "tensor(15.3900, device='cuda:0') [1, 1]\n",
      "tensor(16.0700, device='cuda:0') [0, 1]\n",
      "tensor(16.6700, device='cuda:0') [0, 1]\n",
      "tensor(17.2700, device='cuda:0') [0, 1]\n",
      "tensor(17.9100, device='cuda:0') [1, 1]\n",
      "tensor(18.5100, device='cuda:0') [0, 1]\n",
      "tensor(19.2100, device='cuda:0') [0, 1]\n",
      "tensor(19.8500, device='cuda:0') [1, 1]\n",
      "tensor(19.8500, device='cuda:0') [0, 0]\n",
      "tensor(20.8900, device='cuda:0') [1, 1]\n",
      "tensor(21.2900, device='cuda:0') [0, 1]\n",
      "tensor(21.2900, device='cuda:0') [0, 0]\n",
      "tensor(22.0100, device='cuda:0') [0, 1]\n",
      "tensor(22.6100, device='cuda:0') [0, 1]\n",
      "tensor(23.1500, device='cuda:0') [1, 1]\n",
      "tensor(23.7500, device='cuda:0') [0, 1]\n",
      "tensor(24.4500, device='cuda:0') [0, 1]\n",
      "tensor(25.0500, device='cuda:0') [0, 1]\n",
      "tensor(25.4100, device='cuda:0') [1, 1]\n",
      "tensor(26.2100, device='cuda:0') [0, 1]\n",
      "tensor(26.8100, device='cuda:0') [0, 1]\n",
      "tensor(27.4100, device='cuda:0') [0, 1]\n",
      "tensor(28.0300, device='cuda:0') [1, 1]\n",
      "tensor(28.3900, device='cuda:0') [1, 1]\n",
      "tensor(28.3900, device='cuda:0') [0, 0]\n",
      "tensor(28.3900, device='cuda:0') [0, 0]\n",
      "tensor(29.0500, device='cuda:0') [0, 1]\n",
      "tensor(29.0500, device='cuda:0') [0, 0]\n",
      "tensor(29.6100, device='cuda:0') [0, 1]\n",
      "tensor(29.9700, device='cuda:0') [1, 1]\n",
      "tensor(30.4700, device='cuda:0') [0, 1]\n",
      "tensor(30.9700, device='cuda:0') [0, 1]\n",
      "tensor(31.4300, device='cuda:0') [1, 1]\n",
      "tensor(31.4300, device='cuda:0') [0, 0]\n",
      "tensor(32.3700, device='cuda:0') [0, 1]\n",
      "tensor(32.3700, device='cuda:0') [0, 0]\n",
      "tensor(33.1900, device='cuda:0') [0, 1]\n",
      "tensor(33.7900, device='cuda:0') [0, 1]\n",
      "tensor(34.4900, device='cuda:0') [0, 1]\n",
      "tensor(34.9900, device='cuda:0') [0, 1]\n",
      "tensor(35.4300, device='cuda:0') [1, 1]\n",
      "tensor(35.5900, device='cuda:0') [1, 1]\n",
      "tensor(36.3300, device='cuda:0') [1, 1]\n",
      "tensor(36.8300, device='cuda:0') [0, 1]\n",
      "tensor(36.9900, device='cuda:0') [1, 0]\n",
      "tensor(37.7300, device='cuda:0') [0, 1]\n",
      "tensor(37.7300, device='cuda:0') [0, 0]\n",
      "tensor(38.5900, device='cuda:0') [0, 1]\n",
      "tensor(39.3900, device='cuda:0') [0, 1]\n",
      "tensor(39.9500, device='cuda:0') [1, 1]\n",
      "tensor(40.1100, device='cuda:0') [1, 1]\n",
      "tensor(40.5300, device='cuda:0') [1, 1]\n",
      "tensor(41.1100, device='cuda:0') [0, 1]\n",
      "tensor(41.6100, device='cuda:0') [0, 1]\n",
      "tensor(41.6100, device='cuda:0') [0, 0]\n",
      "tensor(41.9300, device='cuda:0') [1, 0]\n",
      "tensor(42.7100, device='cuda:0') [1, 1]\n",
      "tensor(43.1700, device='cuda:0') [1, 1]\n",
      "tensor(43.5700, device='cuda:0') [0, 1]\n",
      "tensor(44.5400, device='cuda:0') [0, 1]\n",
      "tensor(45.0400, device='cuda:0') [0, 1]\n",
      "tensor(45.7400, device='cuda:0') [0, 1]\n",
      "tensor(46.3400, device='cuda:0') [0, 1]\n",
      "tensor(46.9400, device='cuda:0') [0, 1]\n",
      "tensor(47.6400, device='cuda:0') [0, 1]\n",
      "tensor(48.3400, device='cuda:0') [0, 1]\n",
      "tensor(48.8000, device='cuda:0') [1, 1]\n",
      "tensor(49.5000, device='cuda:0') [0, 1]\n",
      "tensor(49.9400, device='cuda:0') [1, 1]\n",
      "tensor(50.5400, device='cuda:0') [0, 1]\n",
      "tensor(51.1400, device='cuda:0') [0, 1]\n",
      "tensor(51.1400, device='cuda:0') [0, 0]\n",
      "tensor(52.0800, device='cuda:0') [0, 1]\n",
      "tensor(52.7800, device='cuda:0') [0, 1]\n",
      "tensor(53.2800, device='cuda:0') [0, 1]\n",
      "tensor(53.8200, device='cuda:0') [1, 1]\n",
      "tensor(53.8200, device='cuda:0') [0, 0]\n",
      "tensor(54.6600, device='cuda:0') [0, 1]\n",
      "tensor(54.6600, device='cuda:0') [0, 0]\n",
      "tensor(55.0200, device='cuda:0') [0, 1]\n",
      "tensor(55.8300, device='cuda:0') [1, 1]\n",
      "tensor(56.4500, device='cuda:0') [1, 1]\n",
      "tensor(57.0500, device='cuda:0') [0, 1]\n",
      "tensor(57.0500, device='cuda:0') [0, 0]\n",
      "tensor(57.0500, device='cuda:0') [0, 0]\n",
      "tensor(57.0500, device='cuda:0') [0, 0]\n",
      "tensor(57.8300, device='cuda:0') [1, 1]\n",
      "tensor(58.3300, device='cuda:0') [0, 1]\n",
      "tensor(58.8900, device='cuda:0') [1, 1]\n",
      "tensor(59.2900, device='cuda:0') [0, 1]\n",
      "tensor(59.7900, device='cuda:0') [0, 1]\n",
      "tensor(60.1900, device='cuda:0') [0, 1]\n",
      "tensor(60.1900, device='cuda:0') [0, 0]\n",
      "tensor(60.5100, device='cuda:0') [1, 0]\n",
      "tensor(60.5100, device='cuda:0') [0, 0]\n",
      "tensor(61.4500, device='cuda:0') [0, 1]\n",
      "tensor(62.0900, device='cuda:0') [1, 1]\n",
      "tensor(62.7900, device='cuda:0') [0, 1]\n",
      "tensor(63.4900, device='cuda:0') [0, 1]\n",
      "tensor(64.0500, device='cuda:0') [1, 1]\n",
      "tensor(64.6500, device='cuda:0') [0, 1]\n",
      "tensor(64.6500, device='cuda:0') [0, 0]\n",
      "tensor(64.6500, device='cuda:0') [0, 0]\n",
      "tensor(65.3100, device='cuda:0') [0, 1]\n",
      "tensor(66.1100, device='cuda:0') [0, 1]\n",
      "tensor(66.7100, device='cuda:0') [0, 1]\n",
      "tensor(67.4100, device='cuda:0') [0, 1]\n",
      "tensor(68.1100, device='cuda:0') [0, 1]\n",
      "tensor(68.6500, device='cuda:0') [1, 1]\n",
      "tensor(69.2100, device='cuda:0') [1, 1]\n",
      "tensor(69.6100, device='cuda:0') [0, 1]\n",
      "tensor(70.4700, device='cuda:0') [0, 1]\n",
      "tensor(71.1700, device='cuda:0') [0, 1]\n",
      "tensor(71.1700, device='cuda:0') [0, 0]\n",
      "tensor(72.1100, device='cuda:0') [1, 1]\n",
      "tensor(72.7100, device='cuda:0') [0, 1]\n",
      "tensor(72.7100, device='cuda:0') [0, 0]\n",
      "tensor(73.4500, device='cuda:0') [0, 1]\n",
      "tensor(73.8100, device='cuda:0') [1, 1]\n",
      "tensor(74.3700, device='cuda:0') [1, 1]\n",
      "tensor(75.0700, device='cuda:0') [0, 1]\n",
      "tensor(75.6300, device='cuda:0') [1, 1]\n",
      "tensor(76.4300, device='cuda:0') [0, 1]\n",
      "tensor(76.4300, device='cuda:0') [0, 0]\n",
      "tensor(77.2500, device='cuda:0') [0, 1]\n",
      "tensor(77.9500, device='cuda:0') [0, 1]\n",
      "tensor(78.6700, device='cuda:0') [1, 1]\n",
      "tensor(78.6700, device='cuda:0') [0, 0]\n",
      "tensor(79.5100, device='cuda:0') [1, 1]\n",
      "tensor(80.1100, device='cuda:0') [0, 1]\n",
      "tensor(80.5100, device='cuda:0') [0, 1]\n",
      "tensor(80.5100, device='cuda:0') [0, 0]\n",
      "tensor(81.4500, device='cuda:0') [1, 1]\n",
      "tensor(82.0500, device='cuda:0') [0, 1]\n",
      "tensor(82.5900, device='cuda:0') [1, 1]\n",
      "tensor(83.1300, device='cuda:0') [1, 1]\n",
      "tensor(83.7300, device='cuda:0') [0, 1]\n",
      "tensor(84.4300, device='cuda:0') [0, 1]\n",
      "tensor(85.0300, device='cuda:0') [0, 1]\n",
      "tensor(85.4900, device='cuda:0') [1, 1]\n",
      "tensor(86.0900, device='cuda:0') [0, 1]\n",
      "tensor(86.6900, device='cuda:0') [0, 1]\n",
      "tensor(86.6900, device='cuda:0') [0, 0]\n",
      "tensor(87.6300, device='cuda:0') [1, 1]\n",
      "tensor(87.6300, device='cuda:0') [0, 0]\n",
      "tensor(88.3300, device='cuda:0') [1, 1]\n",
      "tensor(88.8300, device='cuda:0') [0, 1]\n",
      "tensor(88.8300, device='cuda:0') [0, 0]\n",
      "tensor(89.5900, device='cuda:0') [0, 1]\n",
      "tensor(90.3900, device='cuda:0') [0, 1]\n",
      "tensor(91.0900, device='cuda:0') [0, 1]\n",
      "tensor(92.1900, device='cuda:0') [1, 1]\n",
      "tensor(92.1900, device='cuda:0') [0, 0]\n",
      "tensor(93.5100, device='cuda:0') [1, 1]\n",
      "tensor(94.1100, device='cuda:0') [0, 1]\n",
      "tensor(94.9100, device='cuda:0') [0, 1]\n",
      "tensor(95.7100, device='cuda:0') [0, 1]\n",
      "tensor(96.4100, device='cuda:0') [0, 1]\n",
      "tensor(97.2100, device='cuda:0') [0, 1]\n",
      "tensor(97.8100, device='cuda:0') [0, 1]\n",
      "tensor(99.3800, device='cuda:0') [0, 1]\n",
      "tensor(100.1800, device='cuda:0') [0, 1]\n",
      "tensor(100.8800, device='cuda:0') [0, 1]\n",
      "tensor(101.9800, device='cuda:0') [1, 1]\n",
      "tensor(103.3800, device='cuda:0') [0, 1]\n",
      "tensor(103.9800, device='cuda:0') [0, 1]\n",
      "tensor(105.0800, device='cuda:0') [1, 1]\n",
      "tensor(106.0800, device='cuda:0') [0, 1]\n",
      "tensor(107.2800, device='cuda:0') [0, 1]\n",
      "tensor(108.6800, device='cuda:0') [0, 1]\n",
      "tensor(109.3800, device='cuda:0') [0, 1]\n",
      "tensor(109.7000, device='cuda:0') [1, 1]\n",
      "tensor(109.7000, device='cuda:0') [0, 1]\n",
      "tensor(110.9820, device='cuda:0') [0, 1]\n",
      "tensor(112.2820, device='cuda:0') [0, 1]\n",
      "tensor(113.1220, device='cuda:0') [1, 1]\n",
      "tensor(113.4820, device='cuda:0') [0, 1]\n",
      "tensor(114.3220, device='cuda:0') [0, 1]\n",
      "tensor(115.0820, device='cuda:0') [0, 1]\n",
      "tensor(115.6720, device='cuda:0') [1, 1]\n",
      "tensor(116.7420, device='cuda:0') [0, 1]\n",
      "tensor(118.0420, device='cuda:0') [0, 1]\n",
      "tensor(118.6420, device='cuda:0') [0, 1]\n",
      "tensor(119.6420, device='cuda:0') [1, 1]\n",
      "tensor(120.4420, device='cuda:0') [0, 1]\n",
      "tensor(121.3220, device='cuda:0') [1, 1]\n",
      "tensor(121.3220, device='cuda:0') [0, 0]\n",
      "tensor(122.4420, device='cuda:0') [0, 1]\n",
      "tensor(123.2420, device='cuda:0') [0, 1]\n",
      "tensor(124.0220, device='cuda:0') [1, 1]\n",
      "tensor(124.0220, device='cuda:0') [1, 1]\n",
      "tensor(124.7420, device='cuda:0') [0, 0]\n",
      "tensor(126.4450, device='cuda:0') [0, 1]\n",
      "tensor(127.4450, device='cuda:0') [0, 1]\n",
      "tensor(127.8450, device='cuda:0') [0, 1]\n",
      "tensor(129.3050, device='cuda:0') [1, 1]\n",
      "tensor(130.3050, device='cuda:0') [0, 1]\n",
      "tensor(130.4850, device='cuda:0') [0, 1]\n",
      "tensor(131.3850, device='cuda:0') [0, 1]\n",
      "tensor(132.4050, device='cuda:0') [0, 1]\n",
      "tensor(132.4050, device='cuda:0') [0, 1]\n",
      "tensor(133.5750, device='cuda:0') [1, 1]\n",
      "tensor(135.1410, device='cuda:0') [0, 1]\n",
      "tensor(135.8610, device='cuda:0') [0, 1]\n",
      "tensor(136.4010, device='cuda:0') [0, 1]\n",
      "tensor(136.9140, device='cuda:0') [0, 1]\n",
      "tensor(138.0840, device='cuda:0') [0, 1]\n",
      "tensor(138.5880, device='cuda:0') [0, 1]\n",
      "tensor(139.9819, device='cuda:0') [1, 1]\n",
      "tensor(140.2520, device='cuda:0') [0, 1]\n",
      "tensor(140.9035, device='cuda:0') [0, 1]\n",
      "tensor(142.6136, device='cuda:0') [0, 1]\n",
      "tensor(144.0435, device='cuda:0') [1, 1]\n",
      "tensor(144.0435, device='cuda:0') [0, 1]\n",
      "tensor(144.7455, device='cuda:0') [0, 1]\n",
      "tensor(145.3485, device='cuda:0') [0, 1]\n",
      "tensor(146.8785, device='cuda:0') [0, 1]\n",
      "tensor(147.7785, device='cuda:0') [1, 1]\n",
      "tensor(148.6605, device='cuda:0') [0, 1]\n",
      "tensor(148.9845, device='cuda:0') [0, 1]\n",
      "tensor(151.2076, device='cuda:0') [0, 1]\n",
      "tensor(151.5676, device='cuda:0') [0, 1]\n",
      "tensor(151.8916, device='cuda:0') [0, 1]\n",
      "tensor(152.7236, device='cuda:0') [0, 1]\n",
      "tensor(152.7236, device='cuda:0') [1, 1]\n",
      "tensor(153.7060, device='cuda:0') [0, 1]\n",
      "tensor(154.4814, device='cuda:0') [0, 1]\n",
      "tensor(155.4975, device='cuda:0') [0, 1]\n",
      "tensor(155.7675, device='cuda:0') [0, 1]\n",
      "tensor(157.5836, device='cuda:0') [1, 1]\n",
      "tensor(158.5929, device='cuda:0') [0, 1]\n",
      "tensor(159.1959, device='cuda:0') [0, 1]\n",
      "tensor(159.1959, device='cuda:0') [0, 1]\n",
      "tensor(159.5199, device='cuda:0') [0, 1]\n",
      "tensor(160.3672, device='cuda:0') [0, 1]\n",
      "tensor(160.9702, device='cuda:0') [0, 1]\n",
      "tensor(161.6338, device='cuda:0') [0, 1]\n",
      "tensor(162.2075, device='cuda:0') [1, 1]\n",
      "tensor(163.5836, device='cuda:0') [1, 1]\n",
      "tensor(165.3392, device='cuda:0') [0, 1]\n",
      "tensor(165.7329, device='cuda:0') [0, 1]\n",
      "tensor(166.3929, device='cuda:0') [0, 1]\n",
      "tensor(166.9845, device='cuda:0') [0, 1]\n",
      "tensor(167.4219, device='cuda:0') [0, 1]\n",
      "tensor(167.7819, device='cuda:0') [0, 1]\n",
      "tensor(169.2043, device='cuda:0') [1, 1]\n",
      "tensor(170.0354, device='cuda:0') [0, 1]\n",
      "tensor(170.0354, device='cuda:0') [0, 1]\n",
      "tensor(171.2261, device='cuda:0') [0, 1]\n",
      "tensor(172.9865, device='cuda:0') [0, 1]\n",
      "tensor(172.9865, device='cuda:0') [0, 1]\n",
      "tensor(173.3105, device='cuda:0') [0, 1]\n",
      "tensor(175.2049, device='cuda:0') [1, 1]\n",
      "tensor(175.2049, device='cuda:0') [0, 1]\n",
      "tensor(175.3669, device='cuda:0') [1, 1]\n",
      "tensor(176.9261, device='cuda:0') [0, 1]\n",
      "tensor(177.4323, device='cuda:0') [0, 1]\n",
      "tensor(177.4323, device='cuda:0') [0, 1]\n",
      "tensor(178.0915, device='cuda:0') [0, 1]\n",
      "tensor(180.1092, device='cuda:0') [1, 1]\n",
      "tensor(180.7266, device='cuda:0') [0, 1]\n",
      "tensor(180.9966, device='cuda:0') [0, 1]\n",
      "tensor(183.0491, device='cuda:0') [1, 1]\n",
      "tensor(183.5351, device='cuda:0') [0, 1]\n",
      "tensor(184.1381, device='cuda:0') [0, 1]\n",
      "tensor(184.3181, device='cuda:0') [0, 1]\n",
      "tensor(185.8571, device='cuda:0') [0, 1]\n",
      "tensor(186.2801, device='cuda:0') [0, 1]\n",
      "tensor(186.5501, device='cuda:0') [1, 1]\n",
      "tensor(188.0941, device='cuda:0') [0, 1]\n",
      "tensor(188.3641, device='cuda:0') [0, 1]\n",
      "tensor(188.7241, device='cuda:0') [0, 1]\n",
      "tensor(189.6203, device='cuda:0') [0, 1]\n",
      "tensor(191.5430, device='cuda:0') [1, 1]\n",
      "tensor(191.5430, device='cuda:0') [0, 1]\n",
      "tensor(192.0560, device='cuda:0') [0, 1]\n",
      "tensor(193.2798, device='cuda:0') [0, 1]\n",
      "tensor(193.2798, device='cuda:0') [0, 1]\n",
      "tensor(193.8738, device='cuda:0') [0, 1]\n",
      "tensor(195.2475, device='cuda:0') [1, 1]\n",
      "tensor(196.3701, device='cuda:0') [0, 1]\n",
      "tensor(196.7931, device='cuda:0') [1, 1]\n",
      "tensor(197.9068, device='cuda:0') [0, 1]\n",
      "tensor(198.7204, device='cuda:0') [0, 1]\n",
      "tensor(199.0804, device='cuda:0') [0, 1]\n",
      "tensor(199.7878, device='cuda:0') [0, 1]\n",
      "tensor(200.5168, device='cuda:0') [0, 1]\n",
      "tensor(201.4888, device='cuda:0') [0, 1]\n",
      "tensor(202.6498, device='cuda:0') [0, 1]\n",
      "tensor(203.0098, device='cuda:0') [1, 1]\n",
      "tensor(204.1055, device='cuda:0') [0, 1]\n",
      "tensor(204.7279, device='cuda:0') [0, 1]\n",
      "tensor(204.9979, device='cuda:0') [1, 1]\n",
      "tensor(205.9879, device='cuda:0') [0, 1]\n",
      "tensor(205.9879, device='cuda:0') [0, 1]\n",
      "tensor(206.7969, device='cuda:0') [0, 1]\n",
      "tensor(208.2426, device='cuda:0') [0, 1]\n",
      "tensor(209.1163, device='cuda:0') [1, 1]\n",
      "tensor(209.6899, device='cuda:0') [0, 1]\n",
      "tensor(209.9599, device='cuda:0') [1, 1]\n",
      "tensor(211.0399, device='cuda:0') [0, 1]\n",
      "tensor(211.2525, device='cuda:0') [0, 1]\n",
      "tensor(211.7081, device='cuda:0') [0, 1]\n",
      "tensor(212.8116, device='cuda:0') [0, 1]\n",
      "tensor(213.8277, device='cuda:0') [0, 1]\n",
      "tensor(214.5813, device='cuda:0') [0, 1]\n",
      "tensor(215.6354, device='cuda:0') [1, 1]\n",
      "tensor(215.6354, device='cuda:0') [0, 1]\n",
      "tensor(216.1574, device='cuda:0') [0, 1]\n",
      "tensor(216.4274, device='cuda:0') [1, 1]\n",
      "tensor(218.6070, device='cuda:0') [1, 1]\n",
      "tensor(219.0007, device='cuda:0') [0, 1]\n",
      "tensor(219.8037, device='cuda:0') [0, 1]\n",
      "tensor(220.1580, device='cuda:0') [0, 1]\n",
      "tensor(221.5854, device='cuda:0') [1, 1]\n",
      "tensor(222.3054, device='cuda:0') [0, 1]\n",
      "tensor(223.1084, device='cuda:0') [0, 1]\n",
      "tensor(223.5020, device='cuda:0') [0, 1]\n",
      "tensor(223.7720, device='cuda:0') [1, 1]\n",
      "tensor(225.1481, device='cuda:0') [0, 1]\n",
      "tensor(226.8648, device='cuda:0') [0, 1]\n",
      "tensor(227.1348, device='cuda:0') [0, 1]\n",
      "tensor(227.1348, device='cuda:0') [0, 1]\n",
      "tensor(227.5592, device='cuda:0') [0, 1]\n",
      "tensor(228.3849, device='cuda:0') [0, 1]\n",
      "tensor(228.8849, device='cuda:0') [1, 1]\n",
      "tensor(229.7454, device='cuda:0') [0, 1]\n",
      "tensor(230.7597, device='cuda:0') [1, 1]\n",
      "tensor(230.7597, device='cuda:0') [1, 1]\n",
      "tensor(232.6525, device='cuda:0') [1, 1]\n",
      "tensor(233.2338, device='cuda:0') [0, 1]\n",
      "tensor(233.7378, device='cuda:0') [0, 1]\n",
      "tensor(233.7378, device='cuda:0') [0, 1]\n",
      "tensor(235.0698, device='cuda:0') [0, 1]\n",
      "tensor(235.5072, device='cuda:0') [0, 1]\n",
      "tensor(236.7492, device='cuda:0') [0, 1]\n",
      "tensor(237.8868, device='cuda:0') [1, 1]\n",
      "tensor(238.6068, device='cuda:0') [0, 1]\n",
      "tensor(239.1108, device='cuda:0') [0, 1]\n",
      "tensor(239.2908, device='cuda:0') [0, 1]\n",
      "tensor(240.5544, device='cuda:0') [1, 1]\n",
      "tensor(240.7344, device='cuda:0') [0, 1]\n",
      "tensor(241.2669, device='cuda:0') [0, 1]\n",
      "tensor(242.4105, device='cuda:0') [1, 1]\n",
      "tensor(243.2079, device='cuda:0') [0, 1]\n",
      "tensor(243.9153, device='cuda:0') [0, 1]\n",
      "tensor(245.3193, device='cuda:0') [0, 1]\n",
      "tensor(245.5893, device='cuda:0') [1, 1]\n",
      "tensor(246.2573, device='cuda:0') [0, 1]\n",
      "tensor(247.1747, device='cuda:0') [1, 1]\n",
      "tensor(248.8787, device='cuda:0') [1, 1]\n",
      "tensor(248.8787, device='cuda:0') [0, 0]\n",
      "tensor(250.1187, device='cuda:0') [1, 1]\n",
      "tensor(250.1187, device='cuda:0') [0, 1]\n",
      "tensor(251.6887, device='cuda:0') [0, 1]\n",
      "tensor(253.1287, device='cuda:0') [0, 1]\n",
      "tensor(253.7287, device='cuda:0') [0, 1]\n",
      "tensor(253.9087, device='cuda:0') [0, 1]\n",
      "tensor(254.5687, device='cuda:0') [1, 1]\n",
      "tensor(254.8387, device='cuda:0') [0, 1]\n",
      "tensor(255.8187, device='cuda:0') [1, 1]\n",
      "tensor(257.0052, device='cuda:0') [0, 1]\n",
      "tensor(258.9182, device='cuda:0') [0, 1]\n",
      "tensor(258.9182, device='cuda:0') [0, 1]\n",
      "tensor(259.6382, device='cuda:0') [0, 1]\n",
      "tensor(261.2482, device='cuda:0') [0, 1]\n",
      "tensor(261.4482, device='cuda:0') [0, 1]\n",
      "tensor(261.9882, device='cuda:0') [1, 1]\n",
      "tensor(264.0682, device='cuda:0') [0, 1]\n",
      "tensor(265.3682, device='cuda:0') [0, 1]\n",
      "tensor(265.7682, device='cuda:0') [0, 1]\n",
      "tensor(266.1281, device='cuda:0') [1, 1]\n",
      "tensor(268.0081, device='cuda:0') [0, 1]\n",
      "tensor(268.6082, device='cuda:0') [0, 1]\n",
      "tensor(269.9882, device='cuda:0') [0, 1]\n",
      "tensor(270.9882, device='cuda:0') [0, 1]\n",
      "tensor(272.0482, device='cuda:0') [1, 1]\n",
      "tensor(272.0482, device='cuda:0') [0, 1]\n",
      "tensor(273.3282, device='cuda:0') [0, 1]\n",
      "tensor(273.8682, device='cuda:0') [1, 1]\n",
      "tensor(276.1582, device='cuda:0') [0, 1]\n",
      "tensor(276.1582, device='cuda:0') [0, 1]\n",
      "tensor(276.9982, device='cuda:0') [1, 1]\n",
      "tensor(277.6582, device='cuda:0') [0, 1]\n",
      "tensor(277.9498, device='cuda:0') [0, 1]\n",
      "tensor(279.2998, device='cuda:0') [0, 1]\n",
      "tensor(279.8938, device='cuda:0') [0, 1]\n",
      "tensor(280.1638, device='cuda:0') [0, 1]\n",
      "tensor(281.3014, device='cuda:0') [1, 1]\n",
      "tensor(282.0214, device='cuda:0') [0, 1]\n",
      "tensor(283.5359, device='cuda:0') [1, 1]\n",
      "tensor(284.0219, device='cuda:0') [0, 1]\n",
      "tensor(284.9039, device='cuda:0') [0, 1]\n",
      "tensor(285.1739, device='cuda:0') [0, 1]\n",
      "tensor(286.6979, device='cuda:0') [0, 1]\n",
      "tensor(287.2379, device='cuda:0') [0, 1]\n",
      "tensor(287.5079, device='cuda:0') [1, 1]\n",
      "tensor(289.0379, device='cuda:0') [0, 1]\n",
      "tensor(290.7809, device='cuda:0') [0, 1]\n",
      "tensor(291.3749, device='cuda:0') [0, 1]\n",
      "tensor(291.9149, device='cuda:0') [0, 1]\n",
      "tensor(292.8149, device='cuda:0') [1, 1]\n",
      "tensor(293.8049, device='cuda:0') [0, 1]\n",
      "tensor(294.1649, device='cuda:0') [0, 1]\n",
      "tensor(295.5509, device='cuda:0') [0, 1]\n",
      "tensor(296.2349, device='cuda:0') [0, 1]\n",
      "tensor(296.2349, device='cuda:0') [0, 1]\n",
      "tensor(298.4579, device='cuda:0') [0, 1]\n",
      "tensor(299.2679, device='cuda:0') [1, 1]\n",
      "tensor(300.1498, device='cuda:0') [0, 1]\n",
      "tensor(300.8788, device='cuda:0') [0, 1]\n",
      "tensor(301.4476, device='cuda:0') [1, 1]\n",
      "tensor(302.1676, device='cuda:0') [0, 1]\n",
      "tensor(302.6896, device='cuda:0') [0, 1]\n",
      "tensor(303.3139, device='cuda:0') [0, 1]\n",
      "tensor(303.4939, device='cuda:0') [0, 1]\n",
      "tensor(303.4939, device='cuda:0') [0, 1]\n",
      "tensor(305.3672, device='cuda:0') [1, 1]\n",
      "tensor(305.7215, device='cuda:0') [0, 1]\n",
      "tensor(306.4055, device='cuda:0') [0, 1]\n",
      "tensor(307.2586, device='cuda:0') [0, 1]\n",
      "tensor(307.2586, device='cuda:0') [1, 1]\n",
      "tensor(308.1406, device='cuda:0') [0, 1]\n",
      "tensor(309.1768, device='cuda:0') [0, 1]\n",
      "tensor(309.5930, device='cuda:0') [0, 1]\n",
      "tensor(309.5930, device='cuda:0') [0, 1]\n",
      "tensor(311.8709, device='cuda:0') [1, 1]\n",
      "tensor(312.3133, device='cuda:0') [0, 1]\n",
      "tensor(312.5758, device='cuda:0') [0, 1]\n",
      "tensor(313.0002, device='cuda:0') [0, 1]\n",
      "tensor(314.0316, device='cuda:0') [0, 1]\n",
      "tensor(314.6832, device='cuda:0') [0, 1]\n",
      "tensor(315.3006, device='cuda:0') [0, 1]\n",
      "tensor(316.0080, device='cuda:0') [0, 1]\n",
      "tensor(316.6680, device='cuda:0') [1, 1]\n",
      "tensor(317.2417, device='cuda:0') [1, 1]\n",
      "tensor(318.7977, device='cuda:0') [0, 1]\n",
      "tensor(319.5977, device='cuda:0') [1, 1]\n",
      "tensor(320.0837, device='cuda:0') [0, 1]\n",
      "tensor(321.1367, device='cuda:0') [0, 1]\n",
      "tensor(322.2767, device='cuda:0') [0, 1]\n",
      "tensor(322.6767, device='cuda:0') [0, 1]\n",
      "tensor(323.8797, device='cuda:0') [1, 1]\n",
      "tensor(323.8797, device='cuda:0') [0, 1]\n",
      "tensor(325.2897, device='cuda:0') [0, 1]\n",
      "tensor(326.5597, device='cuda:0') [0, 1]\n",
      "tensor(326.9597, device='cuda:0') [0, 1]\n",
      "tensor(327.9397, device='cuda:0') [1, 1]\n",
      "tensor(329.0997, device='cuda:0') [0, 1]\n",
      "tensor(330.2997, device='cuda:0') [1, 1]\n",
      "tensor(330.2997, device='cuda:0') [0, 0]\n",
      "tensor(331.3197, device='cuda:0') [0, 1]\n",
      "tensor(331.9197, device='cuda:0') [0, 1]\n",
      "tensor(332.1198, device='cuda:0') [0, 1]\n",
      "tensor(334.2198, device='cuda:0') [1, 1]\n",
      "tensor(335.4198, device='cuda:0') [0, 1]\n",
      "tensor(335.4198, device='cuda:0') [0, 0]\n",
      "tensor(336.5398, device='cuda:0') [1, 1]\n",
      "tensor(337.3398, device='cuda:0') [0, 1]\n",
      "tensor(337.6397, device='cuda:0') [0, 1]\n",
      "tensor(339.1797, device='cuda:0') [0, 1]\n",
      "tensor(339.9797, device='cuda:0') [1, 1]\n",
      "tensor(340.3397, device='cuda:0') [0, 1]\n",
      "tensor(340.5197, device='cuda:0') [0, 1]\n",
      "tensor(342.4397, device='cuda:0') [0, 1]\n",
      "tensor(343.0997, device='cuda:0') [0, 1]\n",
      "tensor(343.9397, device='cuda:0') [1, 1]\n",
      "tensor(344.9197, device='cuda:0') [1, 1]\n",
      "tensor(345.1897, device='cuda:0') [0, 0]\n",
      "tensor(345.8097, device='cuda:0') [0, 1]\n",
      "tensor(347.3497, device='cuda:0') [0, 1]\n",
      "tensor(348.5097, device='cuda:0') [1, 1]\n",
      "tensor(349.0797, device='cuda:0') [0, 1]\n",
      "tensor(349.4397, device='cuda:0') [0, 1]\n",
      "tensor(350.9397, device='cuda:0') [0, 1]\n",
      "tensor(351.7337, device='cuda:0') [0, 1]\n",
      "tensor(352.2737, device='cuda:0') [0, 1]\n",
      "tensor(353.6537, device='cuda:0') [1, 1]\n",
      "tensor(353.8337, device='cuda:0') [0, 1]\n",
      "tensor(354.1037, device='cuda:0') [1, 1]\n",
      "tensor(355.7477, device='cuda:0') [0, 1]\n",
      "tensor(356.2607, device='cuda:0') [0, 1]\n",
      "tensor(356.8907, device='cuda:0') [0, 1]\n",
      "tensor(357.6107, device='cuda:0') [0, 1]\n",
      "tensor(359.1307, device='cuda:0') [1, 1]\n",
      "tensor(360.7007, device='cuda:0') [0, 1]\n",
      "tensor(361.5007, device='cuda:0') [0, 1]\n",
      "tensor(361.9007, device='cuda:0') [0, 1]\n",
      "tensor(362.4607, device='cuda:0') [0, 1]\n",
      "tensor(363.3607, device='cuda:0') [1, 1]\n",
      "tensor(364.3507, device='cuda:0') [0, 0]\n",
      "tensor(365.3707, device='cuda:0') [0, 1]\n",
      "tensor(365.6907, device='cuda:0') [1, 1]\n",
      "tensor(365.9607, device='cuda:0') [0, 1]\n",
      "tensor(366.6207, device='cuda:0') [0, 1]\n",
      "tensor(368.0467, device='cuda:0') [0, 1]\n",
      "tensor(369.0067, device='cuda:0') [0, 1]\n",
      "tensor(369.4867, device='cuda:0') [1, 1]\n",
      "tensor(369.9567, device='cuda:0') [0, 1]\n",
      "tensor(371.0967, device='cuda:0') [0, 1]\n",
      "tensor(372.3667, device='cuda:0') [1, 1]\n",
      "tensor(373.1667, device='cuda:0') [0, 1]\n",
      "tensor(373.9667, device='cuda:0') [0, 1]\n",
      "tensor(375.2667, device='cuda:0') [0, 1]\n",
      "tensor(375.8867, device='cuda:0') [1, 1]\n",
      "tensor(375.8867, device='cuda:0') [1, 0]\n",
      "tensor(376.6067, device='cuda:0') [0, 0]\n",
      "tensor(377.5467, device='cuda:0') [0, 1]\n",
      "tensor(378.4267, device='cuda:0') [1, 1]\n",
      "tensor(378.4267, device='cuda:0') [0, 1]\n",
      "tensor(380.2067, device='cuda:0') [0, 1]\n",
      "tensor(381.2067, device='cuda:0') [0, 1]\n",
      "tensor(382.0867, device='cuda:0') [0, 1]\n",
      "tensor(382.8867, device='cuda:0') [1, 1]\n",
      "tensor(384.1467, device='cuda:0') [0, 1]\n",
      "tensor(385.5467, device='cuda:0') [0, 1]\n",
      "tensor(386.3466, device='cuda:0') [0, 1]\n",
      "tensor(386.6667, device='cuda:0') [1, 1]\n",
      "tensor(387.7367, device='cuda:0') [1, 1]\n",
      "tensor(387.9167, device='cuda:0') [0, 1]\n",
      "tensor(388.8766, device='cuda:0') [0, 1]\n",
      "tensor(390.2997, device='cuda:0') [0, 1]\n",
      "tensor(390.8997, device='cuda:0') [0, 1]\n",
      "tensor(391.6597, device='cuda:0') [0, 1]\n",
      "tensor(392.9997, device='cuda:0') [1, 1]\n",
      "tensor(393.8697, device='cuda:0') [0, 1]\n",
      "tensor(394.2697, device='cuda:0') [0, 1]\n",
      "tensor(395.7827, device='cuda:0') [0, 1]\n",
      "tensor(396.7527, device='cuda:0') [0, 1]\n",
      "tensor(396.7527, device='cuda:0') [0, 1]\n",
      "tensor(398.2726, device='cuda:0') [1, 1]\n",
      "tensor(399.8526, device='cuda:0') [0, 1]\n",
      "tensor(400.5526, device='cuda:0') [0, 1]\n",
      "tensor(401.4526, device='cuda:0') [0, 1]\n",
      "tensor(401.7726, device='cuda:0') [1, 1]\n",
      "tensor(402.2426, device='cuda:0') [0, 1]\n",
      "tensor(403.4826, device='cuda:0') [0, 1]\n",
      "tensor(404.2826, device='cuda:0') [1, 1]\n",
      "tensor(405.4526, device='cuda:0') [0, 1]\n",
      "tensor(406.1526, device='cuda:0') [0, 1]\n",
      "tensor(406.9526, device='cuda:0') [0, 1]\n",
      "tensor(407.7526, device='cuda:0') [0, 1]\n",
      "tensor(408.9526, device='cuda:0') [1, 1]\n",
      "tensor(409.9526, device='cuda:0') [0, 1]\n",
      "tensor(410.6526, device='cuda:0') [0, 1]\n",
      "tensor(410.6526, device='cuda:0') [0, 0]\n",
      "tensor(411.4526, device='cuda:0') [1, 1]\n",
      "tensor(412.6227, device='cuda:0') [0, 1]\n",
      "tensor(413.9226, device='cuda:0') [0, 1]\n",
      "tensor(413.9226, device='cuda:0') [1, 1]\n",
      "tensor(415.0026, device='cuda:0') [0, 0]\n",
      "tensor(415.6426, device='cuda:0') [1, 1]\n",
      "tensor(416.2026, device='cuda:0') [0, 1]\n",
      "tensor(416.7426, device='cuda:0') [0, 1]\n",
      "tensor(418.2227, device='cuda:0') [0, 1]\n",
      "tensor(419.3827, device='cuda:0') [0, 1]\n",
      "tensor(420.1627, device='cuda:0') [1, 1]\n",
      "tensor(420.1627, device='cuda:0') [0, 1]\n",
      "tensor(420.9727, device='cuda:0') [0, 1]\n",
      "tensor(422.9427, device='cuda:0') [1, 1]\n",
      "tensor(423.3026, device='cuda:0') [0, 0]\n",
      "tensor(424.2626, device='cuda:0') [1, 1]\n",
      "tensor(424.7426, device='cuda:0') [0, 1]\n",
      "tensor(425.2827, device='cuda:0') [0, 1]\n",
      "tensor(427.8427, device='cuda:0') [0, 1]\n",
      "tensor(428.5427, device='cuda:0') [0, 1]\n",
      "tensor(428.5427, device='cuda:0') [1, 1]\n",
      "tensor(429.2627, device='cuda:0') [0, 1]\n",
      "tensor(429.8657, device='cuda:0') [0, 1]\n",
      "tensor(431.7617, device='cuda:0') [0, 1]\n",
      "tensor(431.7617, device='cuda:0') [0, 1]\n",
      "tensor(432.1037, device='cuda:0') [1, 1]\n",
      "tensor(433.0037, device='cuda:0') [1, 1]\n",
      "tensor(433.9937, device='cuda:0') [0, 1]\n",
      "tensor(434.9761, device='cuda:0') [0, 1]\n",
      "tensor(434.9761, device='cuda:0') [0, 0]\n",
      "tensor(435.5391, device='cuda:0') [0, 1]\n",
      "tensor(435.8991, device='cuda:0') [0, 1]\n",
      "tensor(437.5191, device='cuda:0') [0, 1]\n",
      "tensor(437.6991, device='cuda:0') [0, 1]\n",
      "tensor(438.5091, device='cuda:0') [0, 1]\n",
      "tensor(440.9291, device='cuda:0') [1, 1]\n",
      "tensor(441.1091, device='cuda:0') [0, 1]\n",
      "tensor(441.2891, device='cuda:0') [1, 1]\n",
      "tensor(442.6931, device='cuda:0') [0, 1]\n",
      "tensor(443.2531, device='cuda:0') [0, 1]\n",
      "tensor(443.2531, device='cuda:0') [0, 1]\n",
      "tensor(444.3007, device='cuda:0') [0, 1]\n",
      "tensor(445.8307, device='cuda:0') [0, 1]\n",
      "tensor(446.0107, device='cuda:0') [1, 1]\n",
      "tensor(447.2166, device='cuda:0') [0, 1]\n",
      "tensor(448.5486, device='cuda:0') [0, 1]\n",
      "tensor(449.7187, device='cuda:0') [0, 1]\n",
      "tensor(450.9787, device='cuda:0') [0, 1]\n",
      "tensor(451.5687, device='cuda:0') [1, 1]\n",
      "tensor(451.8387, device='cuda:0') [1, 1]\n",
      "tensor(452.2761, device='cuda:0') [0, 1]\n",
      "tensor(453.1671, device='cuda:0') [0, 1]\n",
      "tensor(454.4091, device='cuda:0') [0, 1]\n",
      "tensor(454.4091, device='cuda:0') [0, 1]\n",
      "tensor(455.1221, device='cuda:0') [0, 1]\n",
      "tensor(455.8645, device='cuda:0') [1, 1]\n",
      "tensor(457.2159, device='cuda:0') [0, 1]\n",
      "tensor(458.0876, device='cuda:0') [0, 1]\n",
      "tensor(458.0876, device='cuda:0') [0, 1]\n",
      "tensor(458.7950, device='cuda:0') [0, 1]\n",
      "tensor(459.4466, device='cuda:0') [0, 1]\n",
      "tensor(460.6282, device='cuda:0') [1, 1]\n",
      "tensor(461.8656, device='cuda:0') [1, 1]\n",
      "tensor(461.8656, device='cuda:0') [0, 1]\n",
      "tensor(462.8700, device='cuda:0') [0, 1]\n",
      "tensor(464.5200, device='cuda:0') [0, 1]\n",
      "tensor(466.2600, device='cuda:0') [1, 1]\n",
      "tensor(466.2600, device='cuda:0') [0, 1]\n",
      "tensor(468.2800, device='cuda:0') [0, 1]\n",
      "tensor(468.2800, device='cuda:0') [0, 1]\n",
      "tensor(469.2600, device='cuda:0') [1, 1]\n",
      "tensor(470.2500, device='cuda:0') [0, 1]\n",
      "tensor(471.5500, device='cuda:0') [0, 1]\n",
      "tensor(471.9500, device='cuda:0') [0, 1]\n",
      "tensor(472.2740, device='cuda:0') [1, 1]\n",
      "tensor(472.7599, device='cuda:0') [0, 1]\n",
      "tensor(473.8399, device='cuda:0') [0, 1]\n",
      "tensor(474.1999, device='cuda:0') [0, 1]\n",
      "tensor(476.8189, device='cuda:0') [0, 1]\n",
      "tensor(477.1789, device='cuda:0') [1, 1]\n",
      "tensor(478.1689, device='cuda:0') [0, 1]\n",
      "tensor(479.7079, device='cuda:0') [0, 1]\n",
      "tensor(479.7079, device='cuda:0') [0, 1]\n",
      "tensor(480.1309, device='cuda:0') [0, 1]\n",
      "tensor(480.4009, device='cuda:0') [1, 1]\n",
      "tensor(481.1209, device='cuda:0') [0, 1]\n",
      "tensor(481.4629, device='cuda:0') [0, 1]\n",
      "tensor(481.9618, device='cuda:0') [0, 1]\n",
      "tensor(483.5723, device='cuda:0') [1, 1]\n",
      "tensor(483.9323, device='cuda:0') [0, 1]\n",
      "tensor(484.5923, device='cuda:0') [0, 1]\n",
      "tensor(484.9466, device='cuda:0') [0, 1]\n",
      "tensor(485.2166, device='cuda:0') [1, 1]\n",
      "tensor(486.5092, device='cuda:0') [0, 1]\n",
      "tensor(487.9912, device='cuda:0') [0, 1]\n",
      "tensor(489.1512, device='cuda:0') [1, 1]\n",
      "tensor(489.4212, device='cuda:0') [0, 1]\n",
      "tensor(490.6122, device='cuda:0') [0, 1]\n",
      "tensor(491.4222, device='cuda:0') [0, 1]\n",
      "tensor(492.0162, device='cuda:0') [0, 1]\n",
      "tensor(492.4536, device='cuda:0') [0, 1]\n",
      "tensor(492.7776, device='cuda:0') [0, 1]\n",
      "tensor(493.0207, device='cuda:0') [0, 1]\n",
      "tensor(494.9513, device='cuda:0') [0, 1]\n",
      "tensor(495.6074, device='cuda:0') [0, 1]\n",
      "tensor(496.6013, device='cuda:0') [0, 1]\n",
      "tensor(496.8376, device='cuda:0') [1, 1]\n",
      "tensor(497.5396, device='cuda:0') [0, 1]\n",
      "tensor(498.0384, device='cuda:0') [0, 1]\n",
      "tensor(499.1084, device='cuda:0') [1, 1]\n",
      "tensor(500.2567, device='cuda:0') [0, 1]\n",
      "tensor(500.2567, device='cuda:0') [0, 1]\n",
      "tensor(500.3267, device='cuda:0') [0, 1]\n",
      "tensor(501.1874, device='cuda:0') [0, 1]\n",
      "tensor(502.0070, device='cuda:0') [1, 1]\n",
      "tensor(502.1870, device='cuda:0') [1, 1]\n",
      "tensor(503.2670, device='cuda:0') [0, 1]\n",
      "tensor(503.6270, device='cuda:0') [0, 1]\n",
      "tensor(504.2452, device='cuda:0') [0, 1]\n",
      "tensor(505.4164, device='cuda:0') [0, 1]\n",
      "tensor(506.9914, device='cuda:0') [0, 1]\n",
      "tensor(507.2614, device='cuda:0') [0, 1]\n",
      "tensor(508.3314, device='cuda:0') [1, 1]\n",
      "tensor(508.9875, device='cuda:0') [0, 1]\n",
      "tensor(510.3276, device='cuda:0') [0, 1]\n",
      "tensor(510.5976, device='cuda:0') [1, 1]\n",
      "tensor(511.5538, device='cuda:0') [0, 1]\n",
      "tensor(511.5538, device='cuda:0') [0, 1]\n",
      "tensor(512.1955, device='cuda:0') [0, 1]\n",
      "tensor(512.7269, device='cuda:0') [0, 1]\n",
      "tensor(513.4952, device='cuda:0') [0, 1]\n",
      "tensor(513.9182, device='cuda:0') [1, 1]\n",
      "tensor(514.9081, device='cuda:0') [0, 1]\n",
      "tensor(515.5870, device='cuda:0') [0, 1]\n",
      "tensor(516.3221, device='cuda:0') [0, 1]\n",
      "tensor(516.5021, device='cuda:0') [1, 1]\n",
      "tensor(517.5229, device='cuda:0') [1, 1]\n",
      "tensor(518.4230, device='cuda:0') [0, 1]\n",
      "tensor(518.6356, device='cuda:0') [0, 1]\n",
      "tensor(520.2053, device='cuda:0') [0, 1]\n",
      "tensor(520.4969, device='cuda:0') [0, 1]\n",
      "tensor(520.4969, device='cuda:0') [0, 1]\n",
      "tensor(521.9064, device='cuda:0') [0, 1]\n",
      "tensor(522.5004, device='cuda:0') [0, 1]\n",
      "tensor(522.8940, device='cuda:0') [0, 1]\n",
      "tensor(523.5795, device='cuda:0') [1, 1]\n",
      "tensor(524.9556, device='cuda:0') [0, 1]\n",
      "tensor(526.0396, device='cuda:0') [0, 1]\n",
      "tensor(526.4396, device='cuda:0') [0, 1]\n",
      "tensor(526.8884, device='cuda:0') [0, 1]\n",
      "tensor(527.5445, device='cuda:0') [1, 1]\n",
      "tensor(528.7865, device='cuda:0') [0, 1]\n",
      "tensor(529.4108, device='cuda:0') [0, 1]\n",
      "tensor(530.1794, device='cuda:0') [0, 1]\n",
      "tensor(530.1794, device='cuda:0') [1, 1]\n",
      "tensor(531.0614, device='cuda:0') [0, 1]\n",
      "tensor(532.0097, device='cuda:0') [0, 1]\n",
      "tensor(533.1738, device='cuda:0') [0, 1]\n",
      "tensor(533.6112, device='cuda:0') [0, 1]\n",
      "tensor(534.2052, device='cuda:0') [0, 1]\n",
      "tensor(534.7789, device='cuda:0') [1, 1]\n",
      "tensor(535.4988, device='cuda:0') [0, 1]\n",
      "tensor(536.6024, device='cuda:0') [0, 1]\n",
      "tensor(537.0186, device='cuda:0') [0, 1]\n",
      "tensor(537.3729, device='cuda:0') [0, 1]\n",
      "tensor(539.1758, device='cuda:0') [1, 1]\n",
      "tensor(539.5302, device='cuda:0') [0, 1]\n",
      "tensor(540.3831, device='cuda:0') [0, 1]\n",
      "tensor(540.5450, device='cuda:0') [0, 1]\n",
      "tensor(541.0670, device='cuda:0') [0, 1]\n",
      "tensor(541.5496, device='cuda:0') [0, 1]\n",
      "tensor(542.9001, device='cuda:0') [0, 1]\n",
      "tensor(543.3987, device='cuda:0') [0, 1]\n",
      "tensor(544.0587, device='cuda:0') [1, 1]\n",
      "tensor(544.4130, device='cuda:0') [1, 1]\n",
      "tensor(545.5870, device='cuda:0') [0, 1]\n",
      "tensor(546.0358, device='cuda:0') [0, 1]\n",
      "tensor(547.3420, device='cuda:0') [1, 1]\n",
      "tensor(547.3420, device='cuda:0') [0, 1]\n",
      "tensor(547.7740, device='cuda:0') [0, 1]\n",
      "tensor(549.1880, device='cuda:0') [1, 1]\n",
      "tensor(551.3000, device='cuda:0') [0, 1]\n",
      "tensor(552.0600, device='cuda:0') [0, 1]\n",
      "tensor(552.0600, device='cuda:0') [0, 1]\n",
      "tensor(552.4200, device='cuda:0') [0, 1]\n",
      "tensor(552.4200, device='cuda:0') [0, 1]\n",
      "tensor(554.1188, device='cuda:0') [0, 1]\n",
      "tensor(555.6749, device='cuda:0') [1, 1]\n",
      "tensor(556.0349, device='cuda:0') [0, 1]\n",
      "tensor(556.7048, device='cuda:0') [0, 1]\n",
      "tensor(557.7673, device='cuda:0') [1, 1]\n",
      "tensor(558.2047, device='cuda:0') [0, 1]\n",
      "tensor(559.2883, device='cuda:0') [0, 1]\n",
      "tensor(559.8282, device='cuda:0') [0, 1]\n",
      "tensor(560.4583, device='cuda:0') [0, 1]\n",
      "tensor(561.0182, device='cuda:0') [0, 1]\n",
      "tensor(562.1882, device='cuda:0') [0, 1]\n",
      "tensor(563.5182, device='cuda:0') [0, 1]\n",
      "tensor(564.3182, device='cuda:0') [1, 1]\n",
      "tensor(565.4982, device='cuda:0') [0, 1]\n",
      "tensor(566.8682, device='cuda:0') [1, 1]\n",
      "tensor(567.8682, device='cuda:0') [0, 1]\n",
      "tensor(567.8682, device='cuda:0') [0, 0]\n",
      "tensor(568.8082, device='cuda:0') [1, 1]\n",
      "tensor(568.8082, device='cuda:0') [0, 1]\n",
      "tensor(569.0782, device='cuda:0') [0, 1]\n",
      "tensor(570.2482, device='cuda:0') [0, 1]\n",
      "tensor(571.5443, device='cuda:0') [0, 1]\n",
      "tensor(572.6143, device='cuda:0') [1, 1]\n",
      "tensor(572.9382, device='cuda:0') [0, 1]\n",
      "tensor(574.1613, device='cuda:0') [1, 1]\n",
      "tensor(574.4313, device='cuda:0') [0, 1]\n",
      "tensor(575.4303, device='cuda:0') [0, 1]\n",
      "tensor(578.5003, device='cuda:0') [0, 1]\n",
      "tensor(578.6803, device='cuda:0') [0, 1]\n",
      "tensor(578.8603, device='cuda:0') [1, 1]\n",
      "tensor(579.6163, device='cuda:0') [0, 1]\n",
      "tensor(580.0483, device='cuda:0') [1, 1]\n",
      "tensor(580.7682, device='cuda:0') [0, 1]\n",
      "tensor(581.0922, device='cuda:0') [0, 1]\n",
      "tensor(581.8586, device='cuda:0') [0, 1]\n",
      "tensor(581.8586, device='cuda:0') [0, 1]\n",
      "tensor(583.1088, device='cuda:0') [0, 1]\n",
      "tensor(584.6505, device='cuda:0') [0, 1]\n",
      "tensor(585.3345, device='cuda:0') [0, 1]\n",
      "tensor(585.6945, device='cuda:0') [0, 1]\n",
      "tensor(586.3544, device='cuda:0') [1, 1]\n",
      "tensor(587.4479, device='cuda:0') [1, 1]\n",
      "tensor(589.1993, device='cuda:0') [0, 1]\n",
      "tensor(589.5593, device='cuda:0') [0, 1]\n",
      "tensor(589.5593, device='cuda:0') [0, 1]\n",
      "tensor(589.8023, device='cuda:0') [0, 1]\n",
      "tensor(590.6280, device='cuda:0') [0, 1]\n",
      "tensor(591.9357, device='cuda:0') [1, 1]\n",
      "tensor(593.6547, device='cuda:0') [0, 1]\n",
      "tensor(594.0146, device='cuda:0') [0, 1]\n",
      "tensor(594.0146, device='cuda:0') [0, 1]\n",
      "tensor(595.8472, device='cuda:0') [0, 1]\n",
      "tensor(596.4988, device='cuda:0') [0, 1]\n",
      "tensor(596.6788, device='cuda:0') [0, 1]\n",
      "tensor(597.8387, device='cuda:0') [1, 1]\n",
      "tensor(598.0187, device='cuda:0') [0, 1]\n",
      "tensor(598.6076, device='cuda:0') [1, 1]\n",
      "tensor(599.5710, device='cuda:0') [0, 1]\n",
      "tensor(600.4029, device='cuda:0') [0, 1]\n",
      "tensor(600.6729, device='cuda:0') [0, 1]\n",
      "tensor(600.6729, device='cuda:0') [0, 1]\n",
      "tensor(601.4858, device='cuda:0') [1, 1]\n",
      "tensor(602.5082, device='cuda:0') [0, 1]\n",
      "tensor(603.4922, device='cuda:0') [0, 1]\n",
      "tensor(604.5048, device='cuda:0') [1, 1]\n",
      "tensor(604.8237, device='cuda:0') [0, 1]\n",
      "tensor(605.0667, device='cuda:0') [0, 1]\n",
      "tensor(606.2738, device='cuda:0') [0, 1]\n",
      "tensor(607.0443, device='cuda:0') [1, 1]\n",
      "tensor(607.7643, device='cuda:0') [0, 1]\n",
      "tensor(608.0073, device='cuda:0') [0, 1]\n",
      "tensor(609.2969, device='cuda:0') [0, 1]\n",
      "tensor(609.5331, device='cuda:0') [0, 1]\n",
      "tensor(610.2185, device='cuda:0') [1, 1]\n",
      "tensor(610.9385, device='cuda:0') [0, 1]\n",
      "tensor(612.0330, device='cuda:0') [0, 1]\n",
      "tensor(612.8934, device='cuda:0') [0, 1]\n",
      "tensor(613.6077, device='cuda:0') [0, 1]\n",
      "tensor(614.0014, device='cuda:0') [0, 1]\n",
      "tensor(614.7234, device='cuda:0') [0, 1]\n",
      "tensor(614.7234, device='cuda:0') [1, 1]\n",
      "tensor(616.5443, device='cuda:0') [1, 1]\n",
      "tensor(616.5443, device='cuda:0') [0, 1]\n",
      "tensor(617.2656, device='cuda:0') [0, 1]\n",
      "tensor(618.0509, device='cuda:0') [0, 1]\n",
      "tensor(618.2422, device='cuda:0') [0, 1]\n",
      "tensor(618.8826, device='cuda:0') [0, 1]\n",
      "tensor(619.6227, device='cuda:0') [1, 1]\n",
      "tensor(620.9670, device='cuda:0') [0, 1]\n",
      "tensor(621.6813, device='cuda:0') [0, 1]\n",
      "tensor(621.6813, device='cuda:0') [0, 1]\n",
      "tensor(622.8969, device='cuda:0') [0, 1]\n",
      "tensor(622.8969, device='cuda:0') [0, 1]\n",
      "tensor(623.2682, device='cuda:0') [1, 1]\n",
      "tensor(624.3071, device='cuda:0') [0, 1]\n",
      "tensor(625.7033, device='cuda:0') [0, 1]\n",
      "tensor(626.2938, device='cuda:0') [1, 1]\n",
      "tensor(627.3681, device='cuda:0') [0, 1]\n",
      "tensor(628.1911, device='cuda:0') [0, 1]\n",
      "tensor(628.1911, device='cuda:0') [0, 1]\n",
      "tensor(628.7637, device='cuda:0') [0, 1]\n",
      "tensor(630.0986, device='cuda:0') [0, 1]\n",
      "tensor(630.4586, device='cuda:0') [0, 1]\n",
      "tensor(630.6948, device='cuda:0') [1, 1]\n",
      "tensor(632.0121, device='cuda:0') [0, 1]\n",
      "tensor(632.2551, device='cuda:0') [0, 1]\n",
      "tensor(632.7360, device='cuda:0') [0, 1]\n",
      "tensor(634.2247, device='cuda:0') [1, 1]\n",
      "tensor(635.1247, device='cuda:0') [0, 1]\n",
      "tensor(635.1247, device='cuda:0') [0, 1]\n",
      "tensor(635.9402, device='cuda:0') [0, 1]\n",
      "tensor(636.8317, device='cuda:0') [0, 1]\n",
      "tensor(637.3631, device='cuda:0') [0, 1]\n",
      "tensor(637.9604, device='cuda:0') [0, 1]\n",
      "tensor(639.1539, device='cuda:0') [0, 1]\n",
      "tensor(639.4239, device='cuda:0') [0, 1]\n",
      "tensor(639.7839, device='cuda:0') [1, 1]\n",
      "tensor(640.3029, device='cuda:0') [0, 1]\n",
      "tensor(641.4449, device='cuda:0') [1, 1]\n",
      "tensor(641.6171, device='cuda:0') [0, 1]\n",
      "tensor(642.5211, device='cuda:0') [0, 1]\n",
      "tensor(642.5211, device='cuda:0') [0, 0]\n",
      "tensor(643.0735, device='cuda:0') [1, 1]\n",
      "tensor(643.7567, device='cuda:0') [0, 1]\n",
      "tensor(645.0972, device='cuda:0') [1, 1]\n",
      "tensor(645.0972, device='cuda:0') [0, 1]\n",
      "tensor(645.6013, device='cuda:0') [0, 1]\n",
      "tensor(646.4485, device='cuda:0') [0, 1]\n",
      "tensor(647.5528, device='cuda:0') [1, 1]\n",
      "tensor(648.0852, device='cuda:0') [0, 1]\n",
      "tensor(648.6752, device='cuda:0') [1, 1]\n",
      "tensor(649.2995, device='cuda:0') [0, 1]\n",
      "tensor(649.5695, device='cuda:0') [0, 1]\n",
      "tensor(650.0521, device='cuda:0') [1, 1]\n",
      "tensor(651.9919, device='cuda:0') [1, 1]\n",
      "tensor(652.1719, device='cuda:0') [1, 1]\n",
      "tensor(653.0720, device='cuda:0') [0, 1]\n",
      "tensor(653.4319, device='cuda:0') [0, 0]\n",
      "tensor(654.4719, device='cuda:0') [0, 1]\n",
      "tensor(654.4719, device='cuda:0') [0, 1]\n",
      "tensor(655.0319, device='cuda:0') [0, 1]\n",
      "tensor(656.8579, device='cuda:0') [1, 1]\n",
      "tensor(657.7279, device='cuda:0') [0, 1]\n",
      "tensor(657.7279, device='cuda:0') [0, 1]\n",
      "tensor(658.6009, device='cuda:0') [0, 1]\n",
      "tensor(658.9609, device='cuda:0') [0, 1]\n",
      "tensor(659.3209, device='cuda:0') [0, 1]\n",
      "tensor(662.5198, device='cuda:0') [0, 1]\n",
      "tensor(663.8198, device='cuda:0') [0, 1]\n",
      "tensor(664.0898, device='cuda:0') [1, 1]\n",
      "tensor(664.3779, device='cuda:0') [1, 1]\n",
      "tensor(665.2328, device='cuda:0') [0, 1]\n",
      "tensor(665.7728, device='cuda:0') [0, 1]\n",
      "tensor(665.9528, device='cuda:0') [1, 1]\n",
      "tensor(667.4328, device='cuda:0') [0, 1]\n",
      "tensor(667.7328, device='cuda:0') [0, 1]\n",
      "tensor(668.1265, device='cuda:0') [0, 1]\n",
      "tensor(669.4279, device='cuda:0') [0, 1]\n",
      "tensor(670.7778, device='cuda:0') [1, 1]\n",
      "tensor(671.5778, device='cuda:0') [1, 1]\n",
      "tensor(671.5778, device='cuda:0') [0, 1]\n",
      "tensor(671.7398, device='cuda:0') [0, 0]\n",
      "tensor(673.0838, device='cuda:0') [0, 1]\n",
      "tensor(673.7838, device='cuda:0') [0, 1]\n",
      "tensor(674.5838, device='cuda:0') [1, 1]\n",
      "tensor(674.8538, device='cuda:0') [0, 1]\n",
      "tensor(676.5738, device='cuda:0') [0, 1]\n",
      "tensor(676.5738, device='cuda:0') [0, 0]\n",
      "tensor(677.0138, device='cuda:0') [0, 1]\n",
      "tensor(677.3338, device='cuda:0') [1, 1]\n",
      "tensor(678.3278, device='cuda:0') [0, 1]\n",
      "tensor(679.2878, device='cuda:0') [0, 1]\n",
      "tensor(680.2878, device='cuda:0') [0, 1]\n",
      "tensor(681.1779, device='cuda:0') [1, 1]\n",
      "tensor(681.8578, device='cuda:0') [1, 1]\n",
      "tensor(682.4578, device='cuda:0') [0, 1]\n",
      "tensor(683.9278, device='cuda:0') [0, 1]\n",
      "tensor(685.1278, device='cuda:0') [1, 1]\n",
      "tensor(686.5278, device='cuda:0') [0, 1]\n",
      "tensor(687.1278, device='cuda:0') [0, 1]\n",
      "tensor(687.9278, device='cuda:0') [1, 1]\n",
      "tensor(688.9078, device='cuda:0') [0, 1]\n",
      "tensor(690.2078, device='cuda:0') [0, 1]\n",
      "tensor(691.6078, device='cuda:0') [0, 1]\n",
      "tensor(691.6078, device='cuda:0') [0, 1]\n",
      "tensor(693.1678, device='cuda:0') [0, 1]\n",
      "tensor(694.0678, device='cuda:0') [1, 1]\n",
      "tensor(694.9678, device='cuda:0') [1, 1]\n",
      "tensor(696.2878, device='cuda:0') [0, 1]\n",
      "tensor(696.8909, device='cuda:0') [0, 1]\n",
      "tensor(697.1609, device='cuda:0') [0, 1]\n",
      "tensor(697.1609, device='cuda:0') [0, 1]\n",
      "tensor(698.1329, device='cuda:0') [0, 1]\n",
      "tensor(699.3658, device='cuda:0') [0, 1]\n",
      "tensor(699.6575, device='cuda:0') [0, 1]\n",
      "tensor(700.9805, device='cuda:0') [0, 1]\n",
      "tensor(701.2721, device='cuda:0') [1, 1]\n",
      "tensor(701.8661, device='cuda:0') [0, 1]\n",
      "tensor(702.8642, device='cuda:0') [0, 1]\n",
      "tensor(703.5442, device='cuda:0') [1, 1]\n",
      "tensor(704.3685, device='cuda:0') [0, 1]\n",
      "tensor(704.3685, device='cuda:0') [1, 1]\n",
      "tensor(705.0367, device='cuda:0') [0, 1]\n",
      "tensor(707.3212, device='cuda:0') [1, 1]\n",
      "tensor(707.3212, device='cuda:0') [0, 1]\n",
      "tensor(707.6755, device='cuda:0') [0, 1]\n",
      "tensor(709.0179, device='cuda:0') [0, 1]\n",
      "tensor(709.3779, device='cuda:0') [1, 1]\n",
      "tensor(710.5353, device='cuda:0') [0, 1]\n",
      "tensor(710.7783, device='cuda:0') [0, 1]\n",
      "tensor(711.3340, device='cuda:0') [0, 1]\n",
      "tensor(711.9496, device='cuda:0') [0, 1]\n",
      "tensor(712.6732, device='cuda:0') [0, 1]\n",
      "tensor(713.6722, device='cuda:0') [0, 1]\n",
      "tensor(714.2896, device='cuda:0') [1, 1]\n",
      "tensor(715.3389, device='cuda:0') [0, 1]\n",
      "tensor(716.7063, device='cuda:0') [0, 1]\n",
      "tensor(717.1063, device='cuda:0') [0, 1]\n",
      "tensor(717.4263, device='cuda:0') [1, 1]\n",
      "tensor(717.8963, device='cuda:0') [0, 1]\n",
      "tensor(718.4503, device='cuda:0') [1, 1]\n",
      "tensor(719.7663, device='cuda:0') [0, 1]\n",
      "tensor(721.2263, device='cuda:0') [1, 1]\n",
      "tensor(722.4263, device='cuda:0') [0, 1]\n",
      "tensor(722.4263, device='cuda:0') [0, 0]\n",
      "tensor(723.4663, device='cuda:0') [1, 1]\n",
      "tensor(724.1663, device='cuda:0') [0, 1]\n",
      "tensor(724.7663, device='cuda:0') [0, 1]\n",
      "tensor(724.7663, device='cuda:0') [1, 1]\n",
      "tensor(727.2463, device='cuda:0') [0, 1]\n",
      "tensor(728.0463, device='cuda:0') [0, 1]\n",
      "tensor(728.0463, device='cuda:0') [0, 0]\n",
      "tensor(728.7662, device='cuda:0') [1, 1]\n",
      "tensor(729.8463, device='cuda:0') [0, 1]\n",
      "tensor(731.0463, device='cuda:0') [0, 1]\n",
      "tensor(731.9463, device='cuda:0') [0, 1]\n",
      "tensor(733.0463, device='cuda:0') [1, 1]\n",
      "tensor(733.4463, device='cuda:0') [0, 1]\n",
      "tensor(734.5163, device='cuda:0') [1, 1]\n",
      "tensor(735.3863, device='cuda:0') [0, 1]\n",
      "tensor(735.3863, device='cuda:0') [0, 0]\n",
      "tensor(736.8063, device='cuda:0') [1, 1]\n",
      "tensor(737.7063, device='cuda:0') [0, 1]\n",
      "tensor(738.3063, device='cuda:0') [0, 1]\n",
      "tensor(739.6663, device='cuda:0') [0, 1]\n",
      "tensor(740.3362, device='cuda:0') [0, 1]\n",
      "tensor(741.6962, device='cuda:0') [0, 1]\n",
      "tensor(741.6962, device='cuda:0') [1, 1]\n",
      "tensor(743.9292, device='cuda:0') [0, 1]\n",
      "tensor(743.9292, device='cuda:0') [0, 0]\n",
      "tensor(744.3322, device='cuda:0') [1, 1]\n",
      "tensor(745.3342, device='cuda:0') [0, 1]\n",
      "tensor(746.2343, device='cuda:0') [0, 1]\n",
      "tensor(746.4142, device='cuda:0') [1, 1]\n",
      "tensor(747.8002, device='cuda:0') [0, 1]\n",
      "tensor(748.0703, device='cuda:0') [0, 1]\n",
      "tensor(748.7363, device='cuda:0') [0, 1]\n",
      "tensor(749.0063, device='cuda:0') [0, 1]\n",
      "tensor(750.8137, device='cuda:0') [1, 1]\n",
      "tensor(751.2510, device='cuda:0') [0, 1]\n",
      "tensor(751.8126, device='cuda:0') [0, 1]\n",
      "tensor(752.5726, device='cuda:0') [0, 1]\n",
      "tensor(753.7877, device='cuda:0') [0, 1]\n",
      "tensor(753.9677, device='cuda:0') [0, 1]\n",
      "tensor(754.9990, device='cuda:0') [1, 1]\n",
      "tensor(756.8970, device='cuda:0') [1, 1]\n",
      "tensor(756.8970, device='cuda:0') [0, 1]\n",
      "tensor(757.5001, device='cuda:0') [0, 1]\n",
      "tensor(759.5701, device='cuda:0') [0, 1]\n",
      "tensor(759.5701, device='cuda:0') [0, 1]\n",
      "tensor(760.2181, device='cuda:0') [0, 1]\n",
      "tensor(760.9741, device='cuda:0') [0, 1]\n",
      "tensor(762.0541, device='cuda:0') [1, 1]\n",
      "tensor(762.7740, device='cuda:0') [0, 1]\n",
      "tensor(763.5535, device='cuda:0') [1, 1]\n",
      "tensor(765.0295, device='cuda:0') [0, 1]\n",
      "tensor(765.4995, device='cuda:0') [0, 1]\n",
      "tensor(765.4995, device='cuda:0') [0, 1]\n",
      "tensor(766.9208, device='cuda:0') [0, 1]\n",
      "tensor(767.1208, device='cuda:0') [0, 1]\n",
      "tensor(767.8499, device='cuda:0') [1, 1]\n",
      "tensor(769.5688, device='cuda:0') [0, 1]\n",
      "tensor(770.5804, device='cuda:0') [0, 1]\n",
      "tensor(770.9404, device='cuda:0') [0, 1]\n",
      "tensor(772.8204, device='cuda:0') [1, 1]\n",
      "tensor(773.0004, device='cuda:0') [0, 1]\n",
      "tensor(773.2921, device='cuda:0') [0, 1]\n",
      "tensor(774.0950, device='cuda:0') [0, 1]\n",
      "tensor(774.8240, device='cuda:0') [1, 1]\n",
      "tensor(775.5440, device='cuda:0') [0, 1]\n",
      "tensor(777.2531, device='cuda:0') [0, 1]\n",
      "tensor(778.1711, device='cuda:0') [0, 1]\n",
      "tensor(778.1711, device='cuda:0') [0, 1]\n",
      "tensor(778.1711, device='cuda:0') [0, 1]\n",
      "tensor(779.3151, device='cuda:0') [0, 1]\n",
      "tensor(779.8887, device='cuda:0') [1, 1]\n",
      "tensor(780.8367, device='cuda:0') [1, 1]\n",
      "tensor(781.1068, device='cuda:0') [0, 1]\n",
      "tensor(781.6056, device='cuda:0') [1, 1]\n",
      "tensor(782.3256, device='cuda:0') [0, 1]\n",
      "tensor(784.1471, device='cuda:0') [1, 1]\n",
      "tensor(784.5408, device='cuda:0') [0, 1]\n",
      "tensor(784.8828, device='cuda:0') [0, 1]\n",
      "tensor(784.8828, device='cuda:0') [0, 1]\n",
      "tensor(787.1379, device='cuda:0') [0, 1]\n",
      "tensor(787.1379, device='cuda:0') [0, 1]\n",
      "tensor(788.1370, device='cuda:0') [0, 1]\n",
      "tensor(788.7543, device='cuda:0') [1, 1]\n",
      "tensor(789.6237, device='cuda:0') [0, 1]\n",
      "tensor(790.9457, device='cuda:0') [1, 1]\n",
      "tensor(791.3882, device='cuda:0') [0, 1]\n",
      "tensor(791.7482, device='cuda:0') [1, 1]\n",
      "tensor(792.4681, device='cuda:0') [0, 1]\n",
      "tensor(792.8663, device='cuda:0') [0, 1]\n",
      "tensor(795.3944, device='cuda:0') [0, 1]\n",
      "tensor(795.8264, device='cuda:0') [0, 1]\n",
      "tensor(796.3304, device='cuda:0') [0, 1]\n",
      "tensor(797.1765, device='cuda:0') [0, 1]\n",
      "tensor(797.9265, device='cuda:0') [1, 1]\n",
      "tensor(798.1965, device='cuda:0') [0, 1]\n",
      "tensor(798.5901, device='cuda:0') [0, 1]\n",
      "tensor(799.1841, device='cuda:0') [0, 1]\n",
      "tensor(799.9341, device='cuda:0') [1, 1]\n",
      "tensor(800.1467, device='cuda:0') [0, 1]\n",
      "tensor(801.5428, device='cuda:0') [0, 1]\n",
      "tensor(802.2928, device='cuda:0') [1, 1]\n",
      "tensor(803.8002, device='cuda:0') [1, 1]\n",
      "tensor(804.0919, device='cuda:0') [0, 1]\n",
      "tensor(805.0549, device='cuda:0') [0, 1]\n",
      "tensor(805.4149, device='cuda:0') [0, 1]\n",
      "tensor(806.7648, device='cuda:0') [0, 1]\n",
      "tensor(808.0968, device='cuda:0') [0, 1]\n",
      "tensor(809.2168, device='cuda:0') [0, 1]\n",
      "tensor(809.7168, device='cuda:0') [1, 1]\n",
      "tensor(809.8968, device='cuda:0') [0, 1]\n",
      "tensor(810.0768, device='cuda:0') [1, 1]\n",
      "tensor(812.2588, device='cuda:0') [0, 1]\n",
      "tensor(812.7788, device='cuda:0') [1, 1]\n",
      "tensor(813.3788, device='cuda:0') [0, 1]\n",
      "tensor(814.6488, device='cuda:0') [1, 1]\n",
      "tensor(815.5488, device='cuda:0') [0, 1]\n",
      "tensor(816.5488, device='cuda:0') [0, 1]\n",
      "tensor(817.5488, device='cuda:0') [1, 1]\n",
      "tensor(818.2488, device='cuda:0') [0, 1]\n",
      "tensor(819.1489, device='cuda:0') [0, 1]\n",
      "tensor(819.5489, device='cuda:0') [0, 1]\n",
      "tensor(820.8889, device='cuda:0') [0, 1]\n",
      "tensor(821.5889, device='cuda:0') [0, 1]\n",
      "tensor(822.1889, device='cuda:0') [0, 1]\n",
      "tensor(822.9389, device='cuda:0') [1, 1]\n",
      "tensor(823.2989, device='cuda:0') [0, 0]\n",
      "tensor(824.3389, device='cuda:0') [1, 1]\n",
      "tensor(825.2989, device='cuda:0') [0, 1]\n",
      "tensor(825.2989, device='cuda:0') [0, 0]\n",
      "tensor(826.2589, device='cuda:0') [0, 1]\n",
      "tensor(826.6589, device='cuda:0') [0, 1]\n",
      "tensor(828.5590, device='cuda:0') [1, 1]\n",
      "tensor(828.5590, device='cuda:0') [0, 0]\n",
      "tensor(829.7990, device='cuda:0') [1, 1]\n",
      "tensor(830.6990, device='cuda:0') [0, 1]\n",
      "tensor(831.9990, device='cuda:0') [0, 1]\n",
      "tensor(832.8990, device='cuda:0') [0, 1]\n",
      "tensor(833.5990, device='cuda:0') [0, 1]\n",
      "tensor(833.7990, device='cuda:0') [0, 1]\n",
      "tensor(834.1190, device='cuda:0') [1, 1]\n",
      "tensor(835.0130, device='cuda:0') [0, 1]\n",
      "tensor(835.8530, device='cuda:0') [1, 1]\n",
      "tensor(835.8530, device='cuda:0') [0, 0]\n",
      "tensor(836.9561, device='cuda:0') [1, 1]\n",
      "tensor(837.7560, device='cuda:0') [0, 1]\n",
      "tensor(838.3560, device='cuda:0') [0, 1]\n",
      "tensor(839.7160, device='cuda:0') [0, 1]\n",
      "tensor(840.3960, device='cuda:0') [1, 1]\n",
      "tensor(841.1960, device='cuda:0') [0, 1]\n",
      "tensor(842.3960, device='cuda:0') [0, 1]\n",
      "tensor(843.2760, device='cuda:0') [1, 1]\n",
      "tensor(844.6760, device='cuda:0') [0, 1]\n",
      "tensor(845.4760, device='cuda:0') [0, 1]\n",
      "tensor(846.2760, device='cuda:0') [0, 1]\n",
      "tensor(847.2760, device='cuda:0') [0, 1]\n",
      "tensor(847.7560, device='cuda:0') [1, 1]\n",
      "tensor(848.8160, device='cuda:0') [0, 1]\n",
      "tensor(849.7160, device='cuda:0') [0, 1]\n",
      "tensor(850.0160, device='cuda:0') [0, 1]\n",
      "tensor(850.6960, device='cuda:0') [1, 1]\n",
      "tensor(851.6760, device='cuda:0') [1, 1]\n",
      "tensor(851.9460, device='cuda:0') [0, 0]\n",
      "tensor(853.1460, device='cuda:0') [1, 1]\n",
      "tensor(854.0460, device='cuda:0') [0, 1]\n",
      "tensor(855.3460, device='cuda:0') [0, 1]\n",
      "tensor(856.3460, device='cuda:0') [0, 1]\n",
      "tensor(857.2160, device='cuda:0') [0, 1]\n",
      "tensor(858.0160, device='cuda:0') [1, 1]\n",
      "tensor(858.7660, device='cuda:0') [1, 1]\n",
      "tensor(859.1260, device='cuda:0') [0, 0]\n",
      "tensor(859.5660, device='cuda:0') [0, 1]\n",
      "tensor(860.9060, device='cuda:0') [1, 1]\n",
      "tensor(861.0860, device='cuda:0') [0, 1]\n",
      "tensor(861.8960, device='cuda:0') [0, 1]\n",
      "tensor(863.4560, device='cuda:0') [0, 1]\n",
      "tensor(863.8160, device='cuda:0') [0, 1]\n",
      "tensor(863.9960, device='cuda:0') [1, 1]\n",
      "tensor(865.3100, device='cuda:0') [0, 1]\n",
      "tensor(865.9700, device='cuda:0') [0, 1]\n",
      "tensor(867.5959, device='cuda:0') [0, 1]\n",
      "tensor(867.7759, device='cuda:0') [1, 1]\n",
      "tensor(869.7659, device='cuda:0') [0, 1]\n",
      "tensor(870.3259, device='cuda:0') [0, 1]\n",
      "tensor(870.3259, device='cuda:0') [0, 1]\n",
      "tensor(871.2919, device='cuda:0') [0, 1]\n",
      "tensor(873.6779, device='cuda:0') [0, 1]\n",
      "tensor(874.7479, device='cuda:0') [1, 1]\n",
      "tensor(875.2279, device='cuda:0') [0, 1]\n",
      "tensor(875.2279, device='cuda:0') [0, 1]\n",
      "tensor(875.8079, device='cuda:0') [0, 1]\n",
      "tensor(876.8569, device='cuda:0') [1, 1]\n",
      "tensor(878.3784, device='cuda:0') [0, 1]\n",
      "tensor(878.3784, device='cuda:0') [1, 1]\n",
      "tensor(879.0983, device='cuda:0') [0, 1]\n",
      "tensor(879.3413, device='cuda:0') [0, 1]\n",
      "tensor(881.6880, device='cuda:0') [0, 1]\n",
      "tensor(881.9580, device='cuda:0') [1, 1]\n",
      "tensor(883.0020, device='cuda:0') [0, 1]\n",
      "tensor(883.3260, device='cuda:0') [0, 1]\n",
      "tensor(883.8480, device='cuda:0') [0, 1]\n",
      "tensor(884.5770, device='cuda:0') [0, 1]\n",
      "tensor(886.4004, device='cuda:0') [0, 1]\n",
      "tensor(886.5624, device='cuda:0') [1, 1]\n",
      "tensor(887.6244, device='cuda:0') [0, 1]\n",
      "tensor(887.8944, device='cuda:0') [1, 1]\n",
      "tensor(889.6921, device='cuda:0') [0, 1]\n",
      "tensor(889.6921, device='cuda:0') [0, 1]\n",
      "tensor(891.0151, device='cuda:0') [0, 1]\n",
      "tensor(891.0151, device='cuda:0') [0, 1]\n",
      "tensor(891.6955, device='cuda:0') [0, 1]\n",
      "tensor(892.7269, device='cuda:0') [0, 1]\n",
      "tensor(893.4883, device='cuda:0') [0, 1]\n",
      "tensor(893.6503, device='cuda:0') [0, 1]\n",
      "tensor(894.2533, device='cuda:0') [0, 1]\n",
      "tensor(894.9133, device='cuda:0') [0, 1]\n",
      "tensor(895.8919, device='cuda:0') [1, 1]\n",
      "tensor(896.4656, device='cuda:0') [1, 1]\n",
      "tensor(898.0996, device='cuda:0') [0, 1]\n",
      "tensor(898.6696, device='cuda:0') [0, 1]\n",
      "tensor(900.0196, device='cuda:0') [1, 1]\n",
      "tensor(900.0196, device='cuda:0') [0, 1]\n",
      "tensor(902.3406, device='cuda:0') [0, 1]\n",
      "tensor(902.7406, device='cuda:0') [0, 1]\n",
      "tensor(903.0106, device='cuda:0') [0, 1]\n",
      "tensor(903.6806, device='cuda:0') [0, 1]\n",
      "tensor(905.3906, device='cuda:0') [0, 1]\n",
      "tensor(906.2906, device='cuda:0') [0, 1]\n",
      "tensor(907.6907, device='cuda:0') [1, 1]\n",
      "tensor(907.9607, device='cuda:0') [1, 1]\n",
      "tensor(909.0807, device='cuda:0') [0, 1]\n",
      "tensor(909.3237, device='cuda:0') [0, 1]\n",
      "tensor(910.3267, device='cuda:0') [0, 1]\n",
      "tensor(911.1367, device='cuda:0') [0, 1]\n",
      "tensor(912.1266, device='cuda:0') [1, 1]\n",
      "tensor(912.8466, device='cuda:0') [0, 1]\n",
      "tensor(915.0176, device='cuda:0') [0, 1]\n",
      "tensor(915.0176, device='cuda:0') [1, 1]\n",
      "tensor(916.3156, device='cuda:0') [0, 1]\n",
      "tensor(916.3156, device='cuda:0') [1, 1]\n",
      "tensor(917.5956, device='cuda:0') [0, 1]\n",
      "tensor(917.5956, device='cuda:0') [0, 1]\n",
      "tensor(917.8657, device='cuda:0') [0, 1]\n",
      "tensor(918.1019, device='cuda:0') [0, 1]\n",
      "tensor(919.3091, device='cuda:0') [0, 1]\n",
      "tensor(919.8691, device='cuda:0') [0, 1]\n",
      "tensor(921.0168, device='cuda:0') [0, 1]\n",
      "tensor(922.2258, device='cuda:0') [1, 1]\n",
      "tensor(923.5874, device='cuda:0') [1, 1]\n",
      "tensor(923.9474, device='cuda:0') [0, 1]\n",
      "tensor(925.4698, device='cuda:0') [0, 1]\n",
      "tensor(925.7399, device='cuda:0') [1, 1]\n",
      "tensor(926.0638, device='cuda:0') [0, 1]\n",
      "tensor(926.8738, device='cuda:0') [0, 1]\n",
      "tensor(927.8729, device='cuda:0') [0, 1]\n",
      "tensor(928.2328, device='cuda:0') [0, 1]\n",
      "tensor(929.0104, device='cuda:0') [0, 1]\n",
      "tensor(930.0095, device='cuda:0') [0, 1]\n",
      "tensor(930.1895, device='cuda:0') [1, 1]\n",
      "tensor(930.9094, device='cuda:0') [0, 1]\n",
      "tensor(934.0611, device='cuda:0') [1, 1]\n",
      "tensor(934.0611, device='cuda:0') [0, 1]\n",
      "tensor(935.1231, device='cuda:0') [0, 1]\n",
      "tensor(935.8251, device='cuda:0') [0, 1]\n",
      "tensor(936.7881, device='cuda:0') [0, 1]\n",
      "tensor(937.1481, device='cuda:0') [0, 1]\n",
      "tensor(937.4182, device='cuda:0') [0, 1]\n",
      "tensor(937.5981, device='cuda:0') [0, 1]\n",
      "tensor(937.5981, device='cuda:0') [1, 1]\n",
      "tensor(939.5253, device='cuda:0') [1, 1]\n",
      "tensor(940.9807, device='cuda:0') [0, 1]\n",
      "tensor(940.9807, device='cuda:0') [0, 1]\n",
      "tensor(941.7097, device='cuda:0') [0, 1]\n",
      "tensor(943.7517, device='cuda:0') [1, 1]\n",
      "tensor(943.7517, device='cuda:0') [0, 1]\n",
      "tensor(944.2647, device='cuda:0') [0, 1]\n",
      "tensor(945.7024, device='cuda:0') [0, 1]\n",
      "tensor(945.7024, device='cuda:0') [1, 1]\n",
      "tensor(947.3404, device='cuda:0') [0, 1]\n",
      "tensor(947.5204, device='cuda:0') [0, 1]\n",
      "tensor(948.1864, device='cuda:0') [0, 1]\n",
      "tensor(949.2564, device='cuda:0') [1, 1]\n",
      "tensor(950.1978, device='cuda:0') [0, 1]\n",
      "tensor(950.9178, device='cuda:0') [0, 1]\n",
      "tensor(952.4378, device='cuda:0') [1, 1]\n",
      "tensor(952.6178, device='cuda:0') [0, 1]\n",
      "tensor(953.9178, device='cuda:0') [0, 1]\n",
      "tensor(954.2778, device='cuda:0') [0, 1]\n",
      "tensor(955.0878, device='cuda:0') [0, 1]\n",
      "tensor(955.4478, device='cuda:0') [0, 1]\n",
      "tensor(956.9697, device='cuda:0') [0, 1]\n",
      "tensor(958.3637, device='cuda:0') [1, 1]\n",
      "tensor(959.5437, device='cuda:0') [0, 1]\n",
      "tensor(960.5437, device='cuda:0') [0, 1]\n",
      "tensor(962.4467, device='cuda:0') [0, 1]\n",
      "tensor(963.2467, device='cuda:0') [0, 1]\n",
      "tensor(963.2467, device='cuda:0') [0, 1]\n",
      "tensor(963.9967, device='cuda:0') [1, 1]\n",
      "tensor(964.2667, device='cuda:0') [0, 1]\n",
      "tensor(964.8841, device='cuda:0') [0, 1]\n",
      "tensor(965.5681, device='cuda:0') [1, 1]\n",
      "tensor(966.7581, device='cuda:0') [0, 1]\n",
      "tensor(967.0497, device='cuda:0') [0, 1]\n",
      "tensor(968.9297, device='cuda:0') [1, 1]\n",
      "tensor(970.3237, device='cuda:0') [0, 1]\n",
      "tensor(970.9237, device='cuda:0') [0, 1]\n",
      "tensor(972.3037, device='cuda:0') [0, 1]\n",
      "tensor(972.7837, device='cuda:0') [1, 1]\n",
      "tensor(974.1437, device='cuda:0') [0, 1]\n",
      "tensor(974.1437, device='cuda:0') [0, 1]\n",
      "tensor(975.0437, device='cuda:0') [0, 1]\n",
      "tensor(975.8267, device='cuda:0') [0, 1]\n",
      "tensor(976.2497, device='cuda:0') [0, 1]\n",
      "tensor(977.1637, device='cuda:0') [1, 1]\n",
      "tensor(977.9877, device='cuda:0') [1, 1]\n",
      "tensor(978.2577, device='cuda:0') [1, 1]\n",
      "tensor(979.2477, device='cuda:0') [0, 0]\n",
      "tensor(980.2877, device='cuda:0') [0, 1]\n",
      "tensor(981.1877, device='cuda:0') [0, 1]\n",
      "tensor(982.1877, device='cuda:0') [1, 1]\n",
      "tensor(983.3877, device='cuda:0') [0, 1]\n",
      "tensor(984.6877, device='cuda:0') [0, 1]\n",
      "tensor(985.6877, device='cuda:0') [1, 1]\n",
      "tensor(986.6877, device='cuda:0') [0, 1]\n",
      "tensor(988.0677, device='cuda:0') [0, 1]\n",
      "tensor(988.0677, device='cuda:0') [0, 1]\n",
      "tensor(990.3377, device='cuda:0') [1, 1]\n",
      "tensor(990.3377, device='cuda:0') [0, 1]\n",
      "tensor(990.3377, device='cuda:0') [0, 1]\n",
      "tensor(991.5607, device='cuda:0') [1, 1]\n",
      "tensor(991.9981, device='cuda:0') [0, 1]\n",
      "tensor(992.4517, device='cuda:0') [0, 1]\n",
      "tensor(992.7937, device='cuda:0') [0, 1]\n",
      "tensor(993.5011, device='cuda:0') [0, 1]\n",
      "tensor(995.0985, device='cuda:0') [1, 1]\n",
      "tensor(995.5359, device='cuda:0') [0, 1]\n",
      "tensor(997.0695, device='cuda:0') [0, 1]\n",
      "tensor(997.0695, device='cuda:0') [0, 1]\n",
      "tensor(998.3825, device='cuda:0') [1, 1]\n",
      "tensor(999.0899, device='cuda:0') [0, 1]\n",
      "tensor(999.8873, device='cuda:0') [0, 1]\n",
      "tensor(1000.7693, device='cuda:0') [0, 1]\n",
      "tensor(1001.1293, device='cuda:0') [1, 1]\n",
      "tensor(1002.0294, device='cuda:0') [0, 1]\n",
      "tensor(1002.8268, device='cuda:0') [0, 1]\n",
      "tensor(1003.9068, device='cuda:0') [0, 1]\n",
      "tensor(1005.4728, device='cuda:0') [0, 1]\n",
      "tensor(1006.3728, device='cuda:0') [1, 1]\n",
      "tensor(1007.6348, device='cuda:0') [0, 1]\n",
      "tensor(1007.6348, device='cuda:0') [0, 1]\n",
      "tensor(1008.9208, device='cuda:0') [1, 1]\n",
      "tensor(1008.9208, device='cuda:0') [0, 1]\n",
      "tensor(1009.5382, device='cuda:0') [1, 1]\n",
      "tensor(1010.1502, device='cuda:0') [0, 1]\n",
      "tensor(1010.8102, device='cuda:0') [1, 1]\n",
      "tensor(1011.5638, device='cuda:0') [0, 1]\n",
      "tensor(1012.4854, device='cuda:0') [0, 1]\n",
      "tensor(1013.0254, device='cuda:0') [0, 1]\n",
      "tensor(1013.7094, device='cuda:0') [0, 1]\n",
      "tensor(1014.6034, device='cuda:0') [0, 1]\n",
      "tensor(1016.0294, device='cuda:0') [0, 1]\n",
      "tensor(1016.3894, device='cuda:0') [1, 1]\n",
      "tensor(1017.6574, device='cuda:0') [1, 1]\n",
      "tensor(1017.9274, device='cuda:0') [0, 0]\n",
      "tensor(1018.7874, device='cuda:0') [1, 1]\n",
      "tensor(1018.7874, device='cuda:0') [0, 0]\n",
      "tensor(1020.2274, device='cuda:0') [1, 1]\n",
      "tensor(1021.5274, device='cuda:0') [0, 1]\n",
      "tensor(1022.8274, device='cuda:0') [0, 1]\n",
      "tensor(1023.2274, device='cuda:0') [0, 1]\n",
      "tensor(1023.7974, device='cuda:0') [0, 1]\n",
      "tensor(1024.2775, device='cuda:0') [1, 1]\n",
      "tensor(1024.6375, device='cuda:0') [0, 1]\n",
      "tensor(1025.9491, device='cuda:0') [0, 1]\n",
      "tensor(1025.9491, device='cuda:0') [0, 1]\n",
      "tensor(1026.2731, device='cuda:0') [1, 1]\n",
      "tensor(1027.4250, device='cuda:0') [0, 1]\n",
      "tensor(1029.9166, device='cuda:0') [0, 1]\n",
      "tensor(1030.7167, device='cuda:0') [0, 1]\n",
      "tensor(1031.5167, device='cuda:0') [1, 1]\n",
      "tensor(1032.7867, device='cuda:0') [0, 1]\n",
      "tensor(1033.9867, device='cuda:0') [0, 1]\n",
      "tensor(1033.9867, device='cuda:0') [0, 1]\n",
      "tensor(1035.4467, device='cuda:0') [0, 1]\n",
      "tensor(1036.3066, device='cuda:0') [1, 1]\n",
      "tensor(1036.5767, device='cuda:0') [0, 1]\n",
      "tensor(1037.3867, device='cuda:0') [0, 1]\n",
      "tensor(1038.0167, device='cuda:0') [1, 1]\n",
      "tensor(1039.0067, device='cuda:0') [1, 1]\n",
      "tensor(1039.4747, device='cuda:0') [0, 1]\n",
      "tensor(1040.6448, device='cuda:0') [0, 1]\n",
      "tensor(1042.9248, device='cuda:0') [0, 1]\n",
      "tensor(1043.5248, device='cuda:0') [0, 1]\n",
      "tensor(1044.4148, device='cuda:0') [1, 1]\n",
      "tensor(1045.3148, device='cuda:0') [0, 1]\n",
      "tensor(1045.3148, device='cuda:0') [1, 1]\n",
      "tensor(1045.9628, device='cuda:0') [0, 1]\n",
      "tensor(1047.0327, device='cuda:0') [1, 1]\n",
      "tensor(1048.0227, device='cuda:0') [0, 1]\n",
      "tensor(1048.0227, device='cuda:0') [0, 1]\n",
      "tensor(1050.3007, device='cuda:0') [1, 1]\n",
      "tensor(1050.3007, device='cuda:0') [0, 0]\n",
      "tensor(1051.1606, device='cuda:0') [1, 1]\n",
      "tensor(1051.5607, device='cuda:0') [0, 1]\n",
      "tensor(1052.4607, device='cuda:0') [0, 1]\n",
      "tensor(1053.6907, device='cuda:0') [0, 1]\n",
      "tensor(1054.4507, device='cuda:0') [0, 1]\n",
      "tensor(1055.2007, device='cuda:0') [1, 1]\n",
      "tensor(1055.8707, device='cuda:0') [0, 1]\n",
      "tensor(1056.4707, device='cuda:0') [0, 1]\n",
      "tensor(1058.3837, device='cuda:0') [0, 1]\n",
      "tensor(1059.1837, device='cuda:0') [1, 1]\n",
      "tensor(1059.1837, device='cuda:0') [0, 0]\n",
      "tensor(1060.5057, device='cuda:0') [1, 1]\n",
      "tensor(1061.4058, device='cuda:0') [0, 1]\n",
      "tensor(1062.0057, device='cuda:0') [0, 1]\n",
      "tensor(1063.2057, device='cuda:0') [0, 1]\n",
      "tensor(1064.3057, device='cuda:0') [1, 1]\n",
      "tensor(1064.5056, device='cuda:0') [0, 1]\n",
      "tensor(1064.8656, device='cuda:0') [0, 1]\n",
      "tensor(1066.7856, device='cuda:0') [0, 1]\n",
      "tensor(1067.2656, device='cuda:0') [1, 1]\n",
      "tensor(1068.1456, device='cuda:0') [0, 1]\n",
      "tensor(1068.7456, device='cuda:0') [0, 1]\n",
      "tensor(1069.0656, device='cuda:0') [1, 1]\n",
      "tensor(1070.0455, device='cuda:0') [1, 1]\n",
      "tensor(1070.0455, device='cuda:0') [0, 0]\n",
      "tensor(1071.8475, device='cuda:0') [0, 1]\n",
      "tensor(1072.9475, device='cuda:0') [1, 1]\n",
      "tensor(1074.1475, device='cuda:0') [0, 1]\n",
      "tensor(1074.1475, device='cuda:0') [0, 0]\n",
      "tensor(1075.1875, device='cuda:0') [1, 1]\n",
      "tensor(1075.8875, device='cuda:0') [0, 1]\n",
      "tensor(1076.8875, device='cuda:0') [0, 1]\n",
      "tensor(1077.8875, device='cuda:0') [0, 1]\n",
      "tensor(1079.1195, device='cuda:0') [1, 1]\n",
      "tensor(1079.7195, device='cuda:0') [0, 1]\n",
      "tensor(1080.8235, device='cuda:0') [0, 1]\n",
      "tensor(1081.3835, device='cuda:0') [0, 1]\n",
      "tensor(1082.2235, device='cuda:0') [1, 1]\n",
      "tensor(1082.5835, device='cuda:0') [0, 1]\n",
      "tensor(1082.8535, device='cuda:0') [0, 1]\n",
      "tensor(1084.0236, device='cuda:0') [0, 1]\n",
      "tensor(1085.2476, device='cuda:0') [1, 1]\n",
      "tensor(1086.1295, device='cuda:0') [0, 0]\n",
      "tensor(1087.0735, device='cuda:0') [0, 1]\n",
      "tensor(1087.8535, device='cuda:0') [1, 1]\n",
      "tensor(1088.1775, device='cuda:0') [0, 1]\n",
      "tensor(1089.0775, device='cuda:0') [0, 1]\n",
      "tensor(1090.5076, device='cuda:0') [1, 1]\n",
      "tensor(1090.5076, device='cuda:0') [0, 1]\n",
      "tensor(1091.0476, device='cuda:0') [0, 1]\n",
      "tensor(1091.9683, device='cuda:0') [0, 1]\n",
      "tensor(1093.4683, device='cuda:0') [0, 1]\n",
      "tensor(1094.9523, device='cuda:0') [0, 1]\n",
      "tensor(1095.4323, device='cuda:0') [1, 1]\n",
      "tensor(1096.1923, device='cuda:0') [0, 1]\n",
      "tensor(1096.5923, device='cuda:0') [0, 1]\n",
      "tensor(1097.1052, device='cuda:0') [0, 1]\n",
      "tensor(1098.1852, device='cuda:0') [1, 1]\n",
      "tensor(1098.9052, device='cuda:0') [0, 0]\n",
      "tensor(1100.3291, device='cuda:0') [1, 1]\n",
      "tensor(1101.7291, device='cuda:0') [0, 1]\n",
      "tensor(1101.7291, device='cuda:0') [0, 0]\n",
      "tensor(1102.3491, device='cuda:0') [0, 1]\n",
      "tensor(1103.5092, device='cuda:0') [1, 1]\n",
      "tensor(1103.8691, device='cuda:0') [0, 1]\n",
      "tensor(1105.2391, device='cuda:0') [0, 1]\n",
      "tensor(1105.7792, device='cuda:0') [0, 1]\n",
      "tensor(1107.1892, device='cuda:0') [0, 1]\n",
      "tensor(1108.7493, device='cuda:0') [1, 1]\n",
      "tensor(1108.7493, device='cuda:0') [0, 1]\n",
      "tensor(1110.0093, device='cuda:0') [0, 1]\n",
      "tensor(1110.0093, device='cuda:0') [0, 1]\n",
      "tensor(1111.3232, device='cuda:0') [0, 1]\n",
      "tensor(1112.9792, device='cuda:0') [0, 1]\n",
      "tensor(1114.1393, device='cuda:0') [1, 1]\n",
      "tensor(1114.6252, device='cuda:0') [0, 1]\n",
      "tensor(1115.1293, device='cuda:0') [0, 1]\n",
      "tensor(1115.1293, device='cuda:0') [0, 1]\n",
      "tensor(1116.5322, device='cuda:0') [1, 1]\n",
      "tensor(1116.7947, device='cuda:0') [0, 1]\n",
      "tensor(1117.6128, device='cuda:0') [0, 1]\n",
      "tensor(1118.3304, device='cuda:0') [0, 1]\n",
      "tensor(1119.4015, device='cuda:0') [0, 1]\n",
      "tensor(1120.1791, device='cuda:0') [0, 1]\n",
      "tensor(1121.0011, device='cuda:0') [1, 1]\n",
      "tensor(1121.1812, device='cuda:0') [0, 1]\n",
      "tensor(1122.2511, device='cuda:0') [1, 1]\n",
      "tensor(1123.1378, device='cuda:0') [0, 1]\n",
      "tensor(1123.4078, device='cuda:0') [0, 1]\n",
      "tensor(1123.9403, device='cuda:0') [0, 1]\n",
      "tensor(1125.2292, device='cuda:0') [0, 1]\n",
      "tensor(1126.3208, device='cuda:0') [1, 1]\n",
      "tensor(1127.2281, device='cuda:0') [0, 1]\n",
      "tensor(1127.8798, device='cuda:0') [0, 1]\n",
      "tensor(1128.8597, device='cuda:0') [1, 1]\n",
      "tensor(1129.3638, device='cuda:0') [0, 1]\n",
      "tensor(1130.3438, device='cuda:0') [1, 1]\n",
      "tensor(1131.9337, device='cuda:0') [0, 1]\n",
      "tensor(1132.1138, device='cuda:0') [0, 0]\n",
      "tensor(1133.0737, device='cuda:0') [1, 1]\n",
      "tensor(1133.9437, device='cuda:0') [0, 1]\n",
      "tensor(1134.5237, device='cuda:0') [0, 1]\n",
      "tensor(1134.5237, device='cuda:0') [0, 1]\n",
      "tensor(1135.7477, device='cuda:0') [0, 1]\n",
      "tensor(1136.6477, device='cuda:0') [0, 1]\n",
      "tensor(1137.5477, device='cuda:0') [0, 1]\n",
      "tensor(1138.0697, device='cuda:0') [0, 1]\n",
      "tensor(1139.0327, device='cuda:0') [0, 1]\n",
      "tensor(1140.0127, device='cuda:0') [1, 1]\n",
      "tensor(1140.6067, device='cuda:0') [0, 1]\n",
      "tensor(1142.4867, device='cuda:0') [1, 1]\n",
      "tensor(1142.8467, device='cuda:0') [0, 0]\n",
      "tensor(1143.7667, device='cuda:0') [1, 1]\n",
      "tensor(1144.1667, device='cuda:0') [0, 1]\n",
      "tensor(1144.4368, device='cuda:0') [0, 1]\n",
      "tensor(1146.2968, device='cuda:0') [0, 1]\n",
      "tensor(1146.2968, device='cuda:0') [0, 1]\n",
      "tensor(1146.9807, device='cuda:0') [0, 1]\n",
      "tensor(1147.4127, device='cuda:0') [0, 1]\n",
      "tensor(1147.6827, device='cuda:0') [1, 1]\n",
      "tensor(1149.2002, device='cuda:0') [0, 1]\n",
      "tensor(1151.6492, device='cuda:0') [0, 1]\n",
      "tensor(1152.4492, device='cuda:0') [1, 1]\n",
      "tensor(1152.8092, device='cuda:0') [0, 1]\n",
      "tensor(1153.0792, device='cuda:0') [0, 1]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = AdvantageMARL().to(device)\n",
    "advantage = AdvantageMARL().to(device)\n",
    "\n",
    "# load parameters\n",
    "model.load_state_dict(torch.load(\"advantage_no_sharing_117.pth\")[\"model_1\"])\n",
    "advantage.load_state_dict(torch.load(\"advantage_no_sharing_117.pth\")[\"advantage_model_1\"])\n",
    "\n",
    "for N in [2,3,4,5,6,7]:\n",
    "    dataCenters = [DataCenter(device) for _ in range(N)]\n",
    "    jobGenerator = JobGenerator(N)\n",
    "    \n",
    "    total_rewards = 0\n",
    "    reward_history = []\n",
    "\n",
    "    for episode in range(2000):\n",
    "        jobs = jobGenerator.generate_job()\n",
    "        # advantages = [advantage.forward_pass(dataCenters[i].state.to(device)) for i in range(N)]\n",
    "        actions = []\n",
    "        for i in range(N):\n",
    "            q_values = model.forward_pass(torch.cat((dataCenters[i].state.to(device), jobs[i].to(device))).to(device))\n",
    "            value_local = q_values[0]\n",
    "            value_local_max = value_local\n",
    "            value_send = q_values[1]\n",
    "            value_send_max = -1000, -1\n",
    "            for j in range(N):\n",
    "                adv_values = advantage.forward_pass(torch.cat((dataCenters[j].state.to(device), jobs[i].to(device))).to(device))\n",
    "                value_local += adv_values[0]/(N-1)\n",
    "                # value_local_max = max(value_local_max, value_local+ adv_values[0])\n",
    "                value_send_max = max(value_send_max, (value_send+ adv_values[1],j))\n",
    "            if value_send_max[0] > value_local_max:\n",
    "                actions.append(value_send_max[1])\n",
    "            else:\n",
    "                actions.append(i)\n",
    "            # actions.append(value_send_max[1])\n",
    "            \n",
    "        reward = 0\n",
    "        for i in range(N):\n",
    "            if actions[i] == i:\n",
    "                reward += dataCenters[i].add_job(jobs[i])\n",
    "            else:\n",
    "                jobs[i][1] *= 0.8\n",
    "                reward = dataCenters[actions[i]].add_job(jobs[i])\n",
    "            reward += dataCenters[i].update(1)\n",
    "        total_rewards += reward\n",
    "        reward_history.append(reward)\n",
    "        print(total_rewards, actions)\n",
    "# print(reward_history, total_rewards)\n",
    "print(\"------------\")\n",
    "        # print(advantages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
