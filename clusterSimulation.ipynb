{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b3149e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e081ed88",
   "metadata": {},
   "source": [
    "This part is reproduction of a previous work of past year student, Timothy Yeo\n",
    "\n",
    "With 2 Data Center, each with 5 machines and 6 queue length.\n",
    "total feature nubmer is 2 * (5 * 2+6 * 3+2) = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c3978a",
   "metadata": {},
   "source": [
    "Single-Agent Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "df2176e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# state: array of length 60, 30 for each data center\n",
    "# action: 1 of the 4 combinations possible for 2 data centers\n",
    "\n",
    "data_center_num = 2\n",
    "machine_num = 5\n",
    "queue_num = 6\n",
    "\n",
    "def machine_index(data_center_id, machine_id):\n",
    "    return data_center_id * (machine_num * 2 + queue_num * 3 + 2) + machine_id * 2\n",
    "\n",
    "def queue_index(data_center_id, queue_id):\n",
    "    return data_center_id * (machine_num * 2 + queue_num * 3 + 2) + machine_num * 2 + queue_id * 3\n",
    "\n",
    "def incoming_index(data_center_id):\n",
    "    return data_center_id * (machine_num * 2 + queue_num * 3 + 2) + machine_num * 2 + queue_num * 3\n",
    "\n",
    "def step(state, action):\n",
    "    state = state.detach().cpu().numpy()\n",
    "    global record\n",
    "    reward = 0\n",
    "    index = 0\n",
    "\n",
    "    for centerId in range(data_center_num):\n",
    "        # update reward by queueing delay\n",
    "        for queue in range(queue_num):\n",
    "            index = queue_index(centerId, queue)\n",
    "            if state[index] > 0:\n",
    "                state[index + 2] = max(0, state[index + 2] - 0.1)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    # STEP 1: update machine states\n",
    "    for centerId in range(data_center_num):\n",
    "        # update machine states (timestep--)\n",
    "        for machine in range(machine_num):\n",
    "            index = machine_index(centerId, machine)\n",
    "            if state[index] == 1:\n",
    "                # decrease by 1 timestep\n",
    "                state[index + 1] -= 1\n",
    "                if state[index + 1] == 0:\n",
    "                    state[index] = 0\n",
    "                    \n",
    "    # STEP 2: update queue states    \n",
    "    for centerId in range(data_center_num):\n",
    "        # update queue states (put into machines)\n",
    "        for queue in range(queue_num):\n",
    "            index = queue_index(centerId, queue)\n",
    "            # if job exist\n",
    "            if state[index] > 0:\n",
    "                for machine in range(machine_num):\n",
    "                    m_index = machine_index(centerId, machine)\n",
    "                    if state[m_index] == 0:\n",
    "                        state[m_index] = 1\n",
    "                        state[m_index + 1] = state[index + 1]\n",
    "                        state[index] = 0\n",
    "                        # update reward\n",
    "                        reward += state[index + 2]\n",
    "                        record[state[index+2].item()] += 1\n",
    "                        break\n",
    "\n",
    "    action = torch.argmax(action)\n",
    "    # update incoming jobs (locally)\n",
    "    for job in range(data_center_num):\n",
    "        if action // pow(2, job) % 2 == 0:\n",
    "            for queue in range(queue_num):\n",
    "                index = queue_index(job, queue)\n",
    "                if state[index] == 0:\n",
    "                    job_index = incoming_index(job)\n",
    "                    state[index] = 1\n",
    "                    state[index + 1] = state[job_index]\n",
    "                    state[index + 2] = state[job_index + 1]\n",
    "                    break\n",
    "            else:\n",
    "                record[\"abandoned\"] += 1\n",
    "\n",
    "    # update incoming jobs (remotely)\n",
    "    for job in range(data_center_num):\n",
    "        if action // pow(2, job) % 2 == 1:\n",
    "            for queue in range(queue_num):\n",
    "                index = queue_index(1- job, queue) # todo: fix logic for N > 2 ...\n",
    "                if state[index] == 0:\n",
    "                    job_index = incoming_index(job)\n",
    "                    state[index] = 1\n",
    "                    state[index + 1] = state[job_index]\n",
    "                    state[index + 2] = state[job_index + 1] - 0.2\n",
    "                    record[\"remote\"] += 1\n",
    "                    break\n",
    "            else:\n",
    "                record[\"abandoned\"] += 1\n",
    "    \n",
    "\n",
    "    # STEP 2: update queue states    \n",
    "    for centerId in range(data_center_num):\n",
    "        # update queue states (put into machines)\n",
    "        for queue in range(queue_num):\n",
    "            index = queue_index(centerId, queue)\n",
    "            # if job exist\n",
    "            if state[index] > 0:\n",
    "                for machine in range(machine_num):\n",
    "                    m_index = machine_index(centerId, machine)\n",
    "                    if state[m_index] == 0:\n",
    "                        state[m_index] = 1\n",
    "                        state[m_index + 1] = state[index + 1]\n",
    "                        state[index] = 0\n",
    "                        # update reward\n",
    "                        reward += state[index + 2]\n",
    "                        record[state[index+2].item()] += 1\n",
    "                        break\n",
    "\n",
    "\n",
    "    # update new incoming job\n",
    "    for job in range(data_center_num):\n",
    "        job_index = incoming_index(job)\n",
    "        seed = torch.rand(1).item()\n",
    "        if seed < 0.4:\n",
    "            state[job_index] = 8\n",
    "            state[job_index + 1] = 0.8\n",
    "        elif seed < 0.7:\n",
    "            state[job_index] = 4\n",
    "            state[job_index + 1] = 0.4\n",
    "        else:\n",
    "            state[job_index] = 2\n",
    "            state[job_index + 1] = 0.2\n",
    "\n",
    "    return state, reward\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "c3acdbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 1. ,  3. ,  1. ,  5. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
      "        5. , 11.9,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
      "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  8. ,  0.8,  1. ,  0. ,  1. ,\n",
      "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
      "        0. , -0.2,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
      "        0. ,  0. ,  0. ,  2. ,  0.2], dtype=float32), 11.699999615550041)\n",
      "Counter({11.899999618530273: 1, 'remote': 1, 0.0: 1, -0.20000000298023224: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "record = Counter()\n",
    "\n",
    "\n",
    "start = torch.zeros(60)\n",
    "start[0] = 1\n",
    "start[1] = 4\n",
    "start[2] = 1\n",
    "start[3] = 1\n",
    "\n",
    "start[queue_index(0,0)] = 1\n",
    "start[queue_index(0,0) + 1] = 5\n",
    "start[queue_index(0,0) + 2] = 12\n",
    "\n",
    "action = torch.tensor([0, 1, 0, 0])\n",
    "\n",
    "print(step(start, action))\n",
    "print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "ebc93cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a NN network with following architecture\n",
    "# Input Layer (60 features)\n",
    "# Leaky ReLU activation\n",
    "# Hidden Layer 1 (512 features)\n",
    "# Leaky ReLU activation\n",
    "# Hidden Layer 2 (256 features)\n",
    "# Leaky ReLU activation\n",
    "# Hidden Layer 3 (256 features)\n",
    "# Leaky ReLU activation\n",
    "# Hidden Layer 3 (256 features)\n",
    "# Leaky ReLU activation\n",
    "# Output Layer (4 actions)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SingleAgentNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SingleAgentNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(60, 512)\n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.layer3 = nn.Linear(256, 256)\n",
    "        self.layer4 = nn.Linear(256, 256)\n",
    "        self.layer5 = nn.Linear(256, 4)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Neural Network with input layer {self.input_layer}, hidden layer 1 {self.hidden_layer_1}, hidden layer 2 {self.hidden_layer_2}, hidden layer 3 {self.hidden_layer_3}, hidden layer 4 {self.hidden_layer_4}, and output layer {self.output_layer}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "    def forward_pass(self, input_data):\n",
    "        x = self.layer1(input_data)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer4(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "241331c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [355], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m total_rewards \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# deep Q learning update\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m expected_value \u001b[38;5;241m=\u001b[39m reward \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.9\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     46\u001b[0m actual_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(actions)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     48\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()(expected_value, actual_value)\n",
      "Cell \u001b[1;32mIn [353], line 42\u001b[0m, in \u001b[0;36mSingleAgentNN.forward_pass\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[0;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mleaky_relu(x)\n\u001b[1;32m---> 42\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\fx\\traceback.py:68\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_list(\u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\traceback.py:227\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 227\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\traceback.py:379\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    376\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[0;32m    377\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals))\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m--> 379\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\compilerop.py:193\u001b[0m, in \u001b[0;36mcheck_linecache_ipython\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call linecache.checkcache() safely protecting our cached values.\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# First call the original checkcache as intended\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkcache_ori\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# Then, update back the cache with our data, so that tracebacks related\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# to our compiled codes can be produced.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m linecache\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mupdate(linecache\u001b[38;5;241m.\u001b[39m_ipython_cache)\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "model = SingleAgentNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Check if GPU is available and if so, use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Transfer the model to the GPU\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "M = 1 #500\n",
    "N = 10 #3000\n",
    "\n",
    "M = 500\n",
    "N = 2000\n",
    "\n",
    "for episode in range(M):\n",
    "    record = Counter()\n",
    "\n",
    "    # create a loss function\n",
    "    cur_state = torch.zeros(60).to(device)\n",
    "    total_rewards = 0\n",
    "\n",
    "    l_time = 0\n",
    "    r_time = 0\n",
    "    import time\n",
    "    for timestep in range(N):\n",
    "        print(timestep)\n",
    "        # CPU part\n",
    "        pre = time.time()\n",
    "        actions = model.forward_pass(cur_state).to(device)\n",
    "        next_state, reward = step(cur_state, actions)\n",
    "        next_state = torch.tensor(next_state).to(device)\n",
    "        post = time.time()\n",
    "\n",
    "        l_time += post - pre\n",
    "\n",
    "        # GPU part\n",
    "        pre = time.time()\n",
    "        total_rewards += reward\n",
    "        # deep Q learning update\n",
    "        expected_value = reward + 0.9 * torch.max(model.forward_pass(next_state))\n",
    "        actual_value = torch.max(actions).float()\n",
    "\n",
    "        loss = torch.nn.MSELoss()(expected_value, actual_value)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        cur_state = next_state\n",
    "        post = time.time()\n",
    "        r_time += post - pre\n",
    "\n",
    "        # print(cur_state)\n",
    "\n",
    "    print(total_rewards, l_time, r_time)\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f513300e",
   "metadata": {},
   "source": [
    "Above are implementation of a previous student's work.\n",
    "Following will be the work by myself.\n",
    "\n",
    "# Data Center\n",
    "Used to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e82ac8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_SIZE = 28\n",
    "QUERY_SIZE = 1\n",
    "VALUE_SIZE = 4\n",
    "\n",
    "JOB_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a46ea3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "1ae44bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each data center holds two NN, one for state compression (Attention-model) and another for action selection (DQN), the following class represents the Attention model\n",
    "\n",
    "# It has access to the full state of the data center and state representation of neighboring data centers\n",
    "\n",
    "# State Compression Using Attention Model\n",
    "class StateCompressor(nn.Module):\n",
    "    def __init__(self, state_size, query_size, value_size, device=\"cpu\"):\n",
    "        super(StateCompressor, self).__init__()\n",
    "        # might replace into a more appropriate encoder\n",
    "        self.W_v_local = nn.Linear(state_size, value_size).to(device)\n",
    "        # attention qkv\n",
    "        self.W_q = nn.Linear(value_size, query_size).to(device)\n",
    "        # value size add 1 to include extra encoding for the local state distingushment\n",
    "        self.W_k = nn.Linear(value_size+1, query_size).to(device)\n",
    "        self.W_v = nn.Linear(value_size+1, value_size).to(device)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "    def forward_pass(self, local_state, remote_info):\n",
    "        local_info = self.W_v_local(local_state.detach())\n",
    "        full_info = torch.cat((local_info.detach().unsqueeze(0), remote_info.detach()), 0)\n",
    "        full_info_with_encoding = torch.cat((full_info, torch.zeros(full_info.size(0), 1).to(self.device)), 1)\n",
    "        full_info_with_encoding[0, -1] = 1\n",
    "\n",
    "\n",
    "        # print(\"full_info\", full_info.size())\n",
    "        q = self.W_q(local_info)\n",
    "        k = self.W_k(full_info_with_encoding)\n",
    "        v = self.W_v(full_info_with_encoding)\n",
    "        # print(q.size(), k.size(), v.size())\n",
    "        x = torch.matmul(q, k.T)\n",
    "        # print(x.size())\n",
    "        x = torch.nn.functional.softmax(x)\n",
    "        x = torch.matmul(x, v)\n",
    "\n",
    "        return local_info + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "bffe161c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4694, 0.1997, 0.2103, 0.2271], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\l\\AppData\\Local\\Temp\\ipykernel_29308\\2647041914.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = torch.nn.functional.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "# brief test\n",
    "state_compressor = StateCompressor(STATE_SIZE, QUERY_SIZE, VALUE_SIZE)\n",
    "print(state_compressor.forward_pass(torch.zeros(STATE_SIZE), torch.zeros((2,4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "866d9aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# action selection using DQN\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, rep_size, device=\"cpu\"):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(state_size+rep_size+JOB_SIZE+1, 512).to(device)\n",
    "        self.layer2 = nn.Linear(512, 256).to(device)\n",
    "        self.layer3 = nn.Linear(256, 256).to(device)\n",
    "        self.layer4 = nn.Linear(256, 256).to(device)\n",
    "        self.layer5 = nn.Linear(256, 1).to(device)\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer4(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "087de7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0077], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# brief test\n",
    "dqn = DQN(STATE_SIZE, VALUE_SIZE)\n",
    "print(dqn.forward_pass(torch.zeros(STATE_SIZE + 4 + 2 + 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8ad5c3",
   "metadata": {},
   "source": [
    "With 2 Data Center, each with 5 machines and 6 queue length.\n",
    "total feature nubmer is 2 * (5 * 2+6 * 3+2) = 60\n",
    "\n",
    "which means that per machine, we have 5*2+6*3 = 28 state size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9017a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "a38d9a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCenter():\n",
    "    def __init__(self, device):\n",
    "        # self.data_center_id = data_center_id\n",
    "        # self.machine_num = machine_num\n",
    "        # self.queue_num = queue_num\n",
    "        self.state = torch.zeros(STATE_SIZE).to(device)\n",
    "        self.compressor = StateCompressor(STATE_SIZE, QUERY_SIZE, VALUE_SIZE, device=device)\n",
    "        self.dqn = DQN(STATE_SIZE, VALUE_SIZE)\n",
    "        self.representations = torch.zeros(VALUE_SIZE).to(device)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.dqn_optimizer = torch.optim.Adam(self.dqn.parameters(), lr=0.001)\n",
    "        self.compressor_optimizer = torch.optim.Adam(self.compressor.parameters(), lr=0.001)\n",
    "    \n",
    "    def update(self, delta):\n",
    "        with torch.no_grad():\n",
    "            # reward = gains from successful job allocation - losses from queueing delay\n",
    "            reward = torch.tensor(0.0).to(self.device)\n",
    "            # Separate machine states and queue states\n",
    "            machines = self.state[:10].view(5, 2).clone()\n",
    "            queues = self.state[10:].view(6, 3).clone()\n",
    "\n",
    "            # Update machine states\n",
    "            machines[:, 1] = torch.maximum(torch.zeros_like(machines[:, 1]), machines[:, 1] - delta)\n",
    "            machines[machines[:, 1] == 0, 0] = 0\n",
    "\n",
    "            # Find available machines and assign jobs from the queue\n",
    "            for i in range(queues.size(0)):\n",
    "                if queues[i, 0] > 0:\n",
    "                    # Find first available machine\n",
    "                    available_machine_index = torch.nonzero(machines[:, 0] == 0, as_tuple=False)\n",
    "                    if available_machine_index.size(0) > 0:\n",
    "                        first_available = available_machine_index[0].item()\n",
    "                        machines[first_available, 0] = 1\n",
    "                        machines[first_available, 1] = queues[i, 1]\n",
    "                        reward += queues[i, 2]\n",
    "                        queues[i, :] = 0\n",
    "            \n",
    "            queues[:, 2] = torch.maximum(torch.zeros_like(queues[:, 2]), queues[:, 2] - 0.1)\n",
    "\n",
    "            # Merge the updated machine and queue states back into self.state\n",
    "            self.state = torch.cat((machines.view(-1), queues.view(-1)))\n",
    "\n",
    "            return reward\n",
    "    \n",
    "    def update_rep(self, remote_info):\n",
    "        new_reps = self.compressor.forward_pass(self.state, remote_info)\n",
    "        # print(new_reps.size(), self.representations.size())\n",
    "        assert new_reps.size() == self.representations.size()\n",
    "        self.representations = new_reps\n",
    "    \n",
    "    def get_q_values(self, reps, job):\n",
    "        batch_input = torch.zeros((2, STATE_SIZE + VALUE_SIZE + JOB_SIZE + 1))\n",
    "        batch_input[0] = torch.cat((self.state, self.representations, job, torch.ones(1).to(self.device)), 0)\n",
    "        for i in range(reps.size(0)):\n",
    "            batch_input[i+1] = torch.cat((self.state, reps[i], job, torch.zeros(1).to(self.device)), 0)\n",
    "            # expand the concat into several instructions\n",
    "        \n",
    "        # batch_input[0, :STATE_SIZE] = self.state\n",
    "        # # batch_input[0, STATE_SIZE:STATE_SIZE+VALUE_SIZE] = self.representations\n",
    "        # batch_input[0, STATE_SIZE+VALUE_SIZE:STATE_SIZE+VALUE_SIZE+JOB_SIZE] = job\n",
    "\n",
    "        batch_input.to(self.device)\n",
    "        q_values = self.dqn.forward_pass(batch_input)\n",
    "        return q_values\n",
    "\n",
    "    # add job to the queue of the data center\n",
    "    def add_job(self, job):\n",
    "        state = self.state.clone()\n",
    "        for i in range(6):\n",
    "            if state[10+i*3] == 0:\n",
    "                state[10+i*3] = 1\n",
    "                state[10+i*3+1] = job[0]\n",
    "                state[10+i*3+2] = job[1]\n",
    "                break\n",
    "        self.state = state\n",
    "\n",
    "\n",
    "    \n",
    "    # how to do this?\n",
    "    def backprop(self):\n",
    "        self.dqn_optimizer.step()\n",
    "        self.compressor_optimizer.step()\n",
    "\n",
    "        self.dqn_optimizer.zero_grad()\n",
    "        self.compressor_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "03427382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 3.9000, 1.0000, 0.9000, 1.0000, 5.0000, 1.0000, 4.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0')\n",
      "tensor([-1.1559, -2.4334, -0.1383,  0.5641], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\l\\AppData\\Local\\Temp\\ipykernel_29308\\2647041914.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = torch.nn.functional.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dc = DataCenter(device)\n",
    "dc.state[0] = 1\n",
    "dc.state[1] = 4\n",
    "dc.state[2] = 1\n",
    "dc.state[3] = 1\n",
    "dc.state[10] = 1\n",
    "dc.state[11] = 5\n",
    "dc.state[12] = 12\n",
    "dc.state[13] = 1\n",
    "dc.state[14] = 4\n",
    "dc.state[15] = 1\n",
    "\n",
    "dc.update(0.1)\n",
    "print(dc.state)\n",
    "\n",
    "remote_info = torch.zeros((2, 4)).to(device)\n",
    "dc.update_rep(remote_info)\n",
    "print(dc.representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "27f27bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobGenerator():\n",
    "    def __init__(self, data_center_num) -> None:\n",
    "        self.data_center_num = data_center_num\n",
    "\n",
    "    def generate_job(self):\n",
    "        jobs = []\n",
    "        for i in range(self.data_center_num):\n",
    "            seed = torch.rand(1).item()\n",
    "            if seed < 0.4:\n",
    "                jobs.append((8, 0.8))\n",
    "            elif seed < 0.7:\n",
    "                jobs.append((4, 0.4))\n",
    "            else:\n",
    "                jobs.append((2, 0.2))\n",
    "        return [torch.tensor(j) for j in jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "feb31ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "job_generator = JobGenerator(2)\n",
    "print(job_generator.generate_job())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "6a26f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(q_values, epsilon):\n",
    "    action = None\n",
    "    if torch.rand(1).item() < epsilon:\n",
    "        action = torch.randint(0, q_values.size(0), (1, ))\n",
    "    else:\n",
    "        action = torch.argmax(q_values)\n",
    "    q_value = q_values[action]\n",
    "    return action, q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "ba4033a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\l\\AppData\\Local\\Temp\\ipykernel_29308\\2647041914.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = torch.nn.functional.softmax(x)\n",
      "c:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th loop tensor(0.4000, device='cuda:0') tensor(0.4000, device='cuda:0') tensor([1., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([-0.5093, -0.5203, -0.3438, -0.7589], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "1th loop tensor(1.2000, device='cuda:0') tensor(1.6000, device='cuda:0') tensor([1., 3., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([-0.2666, -0.7468, -1.1292,  0.6732], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "2th loop tensor(0.8000, device='cuda:0') tensor(2.4000, device='cuda:0') tensor([1., 2., 1., 3., 1., 8., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.2933, -1.3502,  0.3379, -0.0859], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "3th loop tensor(1., device='cuda:0') tensor(3.4000, device='cuda:0') tensor([1., 1., 1., 2., 1., 7., 1., 1., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.0146, -1.2900,  0.3812, -0.0404], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "4th loop tensor(0.8000, device='cuda:0') tensor(4.2000, device='cuda:0') tensor([0., 0., 1., 1., 1., 6., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 0.5512, -0.9740,  0.4638,  0.2827], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "5th loop tensor(0.2000, device='cuda:0') tensor(4.4000, device='cuda:0') tensor([1., 2., 0., 0., 1., 5., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([-0.0341, -1.1262, -0.1125,  0.0105], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "6th loop tensor(0.2000, device='cuda:0') tensor(4.6000, device='cuda:0') tensor([1., 1., 0., 0., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 0.2280, -0.8664, -0.0390,  0.1150], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "7th loop tensor(0.2000, device='cuda:0') tensor(4.8000, device='cuda:0') tensor([1., 4., 0., 0., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 0.3489, -1.1033,  0.4909, -1.0611], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "8th loop tensor(0.8000, device='cuda:0') tensor(5.6000, device='cuda:0') tensor([1., 3., 1., 2., 1., 2., 1., 8., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 2.1557, -1.8004,  0.9333, -0.5148], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "9th loop tensor(1.1000, device='cuda:0') tensor(6.7000, device='cuda:0') tensor([1., 2., 1., 1., 1., 1., 1., 7., 1., 2., 0., 0., 0., 1., 2., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 2.0062, -1.3889,  1.3939, -0.2069], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "10th loop tensor(0.6000, device='cuda:0') tensor(7.3000, device='cuda:0') tensor([1., 1., 1., 2., 0., 0., 1., 6., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 0.8637, -1.1732,  0.0797,  0.2447], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "11th loop tensor(0.2000, device='cuda:0') tensor(7.5000, device='cuda:0') tensor([0., 0., 1., 1., 0., 0., 1., 5., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.1397, -0.6135,  0.3396,  0.2041], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "12th loop tensor(0.6000, device='cuda:0') tensor(8.1000, device='cuda:0') tensor([0., 0., 0., 0., 0., 0., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 0.4632, -0.3298,  0.3041, -0.2018], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "13th loop tensor(0., device='cuda:0') tensor(8.1000, device='cuda:0') tensor([0., 0., 0., 0., 0., 0., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([-0.0462, -0.3623, -0.2849,  0.4340], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "14th loop tensor(0., device='cuda:0') tensor(8.1000, device='cuda:0') tensor([0., 0., 0., 0., 0., 0., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 0.0896, -0.2503, -0.3148,  0.3689], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "15th loop tensor(0., device='cuda:0') tensor(8.1000, device='cuda:0') tensor([0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([-0.0762, -0.0591, -0.5067,  0.4371], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "16th loop tensor(0., device='cuda:0') tensor(8.1000, device='cuda:0') tensor([1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([-0.6354, -0.2399, -0.4765, -0.3044], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "17th loop tensor(0.4000, device='cuda:0') tensor(8.5000, device='cuda:0') tensor([1., 1., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([-0.1069, -0.2684, -0.9212,  0.6088], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th loop tensor(1., device='cuda:0') tensor(9.5000, device='cuda:0') tensor([1., 8., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([-1.2513, -1.6464, -1.0325, -1.0520], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "19th loop tensor(0.8000, device='cuda:0') tensor(10.3000, device='cuda:0') tensor([1., 7., 1., 2., 1., 2., 1., 8., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 0.3410, -1.8725,  0.1544, -1.4830], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "20th loop tensor(0.4000, device='cuda:0') tensor(10.7000, device='cuda:0') tensor([1., 6., 1., 1., 1., 1., 1., 7., 1., 4., 0., 0., 0., 1., 2., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 0.5834, -2.2409,  0.6006, -1.1236], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "21th loop tensor(0.6000, device='cuda:0') tensor(11.3000, device='cuda:0') tensor([1., 5., 1., 2., 1., 2., 1., 6., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 0.4079, -2.3832, -0.0855, -0.5427], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "22th loop tensor(0.2000, device='cuda:0') tensor(11.5000, device='cuda:0') tensor([1., 4., 1., 1., 1., 1., 1., 5., 1., 2., 1., 2., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 0.3815, -1.8111, -0.0702, -0.7133], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "23th loop tensor(0.2000, device='cuda:0') tensor(11.7000, device='cuda:0') tensor([1.0000, 3.0000, 1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 4.0000, 1.0000,\n",
      "        1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 4.0000,\n",
      "        0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0470, -1.3540, -0.3690, -0.3398], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "24th loop tensor(0.4000, device='cuda:0') tensor(12.1000, device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 3.0000, 1.0000,\n",
      "        4.0000, 0.0000, 0.0000, 0.0000, 1.0000, 8.0000, 0.5000, 1.0000, 4.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.4024, -0.4269,  0.9289,  1.3412], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "25th loop tensor(0.7000, device='cuda:0') tensor(12.8000, device='cuda:0') tensor([1., 1., 1., 4., 1., 8., 1., 2., 1., 3., 0., 0., 0., 0., 0., 0., 1., 4.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 2.3258, -1.5697,  0.5277, -0.5162], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "26th loop tensor(0.2000, device='cuda:0') tensor(13.0000, device='cuda:0') tensor([1., 4., 1., 3., 1., 7., 1., 1., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 0.9187, -1.7624,  0.2721, -0.5431], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "27th loop tensor(0.8000, device='cuda:0') tensor(13.8000, device='cuda:0') tensor([1., 3., 1., 2., 1., 6., 1., 8., 1., 1., 0., 0., 0., 1., 2., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1.7885, -1.6012,  1.3277, -0.2581], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [436], line 124\u001b[0m\n\u001b[0;32m    121\u001b[0m dataCenter2\u001b[38;5;241m.\u001b[39mupdate_rep(dataCenter1\u001b[38;5;241m.\u001b[39mrepresentations\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# get initial actions\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m q_values_1 \u001b[38;5;241m=\u001b[39m \u001b[43mdataCenter1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_q_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataCenter2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m q_values_2 \u001b[38;5;241m=\u001b[39m dataCenter2\u001b[38;5;241m.\u001b[39mget_q_values(dataCenter1\u001b[38;5;241m.\u001b[39mrepresentations\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), jobs[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m    127\u001b[0m action1, q_value_1 \u001b[38;5;241m=\u001b[39m epsilon_greedy(q_values_1, \u001b[38;5;241m0.1\u001b[39m)\n",
      "Cell \u001b[1;32mIn [431], line 57\u001b[0m, in \u001b[0;36mDataCenter.get_q_values\u001b[1;34m(self, reps, job)\u001b[0m\n\u001b[0;32m     55\u001b[0m batch_input[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentations, job, torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(reps\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)):\n\u001b[1;32m---> 57\u001b[0m     batch_input[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# expand the concat into several instructions\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# batch_input[0, :STATE_SIZE] = self.state\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# # batch_input[0, STATE_SIZE:STATE_SIZE+VALUE_SIZE] = self.representations\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# batch_input[0, STATE_SIZE+VALUE_SIZE:STATE_SIZE+VALUE_SIZE+JOB_SIZE] = job\u001b[39;00m\n\u001b[0;32m     64\u001b[0m batch_input\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main Simulation\n",
    "\n",
    "# configs\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "# Check if GPU is available and if so, use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create Data Centers\n",
    "data_center_num = 2\n",
    "dataCenter1 = DataCenter(device)\n",
    "dataCenter2 = DataCenter(device)\n",
    "\n",
    "\n",
    "M = 1 #500\n",
    "N = 300 #3000\n",
    "\n",
    "# M = 500\n",
    "# N = 3000\n",
    "\n",
    "for episode in range(M):\n",
    "    # keep track of rewards\n",
    "    total_rewards = 0\n",
    "\n",
    "    # create a loss function\n",
    "    dataCenter1.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    dataCenter2.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    total_rewards = 0\n",
    "\n",
    "    jobGenerator = JobGenerator(data_center_num)\n",
    "\n",
    "    l_time = 0\n",
    "    r_time = 0\n",
    "    import time\n",
    "\n",
    "    jobs = jobGenerator.generate_job()\n",
    "\n",
    "    # get initial actions\n",
    "    q_values_1 = dataCenter1.get_q_values(dataCenter2.representations.unsqueeze(0), jobs[0].to(device))\n",
    "    q_values_2 = dataCenter2.get_q_values(dataCenter1.representations.unsqueeze(0), jobs[1].to(device))\n",
    "\n",
    "    action1, q_value_1 = epsilon_greedy(q_values_1, 0.1)\n",
    "    action2, q_value_2 = epsilon_greedy(q_values_2, 0.1)\n",
    "\n",
    "    for timestep in range(N):\n",
    "        # update according to action\n",
    "        pre = time.time()\n",
    "\n",
    "        reward1 = 0\n",
    "        reward2 = 0\n",
    "\n",
    "        reward = torch.tensor(0.0).to(device)\n",
    "\n",
    "        if action1 == 0:\n",
    "            dataCenter1.add_job(jobs[0])\n",
    "        else:\n",
    "            jobs[0][1] -= 0.2\n",
    "            dataCenter2.add_job(jobs[0])\n",
    "\n",
    "        if action2 == 0:\n",
    "            dataCenter2.add_job(jobs[1])\n",
    "        else:\n",
    "            jobs[1][1] -= 0.2\n",
    "            dataCenter1.add_job(jobs[1])\n",
    "\n",
    "        reward += dataCenter1.update(1)\n",
    "        reward += dataCenter2.update(1)\n",
    "\n",
    "        post = time.time()\n",
    "        l_time += post - pre\n",
    "        \n",
    "\n",
    "        \n",
    "        # update representations\n",
    "        pre = time.time()\n",
    "        jobs = jobGenerator.generate_job()\n",
    "\n",
    "        # get the representations\n",
    "        dataCenter1.update_rep(dataCenter2.representations.unsqueeze(0))\n",
    "        dataCenter2.update_rep(dataCenter1.representations.unsqueeze(0))\n",
    "\n",
    "        # get next actions\n",
    "        new_q_values_1 = dataCenter1.get_q_values(dataCenter2.representations.unsqueeze(0), jobs[0].to(device))\n",
    "        new_q_values_2 = dataCenter2.get_q_values(dataCenter1.representations.unsqueeze(0), jobs[1].to(device))\n",
    "\n",
    "        new_action1, new_q_value_1 = epsilon_greedy(q_values_1, 0.1)\n",
    "        new_action2, new_q_value_2 = epsilon_greedy(q_values_2, 0.1)\n",
    "\n",
    "        post = time.time()\n",
    "        r_time += post - pre\n",
    "\n",
    "        # handle rewards\n",
    "        total_rewards += reward\n",
    "        reward1 = reward / 2\n",
    "        reward2 = reward / 2\n",
    "\n",
    "        print(f\"{timestep}th loop\", reward, total_rewards, dataCenter1.state, dataCenter1.representations)\n",
    "\n",
    "        # backprop\n",
    "        expected_value_1 = reward1 + 0.9 * torch.max(new_q_values_1)\n",
    "        actual_value_1 = q_value_1.to(device)\n",
    "        loss_1 = torch.nn.MSELoss()(expected_value_1, actual_value_1)\n",
    "        loss_1.backward(retain_graph=True)\n",
    "\n",
    "        expected_value_2 = reward2 + 0.9 * torch.max(new_q_values_2)\n",
    "        actual_value_2 = q_value_2.to(device)\n",
    "        loss_2 = torch.nn.MSELoss()(expected_value_2, actual_value_2)\n",
    "        loss_2.backward(retain_graph=True)\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            dataCenter1.backprop()\n",
    "            dataCenter2.backprop()\n",
    "\n",
    "        # need to re-calculate the q_values to avoid issues in the backpropagation\n",
    "        \n",
    "        # get the representations\n",
    "        dataCenter1.update_rep(dataCenter2.representations.unsqueeze(0))\n",
    "        dataCenter2.update_rep(dataCenter1.representations.unsqueeze(0))\n",
    "\n",
    "        # get initial actions\n",
    "        q_values_1 = dataCenter1.get_q_values(dataCenter2.representations.unsqueeze(0), jobs[0].to(device))\n",
    "        q_values_2 = dataCenter2.get_q_values(dataCenter1.representations.unsqueeze(0), jobs[1].to(device))\n",
    "\n",
    "        action1, q_value_1 = epsilon_greedy(q_values_1, 0.1)\n",
    "        action2, q_value_2 = epsilon_greedy(q_values_2, 0.1)\n",
    "\n",
    "\n",
    "\n",
    "        # # GPU part\n",
    "        # pre = time.time()\n",
    "        # total_rewards += reward\n",
    "        # # deep Q learning update\n",
    "        # expected_value = reward + 0.9 * torch.max(model.forward_pass(next_state))\n",
    "        # actual_value = torch.max(actions).float()\n",
    "\n",
    "        # loss = torch.nn.MSELoss()(expected_value, actual_value)\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        # optimizer.zero_grad()\n",
    "        # cur_state = next_state\n",
    "        # post = time.time()\n",
    "        # r_time += post - pre\n",
    "\n",
    "        # print(cur_state)\n",
    "\n",
    "    print(total_rewards, l_time, r_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeca346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7052beb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
