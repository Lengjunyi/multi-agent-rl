{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b3149e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e081ed88",
   "metadata": {},
   "source": [
    "This part is reproduction of a previous work of past year student, Timothy Yeo\n",
    "\n",
    "With 2 Data Center, each with 5 machines and 6 queue length.\n",
    "total feature nubmer is 2 * (5 * 2+6 * 3+2) = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c3978a",
   "metadata": {},
   "source": [
    "## Single-Agent Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ebc93cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a NN network with following architecture\n",
    "# Input Layer (60 features)\n",
    "# Leaky ReLU activation\n",
    "# Hidden Layer 1 (512 features)\n",
    "# Leaky ReLU activation\n",
    "# Hidden Layer 2 (256 features)\n",
    "# Leaky ReLU activation\n",
    "# Hidden Layer 3 (256 features)\n",
    "# Leaky ReLU activation\n",
    "# Hidden Layer 3 (256 features)\n",
    "# Leaky ReLU activation\n",
    "# Output Layer (4 actions)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SingleAgentNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SingleAgentNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(60, 512)\n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.layer3 = nn.Linear(256, 256)\n",
    "        self.layer4 = nn.Linear(256, 256)\n",
    "        self.layer5 = nn.Linear(256, 4)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Neural Network with input layer {self.input_layer}, hidden layer 1 {self.hidden_layer_1}, hidden layer 2 {self.hidden_layer_2}, hidden layer 3 {self.hidden_layer_3}, hidden layer 4 {self.hidden_layer_4}, and output layer {self.output_layer}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "    def forward_pass(self, input_data):\n",
    "        x = self.layer1(input_data)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer4(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c195d7e",
   "metadata": {},
   "source": [
    "Above are implementation of a previous student's work.\n",
    "Following will be the work by myself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f513300e",
   "metadata": {},
   "source": [
    "# Data Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e82ac8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_SIZE = 28\n",
    "QUERY_SIZE = 1\n",
    "VALUE_SIZE = 4\n",
    "# second config: no information is passed\n",
    "VALUE_SIZE = 1\n",
    "\n",
    "\n",
    "JOB_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46ea3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ae44bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each data center holds two NN, one for state compression (Attention-model) and another for action selection (DQN), the following class represents the Attention model\n",
    "\n",
    "# It has access to the full state of the data center and state representation of neighboring data centers\n",
    "\n",
    "# State Compression Using Attention Model\n",
    "class StateCompressor(nn.Module):\n",
    "    def __init__(self, state_size, query_size, value_size, device=\"cpu\"):\n",
    "        super(StateCompressor, self).__init__()\n",
    "        # might replace into a more appropriate encoder\n",
    "        self.W_v_local = nn.Linear(state_size, value_size).to(device)\n",
    "        # attention qkv\n",
    "        self.W_q = nn.Linear(value_size, query_size).to(device)\n",
    "        # value size add 1 to include extra encoding for the local state distingushment\n",
    "        self.W_k = nn.Linear(value_size+1, query_size).to(device)\n",
    "        self.W_v = nn.Linear(value_size+1, value_size).to(device)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "    def forward_pass(self, local_state, remote_info):\n",
    "        local_info = self.W_v_local(local_state.detach())\n",
    "        full_info = torch.cat((local_info.detach().unsqueeze(0), remote_info.detach()), 0)\n",
    "        full_info_with_encoding = torch.cat((full_info, torch.zeros(full_info.size(0), 1).to(self.device)), 1)\n",
    "        full_info_with_encoding[0, -1] = 1\n",
    "\n",
    "\n",
    "        # print(\"full_info\", full_info.size())\n",
    "        q = self.W_q(local_info)\n",
    "        k = self.W_k(full_info_with_encoding)\n",
    "        v = self.W_v(full_info_with_encoding)\n",
    "        # print(q.size(), k.size(), v.size())\n",
    "        x = torch.matmul(q, k.T)\n",
    "        # print(x.size())\n",
    "        x = torch.nn.functional.softmax(x)\n",
    "        x = torch.matmul(x, v)\n",
    "\n",
    "        return local_info + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bffe161c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0173], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\l\\AppData\\Local\\Temp\\ipykernel_28352\\2790792578.py:39: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = torch.nn.functional.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "# brief test\n",
    "state_compressor = StateCompressor(STATE_SIZE, QUERY_SIZE, VALUE_SIZE)\n",
    "print(state_compressor.forward_pass(torch.zeros(STATE_SIZE), torch.zeros((2,VALUE_SIZE))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "866d9aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# action selection using DQN\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, rep_size, device=\"cpu\"):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(state_size+rep_size+JOB_SIZE+1, 512).to(device)\n",
    "        self.layer2 = nn.Linear(512, 256).to(device)\n",
    "        self.layer3 = nn.Linear(256, 256).to(device)\n",
    "        self.layer4 = nn.Linear(256, 256).to(device)\n",
    "        self.layer5 = nn.Linear(256, 1).to(device)\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer4(x)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.layer5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "087de7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0123], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# brief test\n",
    "dqn = DQN(STATE_SIZE, VALUE_SIZE)\n",
    "print(dqn.forward_pass(torch.zeros(STATE_SIZE + VALUE_SIZE + 2 + 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8ad5c3",
   "metadata": {},
   "source": [
    "With 2 Data Center, each with 5 machines and 6 queue length.\n",
    "total feature nubmer is 2 * (5 * 2+6 * 3+2) = 60\n",
    "\n",
    "which means that per machine, we have 5*2+6*3 = 28 state size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a38d9a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCenter():\n",
    "    def __init__(self, device):\n",
    "        # self.data_center_id = data_center_id\n",
    "        # self.machine_num = machine_num\n",
    "        # self.queue_num = queue_num\n",
    "        self.state = torch.zeros(STATE_SIZE).to(device)\n",
    "        self.compressor = StateCompressor(STATE_SIZE, QUERY_SIZE, VALUE_SIZE, device=device)\n",
    "        self.dqn = DQN(STATE_SIZE, VALUE_SIZE)\n",
    "        self.representations = torch.zeros(VALUE_SIZE).to(device)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.dqn_optimizer = torch.optim.Adam(self.dqn.parameters(), lr=0.001)\n",
    "        self.compressor_optimizer = torch.optim.Adam(self.compressor.parameters(), lr=0.001)\n",
    "    \n",
    "    def update(self, delta):\n",
    "        with torch.no_grad():\n",
    "            # reward = gains from successful job allocation - losses from queueing delay\n",
    "            reward = torch.tensor(0.0).to(self.device)\n",
    "            # Separate machine states and queue states\n",
    "            machines = self.state[:10].view(5, 2).clone()\n",
    "            queues = self.state[10:].view(6, 3).clone()\n",
    "\n",
    "            # Update machine states\n",
    "            machines[:, 1] = torch.maximum(torch.zeros_like(machines[:, 1]), machines[:, 1] - delta)\n",
    "            machines[machines[:, 1] == 0, 0] = 0\n",
    "\n",
    "            # Find available machines and assign jobs from the queue\n",
    "            for i in range(queues.size(0)):\n",
    "                if queues[i, 0] > 0:\n",
    "                    # Find first available machine\n",
    "                    available_machine_index = torch.nonzero(machines[:, 0] == 0, as_tuple=False)\n",
    "                    if available_machine_index.size(0) > 0:\n",
    "                        first_available = available_machine_index[0].item()\n",
    "                        machines[first_available, 0] = 1\n",
    "                        machines[first_available, 1] = queues[i, 1]\n",
    "                        reward += queues[i, 2]\n",
    "                        queues[i, :] = 0\n",
    "                else:\n",
    "                    break\n",
    "            # move remaining jobs to the front\n",
    "            queues = torch.cat((queues[queues[:, 0] > 0], queues[queues[:, 0] == 0]), 0)\n",
    "            \n",
    "\n",
    "            \n",
    "            # queues[:, 2] = torch.maximum(torch.zeros_like(queues[:, 2]), queues[:, 2] - 0.1)\n",
    "            queues[:, 2] *= 0.9\n",
    "\n",
    "            # Merge the updated machine and queue states back into self.state\n",
    "            self.state = torch.cat((machines.view(-1), queues.view(-1)))\n",
    "\n",
    "            return reward\n",
    "    \n",
    "    def update_rep(self, remote_info):\n",
    "        new_reps = self.compressor.forward_pass(self.state, remote_info)\n",
    "        # print(new_reps.size(), self.representations.size())\n",
    "        assert new_reps.size() == self.representations.size()\n",
    "        self.representations = new_reps\n",
    "    \n",
    "    def get_q_values(self, reps, job):\n",
    "        batch_input = torch.zeros((2, STATE_SIZE + VALUE_SIZE + JOB_SIZE + 1))\n",
    "        batch_input[0] = torch.cat((self.state, self.representations, job, torch.ones(1).to(self.device)), 0)\n",
    "        for i in range(reps.size(0)):\n",
    "            batch_input[i+1] = torch.cat((self.state, reps[i], job, torch.zeros(1).to(self.device)), 0)\n",
    "            # expand the concat into several instructions\n",
    "        \n",
    "        # batch_input[0, :STATE_SIZE] = self.state\n",
    "        # # batch_input[0, STATE_SIZE:STATE_SIZE+VALUE_SIZE] = self.representations\n",
    "        # batch_input[0, STATE_SIZE+VALUE_SIZE:STATE_SIZE+VALUE_SIZE+JOB_SIZE] = job\n",
    "\n",
    "        batch_input.to(self.device)\n",
    "        q_values = self.dqn.forward_pass(batch_input)\n",
    "        return q_values\n",
    "\n",
    "    # add job to the queue of the data center\n",
    "    def add_job(self, job):\n",
    "        reward = 0\n",
    "        state = self.state.clone()\n",
    "        for i in range(6):\n",
    "            if state[10+i*3] == 0:\n",
    "                state[10+i*3] = 1\n",
    "                state[10+i*3+1] = job[0]\n",
    "                state[10+i*3+2] = job[1]\n",
    "                break\n",
    "        else:\n",
    "            reward -= 0.2\n",
    "        self.state = state\n",
    "        return reward\n",
    "\n",
    "\n",
    "    \n",
    "    # how to do this?\n",
    "    def backprop(self):\n",
    "        self.dqn_optimizer.step()\n",
    "        self.compressor_optimizer.step()\n",
    "\n",
    "        self.dqn_optimizer.zero_grad()\n",
    "        self.compressor_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "03427382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 3.9000, 1.0000, 0.9000, 1.0000, 5.0000, 1.0000, 4.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0')\n",
      "tensor([0.5381], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\l\\AppData\\Local\\Temp\\ipykernel_28352\\2790792578.py:39: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = torch.nn.functional.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dc = DataCenter(device)\n",
    "dc.state[0] = 1\n",
    "dc.state[1] = 4\n",
    "dc.state[2] = 1\n",
    "dc.state[3] = 1\n",
    "dc.state[10] = 1\n",
    "dc.state[11] = 5\n",
    "dc.state[12] = 12\n",
    "dc.state[13] = 1\n",
    "dc.state[14] = 4\n",
    "dc.state[15] = 1\n",
    "\n",
    "dc.update(0.1)\n",
    "print(dc.state)\n",
    "\n",
    "remote_info = torch.zeros((2, VALUE_SIZE)).to(device)\n",
    "dc.update_rep(remote_info)\n",
    "print(dc.representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "27f27bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobGenerator():\n",
    "    def __init__(self, data_center_num) -> None:\n",
    "        self.underlying_state = torch.randint(0, 2, (data_center_num,))\n",
    "        self.data_center_num = data_center_num\n",
    "\n",
    "    def generate_job(self):\n",
    "        jobs = []\n",
    "        for i in range(self.data_center_num):\n",
    "            if torch.rand(1).item() < 0.02:\n",
    "                self.underlying_state[i] = 1 - i\n",
    "                \n",
    "            seed = torch.rand(1).item()\n",
    "            if self.underlying_state[i] == 1:\n",
    "                # choose high workload\n",
    "                if seed < 0.4:\n",
    "                    jobs.append((10, 1.0))\n",
    "                elif seed < 0.7:\n",
    "                    jobs.append((6, 0.6))\n",
    "                else:\n",
    "                    jobs.append((4, 0.4))\n",
    "            else:\n",
    "                # choose low workload\n",
    "                if seed < 0.3:\n",
    "                    jobs.append((4, 0.4))\n",
    "                elif seed < 0.7:\n",
    "                    jobs.append((3, 0.3))\n",
    "                else:\n",
    "                    jobs.append((2, 0.2))\n",
    "        return [torch.tensor(j) for j in jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "feb31ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "job_generator = JobGenerator(2)\n",
    "print(job_generator.generate_job())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8fd074",
   "metadata": {},
   "source": [
    "# Validity check\n",
    "\n",
    "To investigate that there is no trivial solution for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "572f98fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-113.00000000000107\n",
      "tensor(740.3980)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "total_reward = 0\n",
    "total_neg_reward = 0\n",
    "\n",
    "dataCenter = DataCenter(device)\n",
    "jobGenerator = JobGenerator(1)\n",
    "for i in range(2000):\n",
    "    job = jobGenerator.generate_job()[0]\n",
    "    reward = dataCenter.add_job(job)\n",
    "    total_neg_reward += reward\n",
    "    reward += dataCenter.update(1)\n",
    "    total_reward += reward\n",
    "\n",
    "print(total_neg_reward)\n",
    "\n",
    "dataCenter = DataCenter(device)\n",
    "jobGenerator = JobGenerator(1)\n",
    "for i in range(2000):\n",
    "    job = jobGenerator.generate_job()[0]\n",
    "    reward = dataCenter.add_job(job)\n",
    "    reward += dataCenter.update(1)\n",
    "    total_reward += reward\n",
    "\n",
    "print(total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c310f4",
   "metadata": {},
   "source": [
    "# Utility Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "bc23fcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(q_values, epsilon):\n",
    "    action = None\n",
    "    if torch.rand(1).item() < epsilon:\n",
    "        action = torch.randint(0, q_values.size(0), (1, ))\n",
    "    else:\n",
    "        action = torch.argmax(q_values)\n",
    "    q_value = q_values[action]\n",
    "    return action, q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "348ef84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, state, rep, job, action, reward, next_state, next_rep, next_job):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, rep, job, action, reward, next_state, next_rep, next_job)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # zip into torch tensors\n",
    "        # return zip(*random.sample(self.buffer, batch_size))\n",
    "        batch = random.sample(self.buffer, min(batch_size, len(self.buffer)))\n",
    "        state, rep, job, action, reward, next_state, next_rep, next_job = zip(*batch)\n",
    "        return torch.stack(list(state)), torch.stack(list(rep)), torch.stack(list(job)), torch.stack(list(action)), torch.stack(list(reward)), torch.stack(list(next_state)), torch.stack(list(next_rep)), torch.stack(list(next_job))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d23f4731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1.],\n",
      "        [0.]]), tensor([[1., 1.],\n",
      "        [0., 0.]]), tensor([[0.],\n",
      "        [0.]]), tensor([[0.],\n",
      "        [0.]]), tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1.],\n",
      "        [0.]]), tensor([[1., 1.],\n",
      "        [0., 0.]]))\n"
     ]
    }
   ],
   "source": [
    "# sample test\n",
    "\n",
    "replay_buffer = ReplayBuffer(100)\n",
    "replay_buffer.push(torch.zeros(STATE_SIZE), torch.zeros(VALUE_SIZE), torch.zeros(JOB_SIZE), torch.zeros(1), torch.zeros(1), torch.zeros(STATE_SIZE), torch.zeros(VALUE_SIZE), torch.zeros(JOB_SIZE))\n",
    "replay_buffer.push(torch.ones(STATE_SIZE), torch.ones(VALUE_SIZE), torch.ones(JOB_SIZE), torch.zeros(1), torch.zeros(1), torch.ones(STATE_SIZE), torch.ones(VALUE_SIZE), torch.ones(JOB_SIZE))\n",
    "\n",
    "print(replay_buffer.sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aa5222",
   "metadata": {},
   "source": [
    "# Main Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "68daa6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98fdd64",
   "metadata": {},
   "source": [
    "## Pure DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "7052beb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "we got  tensor(1643.3950, device='cuda:0') total reward  and actions tensor([3300.,  700.]) 8.75326180752087\n",
      "tensor(1643.3950, device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 8.0000, 1.0000, 8.0000, 1.0000, 1.0000, 1.0000,\n",
      "        3.0000, 1.0000, 4.0000, 0.3240, 1.0000, 6.0000, 0.5400, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 4.0000, 1.0000, 3.0000, 1.0000,\n",
      "        1.0000, 1.0000, 4.0000, 0.3240, 1.0000, 2.0000, 0.1800, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.2430, device='cuda:0') tensor([8.3239, 8.3227, 8.2169, 8.2109], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1672.9878, device='cuda:0') total reward  and actions tensor([3341.,  659.]) 8.315598717144827\n",
      "tensor(1672.9878, device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 3.0000, 1.0000, 5.0000, 1.0000, 5.0000, 1.0000,\n",
      "        1.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 9.0000, 1.0000, 3.0000, 1.0000, 2.0000, 1.0000, 2.0000, 1.0000,\n",
      "        3.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.1800, device='cuda:0') tensor([8.6505, 8.6067, 8.5749, 8.5172], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1635.2604, device='cuda:0') total reward  and actions tensor([3284.,  716.]) 7.899818781287585\n",
      "tensor(1635.2604, device='cuda:0') tensor([1., 8., 1., 4., 1., 2., 1., 3., 1., 8., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 7.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000,\n",
      "        4.0000, 1.0000, 3.0000, 0.1594, 1.0000, 4.0000, 0.2362, 1.0000, 3.0000,\n",
      "        0.1968, 1.0000, 4.0000, 0.2916, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.5890, device='cuda:0') tensor([7.8598, 7.8414, 7.7768, 7.7527], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1644.3390, device='cuda:0') total reward  and actions tensor([3327.,  673.]) 7.5048278422232055\n",
      "tensor(1644.3390, device='cuda:0') tensor([1., 7., 1., 5., 1., 4., 1., 1., 1., 4., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 6.0000, 1.0000, 5.0000, 1.0000, 2.0000, 1.0000,\n",
      "        1.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.4000, device='cuda:0') tensor([8.8442, 8.7727, 8.7317, 8.7447], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1647.5278, device='cuda:0') total reward  and actions tensor([3317.,  683.]) 7.129586450112045\n",
      "tensor(1647.5278, device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 3.0000, 1.0000, 5.0000, 1.0000, 2.0000, 1.0000,\n",
      "        1.0000, 1.0000, 6.0000, 0.4860, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  3.0000,  1.0000,  3.0000,  1.0000,  1.0000,\n",
      "         1.0000,  5.0000,  1.0000,  2.0000,  0.1458,  1.0000,  4.0000,  0.3240,\n",
      "         1.0000, 10.0000,  0.7200,  1.0000,  4.0000,  0.3600,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.2187, device='cuda:0') tensor([8.3584, 8.3349, 8.2863, 8.2233], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1638.2767, device='cuda:0') total reward  and actions tensor([3296.,  704.]) 6.773107127606442\n",
      "tensor(1638.2767, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  5.0000,  1.0000,  8.0000,  1.0000,  1.0000,\n",
      "         1.0000,  3.0000,  1.0000, 10.0000,  0.6561,  1.0000,  6.0000,  0.4374,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000, 10.0000,  1.0000,  4.0000,\n",
      "         1.0000,  3.0000,  1.0000,  2.0000,  0.1620,  1.0000,  4.0000,  0.2880,\n",
      "         1.0000,  2.0000,  0.1800,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.7200, device='cuda:0') tensor([7.9079, 7.9051, 7.8402, 7.7927], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1662.9265, device='cuda:0') total reward  and actions tensor([3329.,  671.]) 6.4344517712261196\n",
      "tensor(1662.9265, device='cuda:0') tensor([ 1.0000,  5.0000,  1.0000,  2.0000,  1.0000,  6.0000,  1.0000,  1.0000,\n",
      "         1.0000,  1.0000,  1.0000,  4.0000,  0.3240,  1.0000, 10.0000,  0.9000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 6.0000, 1.0000, 2.0000, 1.0000,\n",
      "        4.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.6660, device='cuda:0') tensor([8.8745, 8.8399, 8.7898, 8.7711], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1656.4082, device='cuda:0') total reward  and actions tensor([3314.,  686.]) 6.112729182664813\n",
      "tensor(1656.4082, device='cuda:0') tensor([ 1.,  5.,  1., 10.,  1.,  2.,  1.,  2.,  1.,  4.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor([1., 2., 1., 9., 1., 7., 1., 4., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor(0, device='cuda:0') tensor(1.5800, device='cuda:0') tensor([8.3567, 8.2888, 8.2699, 8.2264], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1658.7544, device='cuda:0') total reward  and actions tensor([3333.,  667.]) 5.807092723531572\n",
      "tensor(1658.7544, device='cuda:0') tensor([1., 3., 1., 2., 1., 4., 1., 1., 1., 8., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 3.0000, 1.0000, 1.0000, 1.0000,\n",
      "        6.0000, 1.0000, 2.0000, 0.1800, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.7500, device='cuda:0') tensor([8.9884, 8.9599, 8.8958, 8.8757], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1664.3198, device='cuda:0') total reward  and actions tensor([3344.,  656.]) 5.516738087354993\n",
      "tensor(1664.3198, device='cuda:0') tensor([ 1.0000,  5.0000,  1.0000,  4.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "         1.0000,  6.0000,  1.0000, 10.0000,  0.9000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 6.0000, 1.0000, 3.0000, 1.0000, 2.0000, 1.0000, 5.0000, 1.0000,\n",
      "        1.0000, 1.0000, 3.0000, 0.1968, 1.0000, 4.0000, 0.2333, 1.0000, 4.0000,\n",
      "        0.2916, 1.0000, 3.0000, 0.2430, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.7099, device='cuda:0') tensor([8.1059, 8.0355, 8.0163, 7.9954], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1665.6620, device='cuda:0') total reward  and actions tensor([3341.,  659.]) 5.240901182987243\n",
      "tensor(1665.6620, device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 3.0000, 1.0000, 2.0000, 1.0000, 6.0000, 1.0000,\n",
      "        3.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 9.0000, 1.0000,\n",
      "        7.0000, 1.0000, 2.0000, 0.1620, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0., device='cuda:0') tensor([8.7100, 8.7006, 8.5992, 8.6169], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1676.8044, device='cuda:0') total reward  and actions tensor([3364.,  636.]) 4.978856123837881\n",
      "tensor(1676.8044, device='cuda:0') tensor([ 1.0000,  4.0000,  1.0000,  5.0000,  1.0000,  5.0000,  1.0000,  8.0000,\n",
      "         1.0000,  1.0000,  1.0000,  6.0000,  0.4374,  1.0000, 10.0000,  0.8100,\n",
      "         1.0000,  4.0000,  0.3600,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        2.0000, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0.3600, device='cuda:0') tensor([8.3535, 8.3805, 8.1807, 8.2610], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1635.7781, device='cuda:0') total reward  and actions tensor([3315.,  685.]) 4.729913317645987\n",
      "tensor(1635.7781, device='cuda:0') tensor([1.0000, 6.0000, 1.0000, 3.0000, 1.0000, 6.0000, 1.0000, 6.0000, 1.0000,\n",
      "        2.0000, 1.0000, 4.0000, 0.3240, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 1.0000, 1.0000, 8.0000, 1.0000, 3.0000, 1.0000,\n",
      "        4.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(1.2380, device='cuda:0') tensor([8.2677, 8.2563, 8.1892, 8.1700], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1660.1764, device='cuda:0') total reward  and actions tensor([3326.,  674.]) 4.4934176517636875\n",
      "tensor(1660.1764, device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 4.0000, 1.0000, 7.0000, 1.0000, 3.0000, 1.0000,\n",
      "        3.0000, 1.0000, 4.0000, 0.3240, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 4.0000, 1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000,\n",
      "        4.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.6800, device='cuda:0') tensor([8.7753, 8.7692, 8.7190, 8.6791], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1657.4519, device='cuda:0') total reward  and actions tensor([3354.,  646.]) 4.268746769175503\n",
      "tensor(1657.4519, device='cuda:0') tensor([1., 2., 1., 3., 1., 8., 1., 4., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 6.0000, 1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 4.0000, 1.0000,\n",
      "        2.0000, 1.0000, 3.0000, 0.2700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.8400, device='cuda:0') tensor([8.9231, 8.8937, 8.8641, 8.8179], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1641.0349, device='cuda:0') total reward  and actions tensor([3346.,  654.]) 4.0553094307167274\n",
      "tensor(1641.0349, device='cuda:0') tensor([1., 2., 1., 7., 1., 6., 1., 7., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([ 1., 10.,  1.,  3.,  1.,  1.,  1.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor(0, device='cuda:0') tensor(1.1000, device='cuda:0') tensor([8.6949, 8.6181, 8.5212, 8.5582], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1666.7072, device='cuda:0') total reward  and actions tensor([3336.,  664.]) 3.852543959180891\n",
      "tensor(1666.7072, device='cuda:0') tensor([ 1.0000,  7.0000,  1.0000,  2.0000,  1.0000,  2.0000,  1.0000,  1.0000,\n",
      "         1.0000,  2.0000,  1.0000, 10.0000,  0.9000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([ 1., 10.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  3.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       device='cuda:0') tensor(1, device='cuda:0') tensor(1.2000, device='cuda:0') tensor([9.0641, 9.0853, 8.9113, 8.9691], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1673.0361, device='cuda:0') total reward  and actions tensor([3328.,  672.]) 3.6599167612218464\n",
      "tensor(1673.0361, device='cuda:0') tensor([1., 1., 1., 2., 1., 6., 1., 4., 1., 8., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 4.0000, 1.0000, 3.0000, 1.0000, 6.0000, 1.0000,\n",
      "        1.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.8600, device='cuda:0') tensor([8.8197, 8.6509, 8.7230, 8.6623], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1676.3370, device='cuda:0') total reward  and actions tensor([3337.,  663.]) 3.4769209231607543\n",
      "tensor(1676.3370, device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 5.0000, 1.0000, 6.0000, 1.0000,\n",
      "        4.0000, 1.0000, 4.0000, 0.2624, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 5.0000, 1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 4.0000, 1.0000,\n",
      "        2.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.7537, device='cuda:0') tensor([8.5770, 8.5659, 8.5058, 8.4692], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1614.5117, device='cuda:0') total reward  and actions tensor([3314.,  686.]) 3.3030748770027167\n",
      "tensor(1614.5117, device='cuda:0') tensor([ 1.0000,  1.0000,  1.0000,  3.0000,  1.0000,  8.0000,  1.0000,  4.0000,\n",
      "         1.0000,  4.0000,  1.0000, 10.0000,  0.8100,  1.0000, 10.0000,  0.9000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') tensor([1.0000, 1.0000, 1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000,\n",
      "        9.0000, 1.0000, 3.0000, 0.2430, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(1, device='cuda:0') tensor(0.4536, device='cuda:0') tensor([8.1903, 8.1967, 8.1523, 8.1427], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "we got  tensor(1667.5055, device='cuda:0') total reward  and actions tensor([3377.,  623.]) 3.1379211331525805\n",
      "tensor(1667.5055, device='cuda:0') tensor([1.0000, 2.0000, 1.0000, 5.0000, 1.0000, 2.0000, 1.0000, 7.0000, 1.0000,\n",
      "        1.0000, 1.0000, 6.0000, 0.5400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor([1.0000, 9.0000, 1.0000, 3.0000, 1.0000, 4.0000, 1.0000, 3.0000, 1.0000,\n",
      "        5.0000, 1.0000, 4.0000, 0.3600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0') tensor(0, device='cuda:0') tensor(0.3600, device='cuda:0') tensor([8.3863, 8.2854, 8.3444, 8.2687], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [297], line 131\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;66;03m# get next actions\u001b[39;00m\n\u001b[0;32m    130\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward_pass(curr_state)\n\u001b[1;32m--> 131\u001b[0m     action, q_value \u001b[38;5;241m=\u001b[39m \u001b[43mepsilon_greedy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPSILON\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# print(cur_state)\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwe got \u001b[39m\u001b[38;5;124m\"\u001b[39m, total_rewards, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal reward\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and actions\u001b[39m\u001b[38;5;124m\"\u001b[39m, actions_record, EPSILON\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m200\u001b[39m)\n",
      "Cell \u001b[1;32mIn [190], line 7\u001b[0m, in \u001b[0;36mepsilon_greedy\u001b[1;34m(q_values, epsilon)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     action \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(q_values)\n\u001b[1;32m----> 7\u001b[0m q_value \u001b[38;5;241m=\u001b[39m \u001b[43mq_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action, q_value\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\fx\\traceback.py:68\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_list(\u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\traceback.py:227\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 227\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\traceback.py:379\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    376\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[0;32m    377\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals))\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m--> 379\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\compilerop.py:193\u001b[0m, in \u001b[0;36mcheck_linecache_ipython\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call linecache.checkcache() safely protecting our cached values.\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# First call the original checkcache as intended\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkcache_ori\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# Then, update back the cache with our data, so that tracebacks related\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# to our compiled codes can be produced.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m linecache\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mupdate(linecache\u001b[38;5;241m.\u001b[39m_ipython_cache)\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main Simulation\n",
    "\n",
    "# configs\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "EPSILON = 1\n",
    "\n",
    "\n",
    "# Check if GPU is available and if so, use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create Data Centers\n",
    "data_center_num = 2\n",
    "dataCenter1 = DataCenter(device)\n",
    "dataCenter2 = DataCenter(device)\n",
    "\n",
    "\n",
    "model = SingleAgentNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "if True:\n",
    "    print(\"trained model loaded from file\")\n",
    "    model = torch.load(\"SingleAgentBaseline.pth\")\n",
    "    EPSILON = 0.95**60\n",
    "else:\n",
    "    print(\"model initialized randomly\")\n",
    "\n",
    "replay_buffer = ReplayBuffer(200000)\n",
    "dummy_value = torch.zeros(1).to(device)\n",
    "\n",
    "\n",
    "M = 60 #500\n",
    "N = 2000 #3000\n",
    "\n",
    "\n",
    "for episode in range(M):\n",
    "    EPSILON *= 0.95\n",
    "    # keep track of rewards\n",
    "    total_rewards = 0\n",
    "    actions_record = torch.zeros((2,))\n",
    "\n",
    "    # create a loss function\n",
    "    dataCenter1.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    dataCenter2.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    total_rewards = 0\n",
    "\n",
    "    jobGenerator = JobGenerator(data_center_num)\n",
    "\n",
    "    jobs = jobGenerator.generate_job()\n",
    "\n",
    "    # used for replay buffer\n",
    "    curr_state = torch.cat((dataCenter1.state, dataCenter2.state, jobs[0].to(device), jobs[1].to(device)), 0)\n",
    "\n",
    "    # get initial actions\n",
    "    q_values = model.forward_pass(curr_state)\n",
    "    action, q_value = epsilon_greedy(q_values, EPSILON)\n",
    "\n",
    "    for timestep in range(N):\n",
    "        # update according to action\n",
    "\n",
    "        reward1 = 0\n",
    "        reward2 = 0\n",
    "\n",
    "        reward = torch.tensor(0.0).to(device)\n",
    "\n",
    "        reward_from_1 = 0\n",
    "        reward_from_2 = 0\n",
    "\n",
    "        if action % 2 == 0:\n",
    "            reward_from_1 += dataCenter1.add_job(jobs[0])\n",
    "        else:\n",
    "            jobs[0][1] *= 0.8\n",
    "            reward_from_2 += dataCenter2.add_job(jobs[0])\n",
    "\n",
    "        if action // 2 == 0:\n",
    "            reward_from_2 +=  dataCenter2.add_job(jobs[1])\n",
    "        else:\n",
    "            jobs[1][1] *= 0.8\n",
    "            reward_from_1 += dataCenter1.add_job(jobs[1])\n",
    "        actions_record[action % 2 ] += 1\n",
    "        actions_record[action // 2] += 1\n",
    "\n",
    "\n",
    "        # print(\"state before update:\", dataCenter1.state, q_value_1)\n",
    "\n",
    "        reward_from_1 += dataCenter1.update(1)\n",
    "        reward_from_2 += dataCenter2.update(1)\n",
    "\n",
    "        reward1 = reward_from_1 * 0.5 + reward_from_2 * 0.5\n",
    "        reward2 = reward_from_2 * 0.5 + reward_from_1 * 0.5\n",
    "        \n",
    "        reward = reward1 + reward2\n",
    "\n",
    "        jobs = jobGenerator.generate_job()\n",
    "\n",
    "        next_state = torch.cat((dataCenter1.state, dataCenter2.state, jobs[0].to(device), jobs[1].to(device)), 0)\n",
    "\n",
    "        total_rewards += reward\n",
    "\n",
    "        ############################## update replay buffer ##############################\n",
    "\n",
    "        replay_buffer.push(curr_state, dummy_value, jobs[0].to(device), action.view(-1).to(device), reward1, next_state, dummy_value, jobs[1].to(device))\n",
    "        # print(curr_state, dummy_value, jobs[0].to(device), action, reward1, next_state, dummy_value, jobs[1].to(device))\n",
    "        sample_state, _, _, sample_action, sample_reward, sample_next_state, _, _ = replay_buffer.sample(BATCH_SIZE)\n",
    "        replay_actual_q_values = model.forward_pass(sample_state.detach())[torch.arange(sample_state.size(0)), sample_action.view(-1)]\n",
    "        replay_next_q_values = model.forward_pass(sample_next_state.detach())\n",
    "        # print(torch.max(replay_next_q_values, 1).size())\n",
    "        replay_expected_values = sample_reward + 0.95 * torch.max(replay_next_q_values, 1)[0]\n",
    "        loss = torch.nn.MSELoss()(replay_expected_values.detach(), replay_actual_q_values)\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "\n",
    "\n",
    "        # # get next actions\n",
    "        # new_q_values = model.forward_pass(next_state)\n",
    "        # new_action, new_q_value = torch.argmax(new_q_values), torch.max(new_q_values)\n",
    "\n",
    "        # # print(f\"{timestep}th loop\", reward, total_rewards, dataCenter1.state, action, reward)\n",
    "\n",
    "        # # backprop\n",
    "        # expected_value = reward + 0.95 * torch.max(new_q_values)\n",
    "        # actual_value = q_value.to(device)\n",
    "        # loss_1 = torch.nn.MSELoss()(expected_value.detach(), actual_value)\n",
    "        # loss_1.backward(retain_graph=True)\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        curr_state = torch.cat((dataCenter1.state, dataCenter2.state, jobs[0].to(device), jobs[1].to(device)), 0)\n",
    "        # get next actions\n",
    "        q_values = model.forward_pass(curr_state)\n",
    "        action, q_value = epsilon_greedy(q_values, EPSILON)\n",
    "\n",
    "\n",
    "        # print(cur_state)\n",
    "    print(\"we got \", total_rewards, \"total reward\", \" and actions\", actions_record, EPSILON*200)\n",
    "    print(total_rewards, dataCenter1.state, dataCenter2.state, action, reward, q_values)\n",
    "\n",
    "    #print(total_rewards, l_time, r_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "d8cd5666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not saving the model to avoid overwriting\n"
     ]
    }
   ],
   "source": [
    "if None:\n",
    "    print(\"saving the model!\")\n",
    "    torch.save(model, \"SingleAgentBaseline.pth\")\n",
    "else:\n",
    "    print(\"not saving the model to avoid overwriting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384b4eea",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ba4033a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\l\\AppData\\Local\\Temp\\ipykernel_28352\\2790792578.py:39: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = torch.nn.functional.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we got  tensor(125.3600, device='cuda:0') total reward; actions taken are tensor([207., 193.]) 190.0\n",
      "we got  tensor(129.6600, device='cuda:0') total reward; actions taken are tensor([225., 175.]) 180.5\n",
      "we got  tensor(119.1600, device='cuda:0') total reward; actions taken are tensor([223., 177.]) 171.47499999999997\n",
      "we got  tensor(98.8400, device='cuda:0') total reward; actions taken are tensor([238., 162.]) 162.90124999999998\n",
      "we got  tensor(123.1400, device='cuda:0') total reward; actions taken are tensor([243., 157.]) 154.75618749999998\n",
      "we got  tensor(115.6800, device='cuda:0') total reward; actions taken are tensor([246., 154.]) 147.01837812499997\n",
      "we got  tensor(116.1000, device='cuda:0') total reward; actions taken are tensor([250., 150.]) 139.66745921874994\n",
      "we got  tensor(129.1600, device='cuda:0') total reward; actions taken are tensor([255., 145.]) 132.68408625781245\n",
      "we got  tensor(107.8000, device='cuda:0') total reward; actions taken are tensor([270., 130.]) 126.04988194492182\n",
      "we got  tensor(122.8600, device='cuda:0') total reward; actions taken are tensor([259., 141.]) 119.74738784767571\n",
      "we got  tensor(119.6200, device='cuda:0') total reward; actions taken are tensor([211., 189.]) 113.76001845529191\n",
      "we got  tensor(109.0001, device='cuda:0') total reward; actions taken are tensor([242., 158.]) 108.07201753252731\n",
      "we got  tensor(123.9600, device='cuda:0') total reward; actions taken are tensor([242., 158.]) 102.66841665590094\n",
      "we got  tensor(131.9001, device='cuda:0') total reward; actions taken are tensor([261., 139.]) 97.53499582310589\n",
      "we got  tensor(125.9400, device='cuda:0') total reward; actions taken are tensor([238., 162.]) 92.65824603195058\n",
      "we got  tensor(137.9600, device='cuda:0') total reward; actions taken are tensor([260., 140.]) 88.02533373035305\n",
      "we got  tensor(123.9400, device='cuda:0') total reward; actions taken are tensor([268., 132.]) 83.6240670438354\n",
      "we got  tensor(112.8200, device='cuda:0') total reward; actions taken are tensor([296., 104.]) 79.44286369164362\n",
      "we got  tensor(127.1200, device='cuda:0') total reward; actions taken are tensor([244., 156.]) 75.47072050706143\n",
      "we got  tensor(123.9200, device='cuda:0') total reward; actions taken are tensor([266., 134.]) 71.69718448170835\n",
      "we got  tensor(125.5600, device='cuda:0') total reward; actions taken are tensor([290., 110.]) 68.11232525762293\n",
      "we got  tensor(92.7800, device='cuda:0') total reward; actions taken are tensor([286., 114.]) 64.70670899474177\n",
      "we got  tensor(126.5600, device='cuda:0') total reward; actions taken are tensor([317.,  83.]) 61.471373545004695\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\l\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_28352\\\\2790792578.py'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [169], line 135\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# # need to re-calculate the q_values to avoid issues in the backpropagation\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# get the representations\u001b[39;00m\n\u001b[0;32m    134\u001b[0m dataCenter1\u001b[38;5;241m.\u001b[39mupdate_rep(dataCenter2\u001b[38;5;241m.\u001b[39mrepresentations\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m--> 135\u001b[0m \u001b[43mdataCenter2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_rep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataCenter1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# get initial actions\u001b[39;00m\n\u001b[0;32m    138\u001b[0m q_values_1 \u001b[38;5;241m=\u001b[39m dataCenter1\u001b[38;5;241m.\u001b[39mget_q_values(dataCenter2\u001b[38;5;241m.\u001b[39mrepresentations\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n",
      "Cell \u001b[1;32mIn [151], line 48\u001b[0m, in \u001b[0;36mDataCenter.update_rep\u001b[1;34m(self, remote_info)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_rep\u001b[39m(\u001b[38;5;28mself\u001b[39m, remote_info):\n\u001b[1;32m---> 48\u001b[0m     new_reps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremote_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# print(new_reps.size(), self.representations.size())\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m new_reps\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentations\u001b[38;5;241m.\u001b[39msize()\n",
      "Cell \u001b[1;32mIn [3], line 40\u001b[0m, in \u001b[0;36mStateCompressor.forward_pass\u001b[1;34m(self, local_state, remote_info)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# print(x.size())\u001b[39;00m\n\u001b[0;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(x)\n\u001b[1;32m---> 40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m local_info \u001b[38;5;241m+\u001b[39m x\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\fx\\traceback.py:68\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_list(\u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\traceback.py:227\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 227\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\traceback.py:379\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    376\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[0;32m    377\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals))\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m--> 379\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\compilerop.py:193\u001b[0m, in \u001b[0;36mcheck_linecache_ipython\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call linecache.checkcache() safely protecting our cached values.\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# First call the original checkcache as intended\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkcache_ori\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# Then, update back the cache with our data, so that tracebacks related\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# to our compiled codes can be produced.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m linecache\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mupdate(linecache\u001b[38;5;241m.\u001b[39m_ipython_cache)\n",
      "File \u001b[1;32mc:\\Users\\l\\AppData\\Local\\Programs\\Python\\Python310\\lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main Simulation\n",
    "\n",
    "EPSILON = 1\n",
    "\n",
    "# configs\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "# Check if GPU is available and if so, use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create Data Centers\n",
    "data_center_num = 2\n",
    "dataCenter1 = DataCenter(device)\n",
    "dataCenter2 = DataCenter(device)\n",
    "\n",
    "\n",
    "M = 500 #500\n",
    "N = 200 #3000\n",
    "\n",
    "# M = 500\n",
    "# N = 3000\n",
    "\n",
    "for episode in range(M):\n",
    "    EPSILON *= 0.95\n",
    "    # keep track of rewards\n",
    "    total_rewards = 0\n",
    "    actions = torch.zeros((2,))\n",
    "\n",
    "    # for debugging\n",
    "    current_episode_jobs = []\n",
    "    current_episode_actions = []\n",
    "\n",
    "    # create a loss function\n",
    "    dataCenter1.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    dataCenter2.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    total_rewards = 0\n",
    "\n",
    "    jobGenerator = JobGenerator(data_center_num)\n",
    "\n",
    "    l_time = 0\n",
    "    r_time = 0\n",
    "    import time\n",
    "\n",
    "    jobs = jobGenerator.generate_job()\n",
    "    current_episode_jobs.append(jobs)\n",
    "\n",
    "    # get initial actions\n",
    "    q_values_1 = dataCenter1.get_q_values(dataCenter2.representations.unsqueeze(0), jobs[0].to(device))\n",
    "    q_values_2 = dataCenter2.get_q_values(dataCenter1.representations.unsqueeze(0), jobs[1].to(device))\n",
    "\n",
    "    action1, q_value_1 = epsilon_greedy(q_values_1, EPSILON)\n",
    "    action2, q_value_2 = epsilon_greedy(q_values_2, EPSILON)\n",
    "    current_episode_actions.append((action1, action2))\n",
    "\n",
    "    for timestep in range(N):\n",
    "        # update according to action\n",
    "        pre = time.time()\n",
    "\n",
    "        reward1 = 0\n",
    "        reward2 = 0\n",
    "\n",
    "        reward = torch.tensor(0.0).to(device)\n",
    "\n",
    "        if action1 == 0:\n",
    "            reward += dataCenter1.add_job(jobs[0])\n",
    "        else:\n",
    "            jobs[0][1] *= 0.8\n",
    "            reward += dataCenter2.add_job(jobs[0])\n",
    "\n",
    "        if action2 == 0:\n",
    "            reward += dataCenter2.add_job(jobs[1])\n",
    "        else:\n",
    "            jobs[1][1] *= 0.8\n",
    "            reward += dataCenter1.add_job(jobs[1])\n",
    "\n",
    "        actions[action1] += 1\n",
    "        actions[action2] += 1\n",
    "\n",
    "        reward += dataCenter1.update(1)\n",
    "        reward += dataCenter2.update(1)\n",
    "\n",
    "        post = time.time()\n",
    "        l_time += post - pre\n",
    "        \n",
    "\n",
    "        \n",
    "        # update representations\n",
    "        pre = time.time()\n",
    "        jobs = jobGenerator.generate_job()\n",
    "        current_episode_jobs.append(jobs)\n",
    "\n",
    "        # get the representations\n",
    "        dataCenter1.update_rep(dataCenter2.representations.unsqueeze(0))\n",
    "        dataCenter2.update_rep(dataCenter1.representations.unsqueeze(0))\n",
    "\n",
    "        # get next actions\n",
    "        new_q_values_1 = dataCenter1.get_q_values(dataCenter2.representations.unsqueeze(0), jobs[0].to(device))\n",
    "        new_q_values_2 = dataCenter2.get_q_values(dataCenter1.representations.unsqueeze(0), jobs[1].to(device))\n",
    "\n",
    "        new_action1, new_q_value_1 = torch.argmax(new_q_values_1), torch.max(new_q_values_1)\n",
    "        new_action2, new_q_value_2 = torch.argmax(new_q_values_2), torch.max(new_q_values_2)\n",
    "\n",
    "        post = time.time()\n",
    "        r_time += post - pre\n",
    "\n",
    "        # handle rewards\n",
    "        total_rewards += reward\n",
    "        reward1 = reward / 2\n",
    "        reward2 = reward / 2\n",
    "\n",
    "        # print(f\"{timestep}th loop\", reward, total_rewards, dataCenter1.state, dataCenter1.representations, action1, action2)\n",
    "\n",
    "        # backprop\n",
    "        expected_value_1 = reward1 + 0.9 * torch.max(new_q_values_1)\n",
    "        actual_value_1 = q_value_1.to(device)\n",
    "        loss_1 = torch.nn.MSELoss()(expected_value_1.detach(), actual_value_1)\n",
    "        loss_1.backward(retain_graph=True)\n",
    "\n",
    "        expected_value_2 = reward2 + 0.9 * torch.max(new_q_values_2)\n",
    "        actual_value_2 = q_value_2.to(device)\n",
    "        loss_2 = torch.nn.MSELoss()(expected_value_2.detach(), actual_value_2)\n",
    "        loss_2.backward(retain_graph=True)\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            dataCenter1.backprop()\n",
    "            dataCenter2.backprop()\n",
    "\n",
    "        # # need to re-calculate the q_values to avoid issues in the backpropagation\n",
    "        \n",
    "        # get the representations\n",
    "        dataCenter1.update_rep(dataCenter2.representations.unsqueeze(0))\n",
    "        dataCenter2.update_rep(dataCenter1.representations.unsqueeze(0))\n",
    "\n",
    "        # get initial actions\n",
    "        q_values_1 = dataCenter1.get_q_values(dataCenter2.representations.unsqueeze(0), jobs[0].to(device))\n",
    "        q_values_2 = dataCenter2.get_q_values(dataCenter1.representations.unsqueeze(0), jobs[1].to(device))\n",
    "\n",
    "        action1, q_value_1 = epsilon_greedy(q_values_1, EPSILON)\n",
    "        action2, q_value_2 = epsilon_greedy(q_values_2, EPSILON)\n",
    "        current_episode_actions.append((action1, action2))\n",
    "\n",
    "        # action1, q_value_1 = new_action1, new_q_value_1\n",
    "        # action2, q_value_2 = new_action2, new_q_value_2\n",
    "\n",
    "    print(\"we got \", total_rewards, \"total reward; actions taken are\", actions, 200*EPSILON)\n",
    "\n",
    "    #print(total_rewards, l_time, r_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "8a947c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([2., 0.])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2., 0.])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([2., 0.]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([2., 0.])], [tensor([2., 0.]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([2., 0.]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([2., 0.])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([2., 0.]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([2., 0.])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([2., 0.])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([8.0000, 0.6000]), tensor([2., 0.])], [tensor([4.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.2000])], [tensor([2., 0.]), tensor([2., 0.])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([2., 0.]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([2., 0.])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([2., 0.]), tensor([4.0000, 0.2000])], [tensor([2., 0.]), tensor([2., 0.])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.6000])], [tensor([2., 0.]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.6000]), tensor([2., 0.])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.6000])], [tensor([2., 0.]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2., 0.]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([2., 0.])], [tensor([2., 0.]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2., 0.])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.6000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.6000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2., 0.])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.6000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.6000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.6000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([2., 0.]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2., 0.])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([2., 0.])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])], [tensor([4.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([2.0000, 0.2000])], [tensor([4.0000, 0.4000]), tensor([4.0000, 0.4000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2., 0.]), tensor([8.0000, 0.8000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([8.0000, 0.8000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([2.0000, 0.2000]), tensor([2.0000, 0.2000])], [tensor([8.0000, 0.8000]), tensor([4.0000, 0.4000])], [tensor([4.0000, 0.4000]), tensor([8.0000, 0.8000])]] [(tensor(1), tensor(0)), (tensor(0), tensor(0)), (tensor(1), tensor(0)), (tensor(0), tensor(0)), (tensor(1), tensor(1)), (tensor(1), tensor(0)), (tensor(1), tensor(0)), (tensor(1), tensor(0)), (tensor(1), tensor(0)), (tensor(0), tensor(0)), (tensor(1), tensor(0)), (tensor(1), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([0]), tensor(0)), (tensor(1), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(0)), (tensor(1), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(1), tensor(0)), (tensor(1), tensor(0)), (tensor(1), tensor(0)), (tensor(1), tensor(0)), (tensor(1), tensor([1])), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor([0]), tensor(1)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(1)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(1)), (tensor(0), tensor(0)), (tensor([0]), tensor(1)), (tensor(0), tensor(1)), (tensor([1]), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor([1])), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor([1])), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor([1]), tensor(1)), (tensor([0]), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor([1]), tensor([1])), (tensor(0), tensor(1)), (tensor(0), tensor([1])), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(1), tensor(1)), (tensor([1]), tensor(1)), (tensor([1]), tensor([0])), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor([0]), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor([0]), tensor([0])), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor([0]), tensor(1)), (tensor(0), tensor(1)), (tensor([0]), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor([0])), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor([0]), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor([0])), (tensor([0]), tensor(0)), (tensor(0), tensor(1)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(1)), (tensor([1]), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor([1]), tensor(1)), (tensor([0]), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(1)), (tensor(1), tensor(0)), (tensor(0), tensor(1)), (tensor(0), tensor(1)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor([1]), tensor(0)), (tensor([0]), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor([0]), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor([0]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor([0])), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(1), tensor([0])), (tensor(1), tensor([1])), (tensor(1), tensor(0)), (tensor(1), tensor([0])), (tensor(1), tensor(0)), (tensor(1), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor([0])), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor([0]), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor([0])), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor([0]), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor([0]), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor([1]), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor([1])), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor([1])), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor([0]), tensor([0])), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor([0])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([1])), (tensor(0), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor([0])), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor([1]), tensor(0)), (tensor([0]), tensor(0)), (tensor([0]), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0)), (tensor(0), tensor(0))]\n"
     ]
    }
   ],
   "source": [
    "print(current_episode_jobs, current_episode_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fc35ac",
   "metadata": {},
   "source": [
    "## Independent Learners\n",
    "Now we provide a baseline of independent learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8db55fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "we got  tensor(1295.4580, device='cuda:0') total reward\n",
      "actions tensor([2118., 1882.]) 190.0\n",
      "we got  tensor(1328.2771, device='cuda:0') total reward\n",
      "actions tensor([2171., 1829.]) 180.5\n",
      "we got  tensor(1292.5277, device='cuda:0') total reward\n",
      "actions tensor([2295., 1705.]) 171.47499999999997\n",
      "we got  tensor(1295.7089, device='cuda:0') total reward\n",
      "actions tensor([2347., 1653.]) 162.90124999999998\n",
      "we got  tensor(1332.8951, device='cuda:0') total reward\n",
      "actions tensor([2468., 1532.]) 154.75618749999998\n",
      "we got  tensor(1286.6544, device='cuda:0') total reward\n",
      "actions tensor([2507., 1493.]) 147.01837812499997\n",
      "we got  tensor(1271.9941, device='cuda:0') total reward\n",
      "actions tensor([2609., 1391.]) 139.66745921874994\n",
      "we got  tensor(1229.7603, device='cuda:0') total reward\n",
      "actions tensor([2720., 1280.]) 132.68408625781245\n",
      "we got  tensor(1270.2968, device='cuda:0') total reward\n",
      "actions tensor([2784., 1216.]) 126.04988194492182\n",
      "we got  tensor(1258.2737, device='cuda:0') total reward\n",
      "actions tensor([2817., 1183.]) 119.74738784767571\n",
      "we got  tensor(1224.3174, device='cuda:0') total reward\n",
      "actions tensor([2794., 1206.]) 113.76001845529191\n",
      "we got  tensor(1228.6488, device='cuda:0') total reward\n",
      "actions tensor([2833., 1167.]) 108.07201753252731\n",
      "we got  tensor(1220.2758, device='cuda:0') total reward\n",
      "actions tensor([2961., 1039.]) 102.66841665590094\n",
      "we got  tensor(1168.4830, device='cuda:0') total reward\n",
      "actions tensor([2950., 1050.]) 97.53499582310589\n",
      "we got  tensor(1190.2988, device='cuda:0') total reward\n",
      "actions tensor([3007.,  993.]) 92.65824603195058\n",
      "we got  tensor(1179.1124, device='cuda:0') total reward\n",
      "actions tensor([3077.,  923.]) 88.02533373035305\n",
      "we got  tensor(1171.1266, device='cuda:0') total reward\n",
      "actions tensor([3123.,  877.]) 83.6240670438354\n",
      "we got  tensor(1205.8933, device='cuda:0') total reward\n",
      "actions tensor([3138.,  862.]) 79.44286369164362\n",
      "we got  tensor(1120.3774, device='cuda:0') total reward\n",
      "actions tensor([3224.,  776.]) 75.47072050706143\n",
      "we got  tensor(1142.1382, device='cuda:0') total reward\n",
      "actions tensor([3253.,  747.]) 71.69718448170835\n",
      "we got  tensor(1281.8287, device='cuda:0') total reward\n",
      "actions tensor([2989., 1011.]) 68.11232525762293\n",
      "we got  tensor(1341.7612, device='cuda:0') total reward\n",
      "actions tensor([2894., 1106.]) 64.70670899474177\n",
      "we got  tensor(1331.7714, device='cuda:0') total reward\n",
      "actions tensor([2871., 1129.]) 61.471373545004695\n",
      "we got  tensor(1357.8799, device='cuda:0') total reward\n",
      "actions tensor([2902., 1098.]) 58.39780486775445\n",
      "we got  tensor(1356.7318, device='cuda:0') total reward\n",
      "actions tensor([2897., 1103.]) 55.47791462436673\n",
      "we got  tensor(1320.4675, device='cuda:0') total reward\n",
      "actions tensor([2892., 1108.]) 52.704018893148394\n",
      "we got  tensor(1350.8672, device='cuda:0') total reward\n",
      "actions tensor([2923., 1077.]) 50.068817948490974\n",
      "we got  tensor(1345.7572, device='cuda:0') total reward\n",
      "actions tensor([2902., 1098.]) 47.56537705106642\n",
      "we got  tensor(1353.7880, device='cuda:0') total reward\n",
      "actions tensor([2935., 1065.]) 45.1871081985131\n",
      "we got  tensor(1364.6993, device='cuda:0') total reward\n",
      "actions tensor([2970., 1030.]) 42.92775278858744\n",
      "we got  tensor(1308.0901, device='cuda:0') total reward\n",
      "actions tensor([3144.,  856.]) 40.78136514915806\n",
      "we got  tensor(1329.5907, device='cuda:0') total reward\n",
      "actions tensor([3170.,  830.]) 38.742296891700164\n",
      "we got  tensor(1327.5040, device='cuda:0') total reward\n",
      "actions tensor([3189.,  811.]) 36.80518204711515\n",
      "we got  tensor(1342.3096, device='cuda:0') total reward\n",
      "actions tensor([3177.,  823.]) 34.964922944759394\n",
      "we got  tensor(1334.0884, device='cuda:0') total reward\n",
      "actions tensor([3216.,  784.]) 33.21667679752143\n",
      "we got  tensor(1344.3339, device='cuda:0') total reward\n",
      "actions tensor([3176.,  824.]) 31.555842957645353\n",
      "we got  tensor(1329.1971, device='cuda:0') total reward\n",
      "actions tensor([3269.,  731.]) 29.978050809763086\n",
      "we got  tensor(1361.3973, device='cuda:0') total reward\n",
      "actions tensor([3232.,  768.]) 28.47914826927493\n",
      "we got  tensor(1324.7162, device='cuda:0') total reward\n",
      "actions tensor([3202.,  798.]) 27.05519085581118\n",
      "we got  tensor(1354.7268, device='cuda:0') total reward\n",
      "actions tensor([3264.,  736.]) 25.702431313020618\n",
      "we got  tensor(1023.5865, device='cuda:0') total reward\n",
      "actions tensor([3736.,  264.]) 24.417309747369586\n",
      "we got  tensor(1036.0580, device='cuda:0') total reward\n",
      "actions tensor([3755.,  245.]) 23.196444260001105\n",
      "we got  tensor(1025.8730, device='cuda:0') total reward\n",
      "actions tensor([3802.,  198.]) 22.03662204700105\n",
      "we got  tensor(1061.3060, device='cuda:0') total reward\n",
      "actions tensor([3758.,  242.]) 20.934790944650995\n",
      "we got  tensor(1035.2185, device='cuda:0') total reward\n",
      "actions tensor([3810.,  190.]) 19.888051397418447\n",
      "we got  tensor(1031.2743, device='cuda:0') total reward\n",
      "actions tensor([3828.,  172.]) 18.893648827547523\n",
      "we got  tensor(1007.3951, device='cuda:0') total reward\n",
      "actions tensor([3827.,  173.]) 17.94896638617015\n",
      "we got  tensor(1012.5771, device='cuda:0') total reward\n",
      "actions tensor([3824.,  176.]) 17.05151806686164\n",
      "we got  tensor(998.2941, device='cuda:0') total reward\n",
      "actions tensor([3833.,  167.]) 16.198942163518556\n",
      "we got  tensor(1022.0046, device='cuda:0') total reward\n",
      "actions tensor([3854.,  146.]) 15.388995055342628\n",
      "we got  tensor(987.9414, device='cuda:0') total reward\n",
      "actions tensor([3764.,  236.]) 14.619545302575496\n",
      "we got  tensor(1032.5150, device='cuda:0') total reward\n",
      "actions tensor([3823.,  177.]) 13.888568037446719\n",
      "we got  tensor(1036.8600, device='cuda:0') total reward\n",
      "actions tensor([3842.,  158.]) 13.19413963557438\n",
      "we got  tensor(1022.8115, device='cuda:0') total reward\n",
      "actions tensor([3849.,  151.]) 12.53443265379566\n",
      "we got  tensor(1041.8363, device='cuda:0') total reward\n",
      "actions tensor([3844.,  156.]) 11.907711021105877\n",
      "we got  tensor(1029.4265, device='cuda:0') total reward\n",
      "actions tensor([3842.,  158.]) 11.312325470050583\n",
      "we got  tensor(1042.5734, device='cuda:0') total reward\n",
      "actions tensor([3823.,  177.]) 10.746709196548053\n",
      "we got  tensor(1042.2550, device='cuda:0') total reward\n",
      "actions tensor([3860.,  140.]) 10.20937373672065\n",
      "we got  tensor(1016.1352, device='cuda:0') total reward\n",
      "actions tensor([3877.,  123.]) 9.698905049884617\n",
      "we got  tensor(1028.4027, device='cuda:0') total reward\n",
      "actions tensor([3872.,  128.]) 9.213959797390386\n"
     ]
    }
   ],
   "source": [
    "# Main Simulation\n",
    "\n",
    "# configs\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "EPSILON = 1\n",
    "\n",
    "\n",
    "# Check if GPU is available and if so, use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create Data Centers\n",
    "data_center_num = 2\n",
    "dataCenter1 = DataCenter(device)\n",
    "dataCenter2 = DataCenter(device)\n",
    "\n",
    "\n",
    "M = 60 #500\n",
    "N = 2000 #3000\n",
    "\n",
    "\n",
    "for episode in range(M):\n",
    "    EPSILON *= 0.95\n",
    "    # keep track of rewards\n",
    "    total_rewards = 0\n",
    "    actions_record = torch.zeros((2,))\n",
    "\n",
    "    # create a loss function\n",
    "    dataCenter1.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    dataCenter2.state = torch.zeros(STATE_SIZE).to(device)\n",
    "    total_rewards = 0\n",
    "\n",
    "    jobGenerator = JobGenerator(data_center_num)\n",
    "\n",
    "    l_time = 0\n",
    "    r_time = 0\n",
    "    import time\n",
    "\n",
    "    jobs = jobGenerator.generate_job()\n",
    "\n",
    "    # get initial actions\n",
    "    q_values_1 = dataCenter1.get_q_values(torch.zeros((0,)), jobs[0].to(device))\n",
    "    q_values_2 = dataCenter2.get_q_values(torch.zeros((0,)), jobs[1].to(device))\n",
    "\n",
    "    action1, q_value_1 = epsilon_greedy(q_values_1, EPSILON)\n",
    "    action2, q_value_2 = epsilon_greedy(q_values_2, EPSILON)\n",
    "\n",
    "    for timestep in range(N):\n",
    "        # update according to action\n",
    "        pre = time.time()\n",
    "\n",
    "        reward1 = 0\n",
    "        reward2 = 0\n",
    "\n",
    "        reward = torch.tensor(0.0).to(device)\n",
    "\n",
    "        reward_from_1 = 0\n",
    "        reward_from_2 = 0\n",
    "\n",
    "        if action1 == 0:\n",
    "            reward_from_1 += dataCenter1.add_job(jobs[0])\n",
    "        else:\n",
    "            jobs[0][1] *= 0.8\n",
    "            reward_from_2 += dataCenter2.add_job(jobs[0])\n",
    "\n",
    "        if action2 == 0:\n",
    "            reward_from_2 +=  dataCenter2.add_job(jobs[1])\n",
    "        else:\n",
    "            jobs[1][1] *= 0.8\n",
    "            reward_from_1 += dataCenter1.add_job(jobs[1])\n",
    "        actions_record[action1] += 1\n",
    "        actions_record[action2] += 1\n",
    "\n",
    "\n",
    "        # print(\"state before update:\", dataCenter1.state, q_value_1)\n",
    "\n",
    "        reward_from_1 += dataCenter1.update(1)\n",
    "        reward_from_2 += dataCenter2.update(1)\n",
    "\n",
    "        reward1 = reward_from_1 * 0.5 + reward_from_2 * 0.5\n",
    "        reward2 = reward_from_2 * 0.5 + reward_from_1 * 0.5\n",
    "        \n",
    "        reward = reward1 + reward2\n",
    "\n",
    "        post = time.time()\n",
    "        l_time += post - pre\n",
    "        \n",
    "\n",
    "        # update representations\n",
    "        pre = time.time()\n",
    "        jobs = jobGenerator.generate_job()\n",
    "\n",
    "        # get next actions\n",
    "        new_q_values_1 = dataCenter1.get_q_values(torch.zeros((0,)), jobs[0].to(device))\n",
    "        new_q_values_2 = dataCenter2.get_q_values(torch.zeros((0,)), jobs[1].to(device))\n",
    "\n",
    "        new_action1, new_q_value_1 = epsilon_greedy(q_values_1, EPSILON)\n",
    "        new_action2, new_q_value_2 = epsilon_greedy(q_values_2, EPSILON)\n",
    "\n",
    "        post = time.time()\n",
    "        r_time += post - pre\n",
    "\n",
    "        # handle rewards\n",
    "        total_rewards += reward\n",
    "        # reward1 = reward / 2\n",
    "        # reward2 = reward / 2\n",
    "\n",
    "        # print(\"reward\", reward1)\n",
    "\n",
    "        # print(\"state after update:\", dataCenter1.state, new_q_value_1)\n",
    "\n",
    "        # print(f\"{timestep}th loop\", reward, total_rewards, dataCenter1.state, dataCenter1.representations, action1, action2, q_value_1, q_values_1)\n",
    "\n",
    "        # backprop\n",
    "        expected_value_1 = reward1 + 0.95 * torch.max(new_q_values_1)\n",
    "        actual_value_1 = q_value_1.to(device)\n",
    "        loss_1 = torch.nn.MSELoss()(expected_value_1.detach(), actual_value_1)\n",
    "        loss_1.backward(retain_graph=True)\n",
    "\n",
    "        expected_value_2 = reward2 + 0.95 * torch.max(new_q_values_2)\n",
    "        actual_value_2 = q_value_2.to(device)\n",
    "        loss_2 = torch.nn.MSELoss()(expected_value_2.detach(), actual_value_2)\n",
    "        loss_2.backward(retain_graph=True)\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            dataCenter1.backprop()\n",
    "            dataCenter2.backprop()\n",
    "\n",
    "\n",
    "        # get initial actions\n",
    "        q_values_1 = dataCenter1.get_q_values(dataCenter2.representations.unsqueeze(0), jobs[0].to(device))\n",
    "        q_values_2 = dataCenter2.get_q_values(dataCenter1.representations.unsqueeze(0), jobs[1].to(device))\n",
    "\n",
    "        action1, q_value_1 = epsilon_greedy(q_values_1, EPSILON)\n",
    "        action2, q_value_2 = epsilon_greedy(q_values_2, EPSILON)\n",
    "\n",
    "        action1, q_value_1 = epsilon_greedy(q_values_1, EPSILON)\n",
    "        action2, q_value_2 = epsilon_greedy(q_values_2, EPSILON)\n",
    "\n",
    "\n",
    "        # print(cur_state)\n",
    "    print(\"we got \", total_rewards, \"total reward\")\n",
    "    print(\"actions\", actions_record, EPSILON*200)\n",
    "\n",
    "    #print(total_rewards, l_time, r_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
